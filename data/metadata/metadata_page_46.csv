dc.contributor.advisor,dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.relation.ispartofseries,dc.subject,dc.title,dc.rights,dc.rights.uri,dc.language.rfc3066,dc.description,dc.date.updated,dc.identifier.citation,dc.contributor,dc.relation.isreplacedby
Silvio Micali,"Chen, Jing; Micali, Silvio",Theory of Computation,2012-08-01T21:30:09Z,2012-08-01T21:30:09Z,2012-07-31,http://hdl.handle.net/1721.1/71953,"Shimoji and Watson (1998) prove that a strategy of an extensive game is rationalizable in the sense of Pearce if and only if it survives the maximal elimination of conditionally dominated strategies. Briefly, this process iteratively eliminates conditionally dominated strategies according to a specific order, which is also the start of an order of elimination of weakly dominated strategies. Since the final set of possible payoff profiles, or terminal nodes, surviving iterated elimination of weakly dominated strategies may be order-dependent, one may suspect that the same holds for conditional dominance. We prove that, although the sets of strategy profiles surviving two arbitrary elimination orders of conditional dominance may be very different from each other, they are equivalent in the following sense: for each player i and each pair of elimination orders, there exists a function phi_i mapping each strategy of i surviving the first order to a strategy of i surviving the second order, such that, for every strategy profile s surviving the first order, the profile (phi_i(s_i))_i induces the same terminal node as s does. To prove our results we put forward a new notion of dominance and an elementary characterization of extensive-form rationalizability (EFR) that may be of independent interest. We also establish connections between EFR and other existing iterated dominance procedures, using our notion of dominance and our characterization of EFR.",35 p.,MIT-CSAIL-TR-2012-023,extensive-form rationalizability; distinguishable dominance; order independence,"The Order Independence of Iterated Dominance in Extensive Games, with Connections to Mechanism Design and Backward Induction",,,,,,,,
Armando Solar-Lezama,"Cheung, Alvin; Solar-Lezama, Armando; Madden, Samuel",Computer-Aided Programming,2012-08-13T21:15:04Z,2012-08-13T21:15:04Z,2012-08-13,http://hdl.handle.net/1721.1/72106,"This paper presents a new approach to select events of interest to a user in a social media setting where events are generated by the activities of the user's friends through their mobile devices. We argue that given the unique requirements of the social media setting, the problem is best viewed as an inductive learning problem, where the goal is to first generalize from the users' expressed ""likes"" and ""dislikes"" of specific events, then to produce a program that can be manipulated by the system and distributed to the collection devices to collect only data of interest. The key contribution of this paper is a new algorithm that combines existing machine learning techniques with new program synthesis technology to learn users' preferences. We show that when compared with the more standard approaches, our new algorithm provides up to order-of-magnitude reductions in model training time, and significantly higher prediction accuracies for our target application. The approach also improves on standard machine learning techniques in that it produces clear programs that can be manipulated to optimize data collection and filtering.",10 p.,MIT-CSAIL-TR-2012-025,recommender systems; social networking applications; support vector machines,Using Program Synthesis for Social Recommendations,Creative Commons Attribution 3.0 Unported,http://creativecommons.org/licenses/by/3.0/,en-US,,,,,
Brian Williams,"Dong, Shuonan",Model-based Embedded and Robotic Systems,2018-01-30T23:46:40Z,2018-01-30T23:46:40Z,2012-08-23,http://hdl.handle.net/1721.1/113367,"Robots can act as proxies for human operators in environments where a human operator is not present or cannot directly perform a task, such as in dangerous or remote situations. Teleoperation is a common interface for controlling robots that are designed to be human proxies. Unfortunately, teleoperation may fail to preserve the natural fluidity of human motions due to interface limitations such as communication delays, non-immersive sensing, and controller uncertainty. I envision a robot that can learn a set of motions that a teleoperator commonly performs, so that it can autonomously execute routine tasks or recognize a user's motion in real time. Tasks can be either primitive activities or compound plans. During online operation, the robot can recognize a user's teleoperated motions on the fly and offer real-time assistance, for example, by autonomously executing the remainder of the task. I realize this vision by addressing three main problems: (1) learning primitive activities by identifying significant features of the example motions and generalizing the behaviors from user demonstration trajectories; (2) recognizing activities in real time by determining the likelihood that a user is currently executing one of several learned activities; and (3) learning complex plans by generalizing a sequence of activities, through auto-segmentation and incremental learning of previously unknown activities. To solve these problems, I first present an approach to learning activities from human demonstration that (1) provides flexibility and robustness when encoding a user's demonstrated motions by using a novel representation called a probabilistic flow tube, and (2) automatically determines the relevant features of a motion so that they can be preserved during autonomous execution in new situations. I next introduce an approach to real-time motion recognition that (1) uses temporal information to successfully model motions that may be non-Markovian, (2) provides fast real-time recognition of motions in progress by using an incremental temporal alignment approach, and (3) leverages the probabilistic flow tube representation to ensure robustness during recognition against varying environment states. Finally, I develop an approach to learn combinations of activities that (1) automatically determines where activities should be segmented in a sequence and (2) learns previously unknown activities on the fly. I demonstrate the results of autonomously executing motions learned by my approach on two different robotic platforms supporting user-teleoperated manipulation tasks in a variety of environments. I also present the results of real-time recognition in different scenarios, including a robotic hardware platform. Systematic testing in a two-dimensional environment shows up to a 27% improvement in activity recognition rates over prior art, while maintaining average computing times for incremental recognition of less than half of human reaction time.",144 p.,MIT-CSAIL-TR-2018-007,,Learning and recognition of hybrid manipulation tasks in variable environments using probabilistic flow tubes,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,,PhD thesis,2018-01-30T23:46:40Z,,,
Nancy Lynch,"Musial, Peter M.",Theory of Computation,2012-09-05T22:00:14Z,2012-09-05T22:00:14Z,2012-08-27,http://hdl.handle.net/1721.1/72537,"The objective of this work is the derivation of software that is verifiably correct. Our approach is to abstract system specifications and model these in a formal framework called Timed Input/Output Automata, which provides a notation for expressing distributed systems and mathematical support for reasoning about their properties. Although formal reasoning is easier at an abstract level, it is not clear how to transform these abstractions into executable code. During system implementation, when an abstract system specification is left up to human interpretation, then this opens a possibility of undesirable behaviors being introduced into the final code, thereby nullifying all formal efforts. This manuscript addresses this issue and presents a set of transformation methods for systems described as a network to timed automata into Java code for distributed platforms. We prove that the presented transformation methods preserve guarantees of the source specifications, and therefore, result in code that is correct by construction.",92 p.,MIT-CSAIL-TR-2012-027,,From Formal Methods to Executable Code,,,,Note: the cover page of this report shows an incorrect title.  The title given on the first page of the document itself is correct.,,,,
Nancy Lynch,"Censor-Hillel, Keren; Haeupler, Bernhard; Lynch, Nancy; Medard, Muriel",Theory of Computation,2012-09-05T22:00:07Z,2012-09-05T22:00:07Z,2012-08-27,http://hdl.handle.net/1721.1/72536,"Efficient communication in wireless networks is typically challenged by the possibility of interference among several transmitting nodes. Much important research has been invested in decreasing the number of collisions in order to obtain faster algorithms for communication in such networks. This paper proposes a novel approach for wireless communication, which embraces collisions rather than avoiding them, over an additive channel. It introduces a coding technique called Bounded-Contention Coding (BCC) that allows collisions to be successfully decoded by the receiving nodes into the original transmissions and whose complexity depends on a bound on the contention among the transmitters. BCC enables deterministic local broadcast in a network with n nodes and at most a transmitters with information of L bits each within O(a log n + aL) bits of communication with full-duplex radios, and O((a log n + aL)(log n)) bits, with high probability, with half-duplex radios. When combined with random linear network coding, BCC gives global broadcast within O((D + a + log n)(a log n + L)) bits, with high probability. This also holds in dynamic networks that can change arbitrarily over time by a worst-case adversary. When no bound on the contention is given, it is shown how to probabilistically estimate it and obtain global broadcast that is adaptive to the true contention in the network.",17 p.,MIT-CSAIL-TR-2012-026,,Bounded-Contention Coding for Wireless Networks in the High SNR Regime,,,,,,,,
Silvio Micali,"Chiesa, Alessandro; Micali, Silvio; Zhu, Zeyuan Allen",Theory of Computation,2012-09-07T22:15:03Z,2012-09-07T22:15:03Z,2012-09-07,http://hdl.handle.net/1721.1/72584,"We provide an optimal probabilistic mechanism for maximizing social welfare in single-good auctions when each player does not know his true valuation for the good, but only a set of valuations that is guaranteed to include his true one.",19 p.,MIT-CSAIL-TR-2012-028,Knightian Auctions; Probabilistic Mechanisms; Social Welfare,A Social-Welfare Optimal Probabilistic Mechanism for Knightian Single-Good Auctions,,,,,,,,
Tomaso Poggio,"Little, Anna V.; Maggioni, Mauro; Rosasco, Lorenzo",Center for Biological and Computational Learning (CBCL),2012-09-10T18:00:08Z,2012-09-10T18:00:08Z,2012-09-08,http://hdl.handle.net/1721.1/72597,"Large data sets are often modeled as being noisy samples from probability distributions in R^D, with D large. It has been noticed that oftentimes the support M of these probability distributions seems to be well-approximated by low-dimensional sets, perhaps even by manifolds. We shall consider sets that are locally well approximated by k-dimensional planes, with k << D, with k-dimensional manifolds isometrically embedded in R^D being a special case. Samples from this distribution; are furthermore corrupted by D-dimensional noise. Certain tools from multiscale geometric measure theory and harmonic analysis seem well-suited to be adapted to the study of samples from such probability distributions, in order to yield quantitative geometric information about them. In this paper we introduce and study multiscale covariance matrices, i.e. covariances corresponding to the distribution restricted to a ball of radius r, with a fixed center and varying r, and under rather general geometric assumptions we study how their empirical, noisy counterparts behave. We prove that in the range of scales where these covariance matrices are most informative, the empirical, noisy covariances are close to their expected, noiseless counterparts. In fact, this is true as soon as the number of samples in the balls where the covariance matrices are computed is linear in the intrinsic dimension of M. As an application, we present an algorithm for estimating the intrinsic dimension of M.",59 p.,MIT-CSAIL-TR-2012-029; CBCL-310,machine learning; high dimensional data,"Multiscale Geometric Methods for Data Sets I: Multiscale SVD, Noise and Curvature",,,,,,,,
Barbara Liskov,"Liskov, Barbara",Programming Methodology,2012-09-17T18:30:04Z,2012-09-17T18:30:04Z,2012-09-14,http://hdl.handle.net/1721.1/73017,This document describes the interface that the Aeolus information flow platform provides for users who are implementing applications using Java. The document explains how the Aeolus features are made available by means of a Java library.,37 p.,MIT-CSAIL-TR-2012-030,information flow control; DIFC; data privacy,Aeolus Reference Manual,,,,,,,,
John Leonard,"Whelan, Thomas; Johannsson, Hordur; Kaess, Michael; Leonard, John J.; McDonald, John",Marine Robotics,2012-09-25T16:00:05Z,2012-09-25T16:00:05Z,2012-09-17,http://hdl.handle.net/1721.1/73167,"This paper describes extensions to the Kintinuous algorithm for spatially extended KinectFusion, incorporating the following additions: (i) the integration of multiple 6DOF camera odometry estimation methods for robust tracking; (ii) a novel GPU-based implementation of an existing dense RGB-D visual odometry algorithm; (iii) advanced fused real-time surface coloring. These extensions are validated with extensive experimental results, both quantitative and qualitative, demonstrating the ability to build dense fully colored models of spatially extended environments for robotics and virtual reality applications while remaining robust against scenes with challenging sets of geometric and visual features.",8 p.,MIT-CSAIL-TR-2012-031,,Robust Tracking for Real-Time Dense RGB-D Mapping with Kintinuous,,,,,,,,
Fredo Durand,"Gharbi, Michael; Malisiewicz, Tomasz; Paris, Sylvain; Durand, Frédo",Computer Graphics,2012-10-09T16:45:04Z,2012-10-09T16:45:04Z,2012-10-01,http://hdl.handle.net/1721.1/73685,"We introduce a fast technique for the robust computation of image similarity. It builds on a re-interpretation of the recent exemplar-based SVM approach, where a linear SVM is trained at a query point and distance is computed as the dot product with the normal to the separating hyperplane. Although exemplar-based SVM is slow because it requires a new training for each exemplar, the latter approach has shown robustness for image retrieval and object classification, yielding state-of- the-art performance on the PASCAL VOC 2007 detection task despite its simplicity. We re-interpret it by viewing the SVM between a single point and the set of negative examples as the computation of the tangent to the manifold of images at the query. We show that, in a high-dimensional space such as that of image features, all points tend to lie at the periphery and that they are usually separable from the rest of the set. We then use a simple Gaussian approximation to the set of all images in feature space, and fit it by computing the covariance matrix on a large training set. Given the covariance matrix, the computation of the tangent or normal at a point is straightforward and is a simple multiplication by the inverse covariance. This allows us to dramatically speed up image retrieval tasks, going from more than ten minutes to a single second. We further show that our approach is equivalent to feature-space whitening and has links to image saliency.",11 p.,MIT-CSAIL-TR-2012-032,"Image retrieval, object detection, computer vision, parametric model",A Gaussian Approximation of Feature Space for Fast Image Similarity,,,,,,,,
Brian Williams,"Levine, Steven J.",Model-based Embedded and Robotic Systems,2012-10-09T16:45:14Z,2012-10-09T16:45:14Z,2012-10-04,http://hdl.handle.net/1721.1/73686,"To achieve robustness in dynamic and uncertain environments, robotic systems must monitor the progress of their plans during execution. This thesis develops a plan executive called Pike that is capable of executing and monitoring plans. The execution monitor at its core quickly and efficiently detects relevant disturbances that threaten future actions in the plan. We present a set of novel offline algorithms that extract sets of candidate causal links from temporally-flexible plans. A second set of algorithms uses these causal links to monitor the execution online and detect problems with low latency. We additionally introduce the TBurton executive, a system capable of robustly meeting a user s high-level goals through the combined use of Pike and a temporal generative planner. An innovative voice-commanded robot is demonstrated in hardware and simulation that robustly meets high level goals and verbalizes any causes of failure using the execution monitor",125 p.,MIT-CSAIL-TR-2012-033,temporal plan; execution monitoring; causal link; disturbance; executive,Monitoring the Execution of Temporal Plans for Robotic Systems,Creative Commons Attribution 3.0 Unported,http://creativecommons.org/licenses/by/3.0/,,MEng thesis,,,,
Fredo Durand,"Levin, Anat; Nadler, Boaz; Durand, Fredo; Freeman, William T.",Computer Graphics,2012-07-31T17:45:08Z,2012-07-31T17:45:08Z,2012-10-07,http://hdl.handle.net/1721.1/71919,"Image restoration tasks are ill-posed problems, typically solved withpriors. Since the optimal prior is the exact unknown density of natural images,actual priors are only approximate and typically restricted to small patches. Thisraises several questions: How much may we hope to improve current restorationresults with future sophisticated algorithms? And more fundamentally, even withperfect knowledge of natural image statistics, what is the inherent ambiguity ofthe problem? In addition, since most current methods are limited to finite supportpatches or kernels, what is the relation between the patch complexity of naturalimages, patch size, and restoration errors? Focusing on image denoising, we makeseveral contributions. First, in light of computational constraints, we study the relation between denoising gain and sample size requirements in a non parametricapproach. We present a law of diminishing return, namely that with increasingpatch size, rare patches not only require a much larger dataset, but also gain littlefrom it. This result suggests novel adaptive variable-sized patch schemes for denoising. Second, we study absolute denoising limits, regardless of the algorithmused, and the converge rate to them as a function of patch size. Scale invarianceof natural images plays a key role here and implies both a strictly positive lowerbound on denoising and a power law convergence. Extrapolating this parametriclaw gives a ballpark estimate of the best achievable denoising, suggesting thatsome improvement, although modest, is still possible.",23 p.,MIT-CSAIL-TR-2012-022,,"Patch complexity, finite pixel correlations and optimal denoising",Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,,,,supplemental material for conference paper at ECCV 2012 (European Conf. on Computer Vision),,
Fredo Durand,"Belcour, Laurent; Soler, Cyril; Subr, Kartic; Holzschuch, Nicolas; Durand, Fredo",Computer Graphics,2012-11-16T18:00:09Z,2012-11-16T18:00:09Z,2012-11-16,http://hdl.handle.net/1721.1/74662,"The rendering of effects such as motion blur and depth-of-field requires costly 5D integrals. We dramatically accelerate their computation through adaptive sampling and reconstruction based on the prediction of the anisotropy and bandwidth of the integrand. For this, we develop a new frequency analysis of the 5D temporal light-field, and show that first-order motion can be handled through simple changes of coordinates in 5D. We further introduce a compact representation of the spectrum using the co- variance matrix and Gaussian approximations. We derive update equations for the 5 × 5 covariance matrices for each atomic light transport event, such as transport, occlusion, BRDF, texture, lens, and motion. The focus on atomic operations makes our work general, and removes the need for special-case formulas. We present a new rendering algorithm that computes 5D covariance matrices on the image plane by tracing paths through the scene, focusing on the single-bounce case. This allows us to reduce sampling rates when appropriate and perform reconstruction of images with complex depth-of-field and motion blur effects.",19 p.,MIT-CSAIL-TR-2012-034,Rendering; Computer Graphics; Fourier,5D Covariance Tracing for Efficient Defocus and Motion Blur,,,,,,,Fredo Durand,
Tomaso Poggio,"Poggio, Tomaso; Mutch, Jim; Leibo, Joel; Rosasco, Lorenzo; Tacchetti, Andrea",Center for Biological and Computational Learning (CBCL),2013-01-10T21:15:06Z,2013-01-10T21:15:06Z,2012-12-29,http://hdl.handle.net/1721.1/76248,"This paper explores the theoretical consequences of a simple assumption: the computational goal of the feedforward path in the ventral stream -- from V1, V2, V4 and to IT -- is to discount image transformations, after learning them during development.",120 p.,MIT-CSAIL-TR-2012-035,visual cortex; ventral stream; symmetries principles in sensory perception; visual recognition; invariances of sensory perception; learning to learn invariants in the visual world,The computational magic of the ventral stream: sketch of a theory (and why some deep architectures work).,Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,,,,,,
Dina Katabi,"Wang, Jue; Hassanieh, Haitham; Katabi, Dina; Kohno, Tadayoshi",Networks & Mobile Systems,2013-01-14T17:00:03Z,2013-01-14T17:00:03Z,2013-01-12,http://hdl.handle.net/1721.1/76260,"RFID cards are widely used today in sensitive applications such as access control, payment systems, and asset tracking. Past work shows that an eavesdropper snooping on the communication between a card and its legitimate reader can break their cryptographic protocol and obtain their secret keys. One solution for this problem is to install stronger cryptographic protocols on the cards. However, RFIDs' size, power, and cost limitations do not allow for conventional cryptographic protocols. Further, installing new protocols requires revoking billions of cards in consumers  hands and facilities worldwide, which is costly and impractical. In this paper, we ask whether one can secure RFIDs from such attacks without revoking or changing the insecure cards. We propose LocRF, a solution that changes the signal used to read the RFID cards but does not require any changes to the cards themselves. LocRF introduces a new approach that randomizes the modulation of the RFID signal as well as the wireless channel. This design protects RFIDs from eavesdroppers even if they use multi-antenna MIMO receivers. We built a prototype of LocRF on software-defined radios and used it to secure the communication of off-the-shelf cards. Both our analysis and empirical evaluation demonstrate theeffectiveness of LocRF.",15 p.,MIT-CSAIL-TR-2013-001,,Securing Deployed RFIDs by Randomizing the Modulation and the Channel,,,,,,,,
Brian Williams,"Yu, Peng",Model-based Embedded and Robotic Systems,2018-01-31T00:01:21Z,2018-01-31T00:01:21Z,2013-01-25,http://hdl.handle.net/1721.1/113372,"When humans fail to understand the capabilities of an autonomous system or its environmental limitations, they can jeopardize their objectives and the system by asking for unrealistic goals. The objective of this thesis is to enable consensus between human and autonomous system, by giving autonomous systems the ability to communicate to the user the reasons for goal failure and the relaxations to goals that archive feasibility. We represent our problem in the context of over-constrained temporal plans. They are commonly encountered while operating autonomous and decision support systems, when user objectives are in conflict with the environment. Over constrained plans are addressed by relaxing goals and or constraints, such as delaying the arrival time of a trip, with some candidate relaxations being preferable to others. In this thesis we present Uhura, a temporal plan diagnosis and relaxation algorithm that is designed to take over-constrained input plans with temporal flexibility and contingencies, and generate temporal relaxations that make the input plan executable. We introduce two innovative approaches within Uhura: collaborative plan diagnosis and continuous relaxation. Uhura focuses on novel ways of satisfying three goals to make the plan relaxation process more convenient for the users: small perturbation, quick response and simple interaction. We have incorporated Uhura within an autonomous executive that collaborates with human operators to resolve over-constrained temporal plans. Its effectiveness has been demonstrated both in simulation and in hardware on a Personal Transportation System concept. We believe that Uhura's collaborative temporal plan diagnosis capability can benefit a wide range of applications, both within industrial applications and in our daily lives.",168 p.,MIT-CSAIL-TR-2018-012,Over-constrained temporal plan; Plan diagnosis; Mixed initiative planning,continuous Relaxation to Over-constrained Temporal Plans,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,,SM thesis,2018-01-31T00:01:21Z,,,
Nancy Lynch,"Cornejo, Alejandro; Lynch, Nancy; Sastry, Srikanth",Theory of Computation,2013-02-01T20:00:04Z,2013-02-01T20:00:04Z,2013-01-30,http://hdl.handle.net/1721.1/76716,"Failure detectors -- oracles that provide information about process crashes -- are an important abstraction for crash tolerance in distributed systems. The generality of failure-detector theory, while providing great expressiveness, poses significant challenges in developing a robust hierarchy of failure detectors. We address some of these challenges by proposing (1) a variant of failure detectors called asynchronous failure detectors and (2) an associated modeling framework. Unlike the traditional failure-detector framework, our framework eschews real-time completely. We show that asynchronous failure detectors are sufficiently expressive to include several popular failure detectors including, but not limited to, the canonical Chandra-Toueg failure detectors, Sigma and other quorum failure detectors, Omega, anti-Omega, Omega^k, and Psi_k. Additionally, asynchronous failure detectors satisfy many desirable properties: they are self-implementable, guarantee that stronger asynchronous failure-detectors solve harder problems, and ensure that their outputs encode no information other than the set of crashed processes. We introduce the notion of a failure detector being representative for a problem to capture the idea that some problems encode the same information about process crashes as their weakest failure detectors do. We show that a large class of problems, called bounded problems, do not have representative failure detectors. Finally, we use the asynchronous failure-detector framework to show how sufficiently strong AFDs circumvent the impossibility of consensus in asynchronous systems.",46 p.,MIT-CSAIL-TR-2013-002,"Asynchronous System, Fault-Tolerance, I/O Automata",Asynchronous Failure Detectors,,,,This report is superseded by MIT-CSAIL-TR-2013-025.,,,,http://hdl.handle.net/1721.1/81371
Brian Williams,"Wang, Andrew J.",Model-based Embedded and Robotic Systems,2018-01-31T00:01:19Z,2018-01-31T00:01:19Z,2013-01-31,http://hdl.handle.net/1721.1/113371,"Temporal uncertainty arises when performing any activity in the natural world. When activities are composed into temporal plans, then, there is a risk of not meeting the plan requirements. Currently, we do not have quantitatively precise methods for assessing temporal risk of a plan. Existing methods that deal with temporal uncertainty either forgo probabilistic models or try to optimize a single objective, rather than satisfy multiple objectives. This thesis offers a method for evaluating whether a schedule exists that meets a set of temporal constraints, with acceptable risk of failure. Our key insight is to assume a form of risk allocation to each source of temporal uncertainty in our plan, such that we may reformulate the probabilistic plan into an STNU parameterized on the risk allocation. We show that the problem becomes a deterministic one of finding a risk allocation which implies a schedulable STNU within acceptable risk. By leveraging the principles behind STNU analysis, we derive conditions which encode this problem as a convex feasibility program over risk allocations. Furthermore, these conditions may be learned incrementally as temporal conflicts. Thus, to boost computational efficiency, we employ a generate-and-test approach to determine whether a schedule may be found.",64 p.,MIT-CSAIL-TR-2018-011,,Risk Allocation for Temporal Risk Assessment,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,,MEng thesis,2018-01-31T00:01:19Z,,,
Hari Balakrishnan,"LaCurts, Katrina; Deng, Shuo; Balakrishnan, Hari",Networks & Mobile Systems,2013-02-28T17:15:10Z,2013-02-28T17:15:10Z,2013-02-12,http://hdl.handle.net/1721.1/77238,"A significant and growing number of applications deployed on cloud infrastructures are network-intensive. These applications are frequently bottlenecked by the speed of network connections between the machines on which they are deployed. Due to the complexity and size of cloud networks, such applications often run slowly or have unpredictable completion times and/or throughput, both of which can result in increased cost to the customer. In this paper, we argue that cloud customers should be able to express the demands and objectives of their applications. We outline an architecture that allows for this type of expression, and distributes applications within the cloud network such that the application's objectives are met. We discuss some of the key questions that need to be addressed to implement the architecture, as well as the interactions between optimizations done by clients and by cloud providers. We also present preliminary results that indicate that these types of systems are feasible and improve performance.",7 p.,MIT-CSAIL-TR-2013-003,,A Plan for Optimizing Network-Intensive Cloud Applications,Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,,,,,,
Tomaso Poggio,"Tan, Cheston; Poggio, Tomaso",Center for Biological and Computational Learning (CBCL),2013-03-18T22:45:05Z,2013-03-18T22:45:05Z,2013-03-18,http://hdl.handle.net/1721.1/77936,"Visual recognition is an important ability that is central to many everyday tasks such as reading, navigation and social interaction, and is therefore actively studied in neuroscience, cognitive psychology and artificial intelligence. There exist thousands of object categories, all of which pose similar challenges to biological and artificial visual systems: accurate recognition under varying location, scale, view angle, illumination and clutter. In many areas of science, important discoveries have been made using ""model organisms"" such as fruit flies, mice and macaques. For the thousands of object categories, the important and well-studied category of faces could potentially serve as a ""model category"" upon which efforts are focused, and from which fundamental insights are drawn. However, it has been hotly debated whether faces are processed by the brain in a manner fundamentally different from other categories. Here we show that ""neural tuning size"" -- a single parameter in a computational model of object processing -- is able to account for important face-specific phenomena. Thus, surprisingly, ""face-like"" processing is explainable by physiological mechanisms that differ only quantitatively from ""object-like"" processing. Our computational proof-of-principle provides specific neural tuning properties that correspond to the so-far qualitative and controversial notion of ""holistic"" face processing. Overall, faces may be a viable model category. Since faces are highly amenable to complementary experimental techniques like functional MRI, electrophysiology, electroencephalography and transcranial magnetic stimulation, this further raises the odds that the algorithms and neural circuits underlying visual recognition may first be solved for faces. With faces serving as a model category, the great scientific challenge of understanding and reverse-engineering general visual recognition can be greatly accelerated.",19 p.,MIT-CSAIL-TR-2013-004; CBCL-311,face recognition; object recognition; holistic processing; composite effect; inversion effect,"Faces as a ""Model Category"" for Visual Object Recognition",,,,,,,,
