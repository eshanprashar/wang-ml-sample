dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.title,dc.subject
"Lynch, Nancy; Stoica, Ion",Theory of Computation,2005-12-22T01:19:39Z,2005-12-22T01:19:39Z,2004-02-19,MIT-CSAIL-TR-2004-007; MIT-LCS-TR-936,http://hdl.handle.net/1721.1/30448,"MultiChord is a new variant of the Chord namespace management algorithm [7] that includes lightweight mechanismsfor accommodating a limited rate of change, specifically, process joins and failures. This paper describes thealgorithm formally and evaluates its performance, using both simulation and analysis. Our main result is that lookupsare provably correctÂ—that is, each lookup returns results that are consistent with a hypothetical ideal system that differsfrom the actual system only in entries corresponding to recent joins and failuresÂ—in the presence of a limited rateof change. In particular, if the number of joins and failures that occur during a given time interval in a given regionof system are bounded, then all lookups are correct. A second result is a guaranteed upper bound for the latency of alookup operation in the absence of any other lookups in the system. Finally, we establish a relationship between thedeterministic assumptions of bounded joins and failures and the probabilistic assumptions (which are often used tomodel large scale networks). In particular, we derive a lower bound for the mean time between two violations of thedeterministic assumptions in a steady state system where joins and failures are modeled by Poisson processes.",32 p.; 40331651 bytes; 1860288 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,MultiChord: A Resilient Namespace Management Protocol,
"Dolev, Shlomi; Gilbert, Seth; Lynch, Nancy A.; Shvartsman, Alex A.; Welch, Jennifer L.",Theory of Computation,2005-12-22T01:19:48Z,2005-12-22T01:19:48Z,2004-02-25,MIT-CSAIL-TR-2004-008; MIT-LCS-TR-900a,http://hdl.handle.net/1721.1/30449,"We present a new approach, the GeoQuorums approach, for implementing atomic read/write shared memoryin mobile ad hoc networks. Our approach is based on associating abstract atomic objects with certain geographiclocations. We assume the existence of focal points, geographic areas that are normally Â“populatedÂ” by mobile nodes.For example, a focal point may be a road junction, a scenic observation point, or a water resource in the desert. Mobilenodes that happen to populate a focal point participate in implementing a shared atomic object, using a replicated statemachine approach. These objects, which we call focal point objects, are then used to implement atomic read/writeoperations on a virtual shared object, using our new GeoQuorums algorithm. The GeoQuorums algorithm uses aquorum-based strategy in which each each quorum consists of a set of focal point objects. The quorums are used tomaintain the consistency of the shared memory and to tolerate limited failures of the focal point objects, caused bydepopulation of the corresponding geographic areas. We present a mechanism for changing the set of quorums onthe fly, thus improving efficiency. Overall, the new GeoQuorums algorithm efficiently implements read and writeoperations in a highly dynamic, mobile network.",43 p.; 54380882 bytes; 2282502 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,GeoQuorums: Implementing Atomic Memory in Mobile Ad Hoc Networks,
"Dolev, Shlomi; Gilbert, Seth; Lynch, Nancy A.; Schiller, Elad; Shvarstman, Alex A.; Welch, Jennifer",Theory of Computation,2005-12-22T01:19:54Z,2005-12-22T01:19:54Z,2004-02-26,MIT-CSAIL-TR-2004-009; MIT-LCS-TR-937,http://hdl.handle.net/1721.1/30450,"One of the most significant challenges introduced by mobile networks is the difficulty in coping withthe unpredictable movement of mobile nodes. If, instead, the mobile nodes could be programmed totravel through the world in a predictable and useful manner, the task of designing algorithms for mobilenetworks would be significantly simplified. Alas, users of mobile devices in the real world are notamenable to following instructions as to where their devices may travel.While real mobile nodes may be disinclined to move as desired, we propose executing algorithmson virtual mobile nodes that move in a predetermined, predictable, manner through the real world. Inthis paper, we define the Virtual Mobile Node Abstraction, and present selected algorithms that takeadvantage of virtual mobile nodes to simply and efficiently perform complicated tasks in highly dynamic,unpredictable mobile ad hoc networks.We then present the Mobile Point Emulator, a new algorithm that implements robust virtual mobilenodes. This algorithm replicates the virtual node at a constantly changing set of real nodes, choosingnew replicas as the real nodes move in and out of the path of the virtual node. We claim that the MobilePoint algorithm correctly implements a virtual mobile node, and that it is robust as long as the virtualnode travels through well-populated areas of the network.",17 p.; 21915881 bytes; 913204 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Virtual Mobile Nodes for Mobile Ad Hoc Networks,
Riesenhuber; Jarudi; Gilad; Sinha,,2005-12-22T01:20:02Z,2005-12-22T01:20:02Z,2004-03-05,MIT-CSAIL-TR-2004-010; AIM-2004-006; CBCL-236,http://hdl.handle.net/1721.1/30451,"Understanding how the human visual system recognizes objects is one of the key challenges in neuroscience. Inspired by a large body of physiological evidence (Felleman and Van Essen, 1991; Hubel and Wiesel, 1962; Livingstone and Hubel, 1988; Tso et al., 2001; Zeki, 1993), a general class of recognition models has emerged which is based on a hierarchical organization of visual processing, with succeeding stages being sensitive to image features of increasing complexity (Hummel and Biederman, 1992; Riesenhuber and Poggio, 1999; Selfridge, 1959). However, these models appear to be incompatible with some well-known psychophysical results. Prominent among these are experiments investigating recognition impairments caused by vertical inversion of images, especially those of faces. It has been reported that faces that differ Â“featurallyÂ” are much easier to distinguish when inverted than those that differ Â“configurallyÂ” (Freire et al., 2000; Le Grand et al., 2001; Mondloch et al., 2002) Â– a finding that is difficult to reconcile with the aforementioned models. Here we show that after controlling for subjectsÂ’ expectations, there is no difference between Â“featurallyÂ” and Â“configurallyÂ” transformed faces in terms of inversion effect. This result reinforces the plausibility of simple hierarchical models of object representation and recognition in cortex.",12 p.; 14255528 bytes; 840975 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Face processing in humans is compatible with a simple shape-based model of vision,AI; object recognition; faces; psychophysics; inversion effect; neuroscience; comput
Riesenhuber; Jarudi; Gilad; Sinha,,2004-10-20T21:05:22Z,2004-10-20T21:05:22Z,2004-03-05,AIM-2004-006; CBCL-236,http://hdl.handle.net/1721.1/7283,"Understanding how the human visual system recognizes objects is one of the key challenges in neuroscience. Inspired by a large body of physiological evidence (Felleman and Van Essen, 1991; Hubel and Wiesel, 1962; Livingstone and Hubel, 1988; Tso et al., 2001; Zeki, 1993), a general class of recognition models has emerged which is based on a hierarchical organization of visual processing, with succeeding stages being sensitive to image features of increasing complexity (Hummel and Biederman, 1992; Riesenhuber and Poggio, 1999; Selfridge, 1959). However, these models appear to be incompatible with some well-known psychophysical results. Prominent among these are experiments investigating recognition impairments caused by vertical inversion of images, especially those of faces. It has been reported that faces that differ ""featurally"" are much easier to distinguish when inverted than those that differ ""configurally"" (Freire et al., 2000; Le Grand et al., 2001; Mondloch et al., 2002) ??finding that is difficult to reconcile with the aforementioned models. Here we show that after controlling for subjects' expectations, there is no difference between ""featurally"" and ""configurally"" transformed faces in terms of inversion effect. This result reinforces the plausibility of simple hierarchical models of object representation and recognition in cortex.",12 p.; 1595221 bytes; 690861 bytes,application/postscript; application/pdf,en_US,AIM-2004-006; CBCL-236,Face processing in humans is compatible with a simple shape-based model of vision,AI; object recognition; faces; psychophysics; inversion effect; neuroscience; comput
"Abadi, Daniel J.; Madden, Samuel R.",,2005-12-22T01:20:12Z,2005-12-22T01:20:12Z,2004-03-22,MIT-CSAIL-TR-2004-011; MIT-LCS-TR-939,http://hdl.handle.net/1721.1/30452,"This paper presents an algorithm for handling many types of filters insensor networks that cannot be expressed using a simple predicate.Specifically, the action of the filter may be predicated on sensor produceddata where an entire table of sensor-data/result-value pairs are needed toresolve the filter. We describe and evaluate three algorithms that canperform these filters that take advantage of database distributed jointechniques. Our join-based algorithms are capable of running in verylimited amounts of RAM, can distribute the storage burden over groups ofnodes, and are tolerant to dropped packets and node failures. REED isthus suitable for a wide range of event-detection applications thattraditional sensor network database and data collection systems cannot beused to implement.",14 p.; 29691355 bytes; 1109049 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"REED: Robust, Efficient Filtering and Event Detection in Sensor Networks",
"Stephenson, Mark; Amarasinghe, Saman",,2005-12-22T01:20:19Z,2005-12-22T01:20:19Z,2004-03-22,MIT-CSAIL-TR-2004-012; MIT-LCS-TR-938,http://hdl.handle.net/1721.1/30453,"In order to deliver the promise of MooreÂ’s Law to the enduser, compilers must make decisions that are intimately tiedto a specific target architecture. As engineers add architecturalfeatures to increase performance, systems becomeharder to model, and thus, it becomes harder for a compilerto make effective decisions.Machine-learning techniques may be able to help compilerwriters model modern architectures. Because learning techniquescan effectively make sense of high dimensional spaces,they can be a valuable tool for clarifying and discerningcomplex decision boundaries. In our work we focus on loopunrolling, a well-known optimization for exposing instructionlevel parallelism. Using the Open Research Compileras a testbed, we demonstrate how one can use supervisedlearning techniques to model the appropriateness of loopunrolling.We use more than 1,100 loops Â— drawn from 46 benchmarksÂ— to train a simple learning algorithm to recognizewhen loop unrolling is advantageous. The resulting classifiercan predict with 88% accuracy whether a novel loop(i.e., one that was not in the training set) benefits fromloop unrolling. Furthermore, we can predict the optimal ornearly optimal unroll factor 74% of the time. We evaluatethe ramifications of these prediction accuracies using theOpen Research Compiler (ORC) and the Itanium r  2 architecture.The learned classifier yields a 6% speedup (overORCÂ’s unrolling heuristic) for SPEC benchmarks, and a 7%speedup on the remainder of our benchmarks. Because thelearning techniques we employ run very quickly, we wereable to exhaustively determine the four most salient loopcharacteristics for determining when unrolling is beneficial.",9 p.; 15158625 bytes; 629381 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Predicting Unroll Factors Using Nearest Neighbors,
"Yokono, Jerry Jun; Poggio, Tomaso",,2005-12-22T01:25:52Z,2005-12-22T01:25:52Z,2004-03-24,MIT-CSAIL-TR-2004-013; AIM-2004-007; CBCL-237,http://hdl.handle.net/1721.1/30454,"Local descriptors are increasingly used for the task of object recognition because of their perceived robustness with respect to occlusions and to global geometrical deformations. We propose a performance criterion for a local descriptor  based on the tradeoff between selectivity and invariance. In this paper, we evaluate several local descriptors with respect to selectivity and invariance. The descriptors that we evaluated are Gaussian derivatives up to the third order, gray image patches, and Laplacian-based descriptors with either three scales or one scale filters. We compare selectivity and invariance to several affine changes such as rotation, scale, brightness, and viewpoint. Comparisons have been made keeping the dimensionality of the descriptors roughly constant. The overall results indicate a good performance by the descriptor based on a set of oriented Gaussian filters. It is interesting that oriented receptive fields similar to the Gaussian derivatives as well as receptive fields similar to the Laplacian are found in primate visual cortex.",20 p.; 86081886 bytes; 22425671 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Evaluation of sets of oriented and non-oriented receptive fields as local descriptors,"AI; local descriptor; steerable filter; Gaussian derivatives; selectivity,invariance"
"Yokono, Jerry Jun; Poggio, Tomaso",,2004-10-20T21:05:24Z,2004-10-20T21:05:24Z,2004-03-24,AIM-2004-007; CBCL-237,http://hdl.handle.net/1721.1/7284,"Local descriptors are increasingly used for the task of object recognition because of their perceived robustness with respect to occlusions and to global geometrical deformations. We propose a performance criterion for a local descriptor based on the tradeoff between selectivity and invariance. In this paper, we evaluate several local descriptors with respect to selectivity and invariance. The descriptors that we evaluated are Gaussian derivatives up to the third order, gray image patches, and Laplacian-based descriptors with either three scales or one scale filters. We compare selectivity and invariance to several affine changes such as rotation, scale, brightness, and viewpoint. Comparisons have been made keeping the dimensionality of the descriptors roughly constant. The overall results indicate a good performance by the descriptor based on a set of oriented Gaussian filters. It is interesting that oriented receptive fields similar to the Gaussian derivatives as well as receptive fields similar to the Laplacian are found in primate visual cortex.",20 p.; 3426196 bytes; 1925439 bytes,application/postscript; application/pdf,en_US,AIM-2004-007; CBCL-237,Evaluation of sets of oriented and non-oriented receptive fields as local descriptors,AI; local descriptor; steerable filter; Gaussian derivatives; selectivity; invariance
"Donovan, Alan; Kiezun, Adam; Tschantz, Matthew S.; Ernst, Michael D.",Program Analysis,2005-12-22T01:26:03Z,2005-12-22T01:26:03Z,2004-03-30,MIT-CSAIL-TR-2004-015; MIT-LCS-TR-940,http://hdl.handle.net/1721.1/30456,"Java 1.5 will include a type system (called JSR-14) that supports parametric polymorphism, or generic classes. This will bring many benefits to Java programmers, not least because current Java practice makes heavy use of logically-generic classes, including container classes.Translation of Java source code into semantically equivalent JSR-14 source code requires two steps: parameterization (adding type parameters to class definitions) and instantiation (adding the type arguments at each use of a parameterized class). Parameterization need be done only once for a class, whereas instantiation must be performed for each client, of which there are potentially many more. Therefore, this work focuses on the instantiation problem. We present a technique to determine sound and precise JSR-14 types at each use of a class for which a generic type specification is available. Our approach uses a precise and context-sensitive pointer analysis to determine possible types at allocation sites, and a set-constraint-based analysis (that incorporates guarded, or conditional, constraints) to choose consistent types for both allocation and declaration sites. The technique handles all features of the JSR-14 type system, notably the raw types that provide backward compatibility. We have implemented our analysis in a tool that automatically inserts type parameters into Java code, and we report its performance when applied to a number of real-world Java programs.",20 p.; 39929459 bytes; 1693357 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Converting Java Programs to Use Generic Libraries,
"McCamant, Stephen; Ernst, Michael D.",Program Analysis,2005-12-22T01:25:58Z,2005-12-22T01:25:58Z,2004-03-30,MIT-CSAIL-TR-2004-014; MIT-LCS-TR-941,http://hdl.handle.net/1721.1/30455,"This report presents a new, automatic technique to assess whether replacing a component of a softwaresystem by a purportedly compatible component may change the behavior of the system. The techniqueoperates before integrating the new component into the system or running system tests, permitting quickerand cheaper identification of problems. It takes into account the systemÂ’s use of the component, becausea particular component upgrade may be desirable in one context but undesirable in another. No formalspecifications are required, permitting detection of problems due either to errors in the component or toerrors in the system. Both external and internal behaviors can be compared, enabling detection of problemsthat are not immediately reflected in the output.The technique generates an operational abstraction for the old component in the context of the system,and one for the new component in the context of its test suite. An operational abstraction is a set of programproperties that generalizes over observed run-time behavior. Modeling a system as divided into modules,and taking into account the control and data flow between the modules, we formulate a logical conditionto guarantee that the systemÂ’s behavior is preserved across a component replacement. If automated logicalcomparison indicates that the new component does not make all the guarantees that the old one did, thenthe upgrade may affect system behavior and should not be performed without further scrutiny.We describe a practical implementation of the technique, incorporating enhancements to handle nonlocalstate, non-determinism, and missing test suites, and to distinguish old from new incompatibilities. Weevaluate the implementation in case studies using real-world systems, including the Linux C library and 48Unix programs. Our implementation identified real incompatibilities among versions of the C library thataffected some of the programs, and it approved the upgrades for other programs that were unaffected by thechanges.This report is a revision of the first authorÂ’s MasterÂ’s thesis, submitted January 2004.",51 p.; 58257912 bytes; 2025302 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Predicting Problems Caused by Component Upgrades,
"Kuncak, Viktor; Rinard, Martin",Computer Architecture,2005-12-22T01:26:10Z,2005-12-22T01:26:10Z,2004-04-06,MIT-CSAIL-TR-2004-016; MIT-LCS-TR-942,http://hdl.handle.net/1721.1/30457,"We have previously introduced role logic as a notation fordescribing properties of relational structures in shapeanalysis, databases and knowledge bases.  A natural fragmentof role logic corresponds to two-variable logic withcounting and is therefore decidable.We show how to use role logic to describe open and closedrecords, as well the dual of records, inverse records.  Weobserve that the spatial conjunction operation of separationlogic naturally models record concatenation.  Moreover, weshow how to eliminate the spatial conjunction of formulas ofquantifier depth one in first-order logic with counting.  Asa result, allowing spatial conjunction of formulas ofquantifier depth one preserves the decidability oftwo-variable logic with counting.  This result applies totwo-variable role logic fragment as well.The resulting logic smoothly integrates type system andpredicate calculus notation and can be viewed as a naturalgeneralization of the notation for constraints arising inrole analysis and similar shape analysis approaches.",30 p.; 29046951 bytes; 1214158 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,On Generalized Records and Spatial Conjunction in Role Logic,
"Georgiou, Chryssis; Musial, Peter M.; Shvartsman, Alexander A.",Theory of Computation,2005-12-22T01:26:16Z,2005-12-22T01:26:16Z,2004-04-12,MIT-CSAIL-TR-2004-017; MIT-LCS-TR-943,http://hdl.handle.net/1721.1/30458,"Shareable data services providing consistency guarantees, such as atomicity (linearizability), make building distributedsystems easier. However, combining linearizability with efficiency in practical algorithms is difficult. A reconfigurablelinearizable data service, called Rambo, was developed by Lynch and Shvartsman. This service guarantees consistencyunder dynamic conditions involving asynchrony, message loss, node crashes, and new node arrivals. The specificationof the original algorithm is given at an abstract level aimed at concise presentation and formal reasoning aboutcorrectness. The algorithm propagates information by means of gossip messages. If the service is in use for along time, the size and the number of gossip messages may grow without bound. This paper presents a consistentdata service for long-lived objects that improves on Rambo in two ways: it includes an incremental communicationprotocol and a leave service. The new protocol takes advantage of the local knowledge, and carefully manages thesize of messages by removing redundant information, while the leave service allows the nodes to leave the systemgracefully. The new algorithm is formally proved correct by forward simulation using levels of abstraction. Anexperimental implementation of the system was developed for networks-of-workstations. The paper also includesselected analytical and preliminary empirical results that illustrate the advantages of the new algorithm.",28 p.; 36030589 bytes; 1489589 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Long-Lived Rambo: Trading Knowledge for Communication,
"Wentzlaff, David; Agarwal, Anant",Computer Architecture,2005-12-22T01:26:26Z,2005-12-22T01:26:26Z,2004-04-13,MIT-CSAIL-TR-2004-018; MIT-LCS-TR-944,http://hdl.handle.net/1721.1/30459,"General purpose computing architectures are being called on to work on amore diverse application mix every day.  This has been fueled by the needfor reduced time to market and economies of scale that are the hallmarksof software on general purpose microprocessors.  As this application mixexpands, application domains such as bit-level computation, which hasprimarily been the domain of ASICs and FPGAs, will need to be effectivelyhandled by general purpose hardware.  Examples of bit-level applicationsinclude Ethernet framing, forward error correction encoding/decoding, andefficient state machine implementation.In this paper we compare how differing computational structures such asASICs, FPGAs, tiled architectures, and superscalar microprocessors areable to compete on bit-level communication applications.  A quantitativecomparison in terms of absolute performance and performance per area willbe presented.  These results show that although modest gains~(2-3x) inabsolute performance can be achieved when using FPGAs versus tunedmicroprocessor implementations, it is the significantly larger gains~(2-3orders of magnitude) that can be achieved in performance per area thatwill motivate work on supporting bit-level computation in a generalpurpose fashion in the future.",11 p.; 16819251 bytes; 664884 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"A Quantitative Comparison of Reconfigurable, Tiled, and Conventional Architectures on Bit-level Computation",
"Torralba, Antonio",,2004-10-08T20:43:12Z,2004-10-08T20:43:12Z,2004-04-14,AIM-2004-009,http://hdl.handle.net/1721.1/6737,"This article describes a model for including scene/context priors in attention guidance. In the proposed scheme, visual context information can be available early in the visual processing chain, in order to modulate the saliency of image regions and to provide an efficient short cut for object detection and recognition. The scene is represented by means of a low-dimensional global description obtained from low-level features. The global scene features are then used to predict the probability of presence of the target object in the scene, and its location and scale, before exploring the image. Scene information can then be used to modulate the saliency of image regions early during the visual processing in order to provide an efficient short cut for object detection and recognition.",12 p.; 2980182 bytes; 1698158 bytes,application/postscript; application/pdf,en_US,AIM-2004-009,Contextual Influences on Saliency,AI; Attention; context; saliency; scene recognition; object detection
"Katti, Sachin; Katabi, Dina; Kohler, Eddie; Strauss, Jacob",Networks and Mobile Systems,2005-12-22T01:27:11Z,2005-12-22T01:27:11Z,2004-04-14,MIT-CSAIL-TR-2004-022; MIT-LCS-TR-945,http://hdl.handle.net/1721.1/30462,"This paper presents M&M, a passive measurement toolkitsuitable for large-scale studies of Internet path characteristics.The multiQ tool uses equally-spaced mode gaps in TCP flowsÂ’packet interarrival time distributions to detect multiple bottleneckcapacities and their relative order. Unlike previous tools,multiQ can discover up to three bottlenecks fromthe tcpdumptrace of a single flow, and can work with acknowledgment aswell as data interarrivals.We also describe the mystery tool, asimple TCP loss event, packet loss, and RTT analyzer designedto work in concert with multiQ. The M&M toolkit can measuresimple path properties; correlate different types of measurementof the same path, producing new kinds of results; andbecause M&M is passive, it can use publicly-available traces totrack the value of a measurement over multiple years.We validate our tools in depth using the RON overlay network[4], which provides more than 400 heterogeneous Internetpaths and detailed information about their characteristics.We compare multiQ with Nettimer and Pathrate, two othercapacity measurement tools, in the first wide-area, real-worldvalidation of capacity measurement techniques. Each tool accuratelydiscovers minimum capacities (85% of measurementsare within 10%of the true value); multiQ additionally discoversmultiple bottlenecks and their orderings. We also use ourtoolkit to perform several measurement studies using a reservoirof 375 million traced packets spanning the last two years.Among the results of these studies are that bottleneck capacityon our traced links has gone up by around an order ofmagnitudefrom 2002 to 2004, and that differences in levels of statisticalmultiplexing on 10 Mb/s and 100 Mb/s bottleneck links resultin flows over those links having similar fair-share bandwidths.",13 p.; 25499604 bytes; 1134347 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"M&M: A Passive Toolkit for Measuring, Correlating, and Tracking Path Characteristics",
"Torralba, Antonio; Murphy, Kevin P.; Freeman, William T.",,2004-10-08T20:43:10Z,2004-10-08T20:43:10Z,2004-04-14,AIM-2004-008,http://hdl.handle.net/1721.1/6736,"We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, at multiple locations and scales. This can be slow and can require a lot of training data, since each classifier requires the computation of many different image features. In particular, for independently trained detectors, the (run-time) computational complexity, and the (training-time) sample complexity, scales linearly with the number of classes to be detected. It seems unlikely that such an approach will scale up to allow recognition of hundreds or thousands of objects.  We present a multi-class boosting procedure (joint boosting) that reduces the computational and sample complexity, by finding common features that can be shared across the classes (and/or views). The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required, and therefore the computational cost, is observed to scale approximately logarithmically with the number of classes. The features selected jointly are closer to edges and generic features typical of many natural structures instead of finding specific object parts. Those generic features generalize better and reduce considerably the computational cost of an algorithm for multi-class object detection.",17 p.; 4223512 bytes; 1537371 bytes,application/postscript; application/pdf,en_US,AIM-2004-008,Sharing visual features for multiclass and multiview object detection,AI; Object detection; sharing features; feature selection; multiclass; Boosting
"Torralba, Antonio",,2005-12-22T01:26:54Z,2005-12-22T01:26:54Z,2004-04-14,MIT-CSAIL-TR-2004-020; AIM-2004-009,http://hdl.handle.net/1721.1/30460,"This article describes a model for including scene/context priors in attention guidance. In the proposed scheme, visual context information can be available early in the visual processing chain, in order to modulate the saliency of image regions and to provide an efficient short cut for object detection and recognition. The scene is represented by means of a low-dimensional global description obtained from low-level features. The global scene features are then used to predict the probability of presence of the target object in the scene, and its location and scale, before exploring the image. Scene information can then be used to modulate the saliency of image regions early during the visual processing in order to provide an efficient short cut for object detection and recognition.",12 p.; 18377938 bytes; 597436 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Contextual Influences on Saliency,AI; Attention; context; saliency; scene recognition; object detection
"Weinstein, Eugene; Steele, Kenneth; Agarwal, Anant; Glass, James",Computer Architecture,2005-12-22T01:27:05Z,2005-12-22T01:27:05Z,2004-04-14,MIT-CSAIL-TR-2004-021; MIT-LCS-TM-642,http://hdl.handle.net/1721.1/30461,"Ubiquitous computing environments are characterized by an unboundedamount of noise and crosstalk. In these environments, traditionalmethods of sound capture are insufficient, and array microphones areneeded in order to obtain a clean recording of desired speech. In thiswork, we have designed, implemented, and tested LOUD, a novel 1020-nodemicrophone array utilizing the Raw tile parallel processorarchitecture for computation. To the best of our knowledge,this is currently the largest microphone array in the world. We haveexplored the uses of the array within ubiquitous computing scenarios byimplementing an acoustic beamforming algorithm for sound sourceamplification in a noisy environment, and have obtained preliminaryresults demonstrating the efficacy of the array. From one to 1020microphones, we have shown a 13.7dB increase in peak SNR on arepresentative utterance, an 87.2% drop in word error rate withinterferer present, and an 89.6% drop in WER without an interferer.",18 p.; 26946578 bytes; 901671 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,A 1020-Node Modular Microphone Array and Beamformer for Intelligent Computing Spaces,
"Torralba, Antonio; Murphy, Kevin P.; Freeman, William T.",,2005-12-19T22:41:45Z,2005-12-19T22:41:45Z,2004-04-14,MIT-CSAIL-TR-2004-019; AIM-2004-008,http://hdl.handle.net/1721.1/30399,"We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, at multiple locations and scales. This can be slow and can require a lot of training data, since each classifier requires the computation of many different image features. In particular, for independently trained detectors, the (run-time) computational complexity, and the (training-time) sample complexity, scales linearly with the number of classes to be detected. It seems unlikely that such an approach will scale up to allow recognition of hundreds or thousands of objects.We present a multi-class boosting procedure (joint boosting) that reduces the computational and sample complexity, by finding common features that can be shared across the classes (and/or views). The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required, and therefore the computational cost, is observed to scale approximately logarithmically with the number of classes. The features selected jointly are closer to edges and generic features typical of many natural structures instead of finding specific object parts. Those generic features generalize better and reduce considerably the computational cost of an algorithm for multi-class object detection.",17 p.; 24172096 bytes; 1434721 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Sharing visual features for multiclass and multiview object detection,AI; Object detection; sharing features; feature selection; multiclass; Boosting
