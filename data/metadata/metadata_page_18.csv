dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.title,dc.subject,dc.contributor,dc.identifier.citation
"Taylor, Michael Bedford; Lee, Walter; Amarasinghe, Saman; Agarwal, Anant",Computer Architecture,2005-12-22T01:32:06Z,2005-12-22T01:32:06Z,2004-06-08,MIT-CSAIL-TR-2004-038; MIT-LCS-TM-645,http://hdl.handle.net/1721.1/30477,"The bypass paths and multiported register files in microprocessors serve as an implicit interconnect tocommunicate operand values among pipeline stages and multiple ALUs. Previous superscalar designs implementedthis interconnect using centralized structures that do not scale with increasing ILP demands. Insearch of scalability, recent microprocessor designs in industry and academia exhibit a trend toward distributedresources such as partitioned register files, banked caches, multiple independent compute pipelines,and even multiple program counters. Some of these partitioned microprocessor designs have begun to implementbypassing and operand transport using point-to-point interconnects. We call interconnects optimizedfor scalar data transport, whether centralized or distributed, scalar operand networks. Although thesenetworks share many of the challenges of multiprocessor networks such as scalability and deadlock avoidance,they have many unique requirements, including ultra-low latencies (a few cycles versus tens of cycles)and ultra-fast operation-operand matching. This paper discusses the unique properties of scalar operandnetworks (SONs), examines alternative ways of implementing them, and introduces the AsTrO taxonomy todistinguish between them. It discusses the design of two alternative networks in the context of the Raw microprocessor,and presents detailed timing, area and energy statistics for a real implementation. The paperalso presents a 5-tuple performance model for SONs and analyzes their performance sensitivity to networkproperties for ILP workloads.",27 p.; 60061887 bytes; 2516865 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"Scalar Operand Networks: Design, Implementation, and Analysis",,,
"Rabbah, Rodric M.; Bratt, Ian; Asanovic, Krste; Agarwal, Anant",Computer Architecture,2005-12-22T01:32:17Z,2005-12-22T01:32:17Z,2004-06-14,MIT-CSAIL-TR-2004-039; MIT-LCS-TM-646,http://hdl.handle.net/1721.1/30478,"For the last several decades, computer architecture research has largely benefited from, and continues to be driven by ad-hoc benchmarking. Often the benchmarks are selected to represent workloads that architects believe should run on the computational platforms they design. For example, benchmark suites such as SPEC, Winstone, and MediaBench, which represent workstation, desktop and media workloads respectively, have influenced computer architecture innovation for the last decade. Recently, advances in VLSI technology have created an increasing interest within the computer architecture community to build a new kind of processor that is more flexible than extant general purpose processors. Such new processor architectures must efficiently support a broad class of applications including graphics, networking, and signal processing in addition to the traditional desktop workloads. Thus, given the new focus on flexibility demands, a new benchmark suite and new metrics are necessary to accurately reflect the goals of the architecture community. This paper thus proposes VersaBench as a new benchmark suite, and a new Versatility measure to characterize architectural flexibility, or in other words, the ability of the architecture to effectively execute a wide array of workloads. The benchmark suite is composed of applications drawn from several domains including desktop, server, stream, and bit-level processing. The Versatility measure is a single scalar metric inspired by the SPEC paradigm. It normalizes processor performance on each benchmark by that of the highest-performing machine for that application. This paper reports the measured versatility for several existing processors, as well as for some new and emerging research processors. The benchmark suite is freely distributed, and we are actively cataloging and sharing results for various reference processors.",17 p.; 39574971 bytes; 2672127 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Versatility and VersaBench: A New Metric and a Benchmark Suite for Flexible Architectures,,,
"Hearn, Robert A.",,2005-12-22T01:34:55Z,2005-12-22T01:34:55Z,2004-06-16,MIT-CSAIL-TR-2004-040; AITR-2004-004,http://hdl.handle.net/1721.1/30479,"Most Artificial Intelligence (AI) work can be characterized as either ``high-level'' (e.g., logical, symbolic) or ``low-level'' (e.g., connectionist networks, behavior-based robotics). Each approach suffers from particular drawbacks. High-level AI uses abstractions that often have no relation to the way real, biological brains work. Low-level AI, on the other hand, tends to lack the powerful abstractions that are needed to express complex structures and relationships. I have tried to combine the best features of both approaches, by building a set of programming abstractions defined in terms of simple, biologically plausible components. At the ``ground level'', I define a primitive, perceptron-like computational unit. I then show how more abstract computational units may be implemented in terms of the primitive units, and show the utility of the abstract units in sample networks. The new units make it possible to build networks using concepts such as long-term memories, short-term memories, and frames. As a demonstration of these abstractions, I have implemented a simulator for ``creatures'' controlled by a network of abstract units. The creatures exist in a simple 2D world, and exhibit behaviors such as catching mobile prey and sorting colored blocks into matching boxes. This program demonstrates that it is possible to build systems that can interact effectively with a dynamic physical environment, yet use symbolic representations to control aspects of their behavior.",58 p.; 45433655 bytes; 1795607 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Building Grounded Abstractions for Artificial Intelligence Programming,AI; Artificial Intelligence; Society of Mind; Multi-Agent Systems,,
"Hearn, Robert A.",,2004-10-20T20:32:29Z,2004-10-20T20:32:29Z,2004-06-16,AITR-2004-004,http://hdl.handle.net/1721.1/7116,"Most Artificial Intelligence (AI) work can be characterized as either ``high-level'' (e.g., logical, symbolic)  or ``low-level'' (e.g., connectionist networks, behavior-based robotics). Each approach suffers from  particular drawbacks. High-level AI uses abstractions that often have no relation to the way real,  biological brains work. Low-level AI, on the other hand, tends to lack the powerful abstractions that are  needed to express complex structures and relationships. I have tried to combine the best features of  both approaches, by building a set of programming abstractions defined in terms of simple, biologically  plausible components. At the ``ground level'', I define a primitive, perceptron-like computational unit.  I then show how more abstract computational units may be implemented in terms of the primitive  units, and show the utility of the abstract units in sample networks. The new units make it possible to  build networks using concepts such as long-term memories, short-term memories, and frames. As a  demonstration of these abstractions, I have implemented a simulator for ``creatures'' controlled by a  network of abstract units. The creatures exist in a simple 2D world, and exhibit behaviors such as  catching mobile prey and sorting colored blocks into matching boxes. This program demonstrates that  it is possible to build systems that can interact effectively with a dynamic physical environment, yet use  symbolic representations to control aspects of their behavior.",58 p.; 330188 bytes; 26969 bytes,application/postscript; application/pdf,en_US,AITR-2004-004,Building Grounded Abstractions for Artificial Intelligence Programming,AI; Artificial Intelligence; Society of Mind; Multi-Agent Systems,,
"Teevan, Jaime",,2004-10-08T20:43:15Z,2004-10-08T20:43:15Z,2004-06-18,AIM-2004-012,http://hdl.handle.net/1721.1/6739,"This paper investigates how people return to information in a dynamic information environment. For example, a person might want to return to Web content via a link encountered earlier on a Web page, only to learn that the link has since been removed. Changes can benefit users by providing new information, but they hinder returning to previously viewed information. The observational study presented here analyzed instances, collected via a Web search, where people expressed difficulty re-finding information because of changes to the information or its environment. A number of interesting observations arose from this analysis, including that the path originally taken to get to the information target appeared important in its re-retrieval, whereas, surprisingly, the temporal aspects of when the information was seen before were not. While people expressed frustration when problems arose, an explanation of why the change had occurred was often sufficient to allay that frustration, even in the absence of a solution. The implications of these observations for systems that support re-finding in dynamic environments are discussed.",9 p.; 1451699 bytes; 688288 bytes,application/postscript; application/pdf,en_US,AIM-2004-012,How People Re-find Information When the Web Changes,AI; re-finding; information management; dynamic information,,
"Teevan, Jaime",,2005-12-22T01:35:01Z,2005-12-22T01:35:01Z,2004-06-18,MIT-CSAIL-TR-2004-041; AIM-2004-012,http://hdl.handle.net/1721.1/30480,"This paper investigates how people return to information in a dynamic information environment.  For example, a person might want to return to Web content via a link encountered earlier on a Web page, only to learn that the link has since been removed.  Changes can benefit users by providing new information, but they hinder returning to previously viewed information.  The observational study presented here analyzed instances, collected via a Web search, where people expressed difficulty re-finding information because of changes to the information or its environment.  A number of interesting observations arose from this analysis, including that the path originally taken to get to the information target appeared important in its re-retrieval, whereas, surprisingly, the temporal aspects of when the information was seen before were not.  While people expressed frustration when problems arose, an explanation of why the change had occurred was often sufficient to allay that frustration, even in the absence of a solution.  The implications of these observations for systems that support re-finding in dynamic environments are discussed.",9 p.; 16783533 bytes; 654765 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,How People Re-find Information When the Web Changes,AI; re-finding; information management; dynamic information,,
"Walfish, Michael; Stribling, Jeremy; Krohn, Maxwell; Balakrishnan, Hari; Morris, Robert; Shenker, Scott",Networks and Mobile Systems,2005-12-22T01:35:08Z,2005-12-22T01:35:08Z,2004-06-24,MIT-CSAIL-TR-2004-042; MIT-LCS-TR-954,http://hdl.handle.net/1721.1/30481,"Intermediate network elements, such as network address translators (NATs), firewalls, and transparent caches are now commonplace. The usual reaction in the network architecture community to these so-called middleboxes is a combination of scorn (because they violate important architectural principles) and dismay (because these violations make the Internet less flexible). While we acknowledge these concerns, we also recognize that middleboxes have become an Internet fact of life for important reasons. To retain their functions while eliminating their dangerous side-effects, we propose an extension to the Internet architecture, called the Delegation-Oriented Architecture (DOA), that not only allows, but also facilitates, the deployment of middleboxes. DOA involves two relatively modest changes to the current architecture: (a) a set of references that are carried in packets and serve as persistent host identifiers and (b) a way to resolve these references to delegates chosen by the referenced host.",16 p.; 31058710 bytes; 1338617 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Middleboxes No Longer Considered Harmful,,,
"Torralba, Antonio; Murphy, Kevin P.; Freeman, William T.",,2005-12-22T01:35:14Z,2005-12-22T01:35:14Z,2004-06-25,MIT-CSAIL-TR-2004-043; AIM-2004-013,http://hdl.handle.net/1721.1/30482,"We seek to both detect and segment objects in images.  To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random field (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efficient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in office and street scenes.",10 p.; 11085755 bytes; 604755 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Contextual models for object detection using boosted random fields,AI; Object detection; context; boosting; BP; random fields,,
"Torralba, Antonio; Murphy, Kevin P.; Freeman, William T.",,2004-10-08T20:43:16Z,2004-10-08T20:43:16Z,2004-06-25,AIM-2004-013,http://hdl.handle.net/1721.1/6740,"We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random field (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efficient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in office and street scenes.",10 p.; 2184856 bytes; 906515 bytes,application/postscript; application/pdf,en_US,AIM-2004-013,Contextual models for object detection using boosted random fields,AI; Object detection; context; boosting; BP; random fields,,
"Hsu, Eugene; Gentry, Sommer; Popovic, Jovan",,2008-08-25T19:00:19Z,2008-08-25T19:00:19Z,2004-07-01,,http://hdl.handle.net/1721.1/41944,"In human motion control applications, the mapping between a control specification and an appropriate target motion often defies an explicit encoding. We present a method that allows such a mapping to be defined by example, given that the control specification is recorded motion. Our method begins by building a database of semantically meaningful instances of the mapping, each of which is represented by synchronized segments of control and target motion. A dynamic programming algorithm can then be used to interpret an input control specification in terms of mapping instances. This interpretation induces a sequence of target segments from the database, which is concatenated to create the appropriate target motion. We evaluate our method on two examples of indirect control. In the first, we synthesize a walking human character that follows a sampled trajectory. In the second, we generate a synthetic partner for a dancer whose motion is acquired through motion capture.",N/A,,,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Example-Based Control of Human Motion,,Jovan Popovic; Computer Graphics,"In ACM SIGGRAPH/Eurographics Symposium on Computer Animation, pages 69-77, July 2004."
"Indyk, Piotr; Woodruff, David",,2004-10-08T20:43:17Z,2004-10-08T20:43:17Z,2004-07-02,AIM-2004-014,http://hdl.handle.net/1721.1/6741,"We give a one-pass, O~(m^{1-2/k})-space algorithm for estimating the k-th frequency moment of a data stream for any real k>2. Together with known lower bounds, this resolves the main problem left open by Alon, Matias, Szegedy, STOC'96. Our algorithm enables deletions as well as insertions of stream elements.",18 p.; 3705201 bytes; 761567 bytes,application/postscript; application/pdf,en_US,AIM-2004-014,Optimal Approximations of the Frequency Moments,AI,,
"Indyk, Piotr; Woodruff, David",,2005-12-22T01:35:22Z,2005-12-22T01:35:22Z,2004-07-02,MIT-CSAIL-TR-2004-044; AIM-2004-014,http://hdl.handle.net/1721.1/30483,"We give a one-pass, O~(m^{1-2/k})-space algorithm for estimating the k-th frequency moment of a data stream for any real k>2. Together with known lower bounds, this resolves the main problem left open by Alon, Matias, Szegedy, STOC'96. Our algorithm enables deletions as well as insertions of stream elements.",18 p.; 18493060 bytes; 833343 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Optimal Approximations of the Frequency Moments,AI,,
"Badoiu, Mihai; Indyk, Piotr; Sidiropoulos, Anastasios",,2005-12-22T01:35:27Z,2005-12-22T01:35:27Z,2004-07-05,MIT-CSAIL-TR-2004-045; AIM-2004-015,http://hdl.handle.net/1721.1/30484,"We present a constant-factor approximation algorithm for computing anembedding of the shortest path metric of an unweighted graph into atree, that minimizes the multiplicative distortion.",8 p.; 6685848 bytes; 331083 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,A Constant-Factor Approximation Algorithm for Embedding Unweighted Graphs into Trees,AI; embeddings; approximation algorithms; trees,,
"Badoiu, Mihai; Indyk, Piotr; Sidiropoulos, Anastasios",,2004-10-08T20:43:19Z,2004-10-08T20:43:19Z,2004-07-05,AIM-2004-015,http://hdl.handle.net/1721.1/6742,"We present a constant-factor approximation algorithm for computing an embedding of the shortest path metric of an unweighted graph into a tree, that minimizes the multiplicative distortion.",8 p.; 981451 bytes; 626039 bytes,application/postscript; application/pdf,en_US,AIM-2004-015,A Constant-Factor Approximation Algorithm for Embedding Unweighted Graphs into Trees,AI; embeddings; approximation algorithms; trees,,
"Heo, Seongmoo; Asanovic, Krste",Computer Architecture,2005-12-22T01:35:34Z,2005-12-22T01:35:34Z,2004-07-12,MIT-CSAIL-TR-2004-046; MIT-LCS-TR-957,http://hdl.handle.net/1721.1/30485,"Digital circuits often have a critical path that runs through a smallsubset of the component subblocks, but where the path changes dynamicallyduring operation.  Dynamically resizable static CMOS (DRCMOS) logic isproposed as a fine-grain leakage reduction technique that dynamicallydownsizes transistors in inactive subblocks while maintaining speed insubblocks along the current critical path.  A 64-entry register free listand a 64-entry pick-two arbiter are used to evaluate DRCMOS. DRCMOS isshown to give a 50% reduction in total power for equal delay in a70 nm technology.",5 p.; 7595008 bytes; 408267 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Dynamically Resizable Static CMOS Logic for Fine-Grain Leakage,,,
"Tauber, Joshua A.; Garland, Stephen J.",Theory of Computation,2005-12-22T01:35:52Z,2005-12-22T01:35:52Z,2004-07-19,MIT-CSAIL-TR-2004-048; MIT-LCS-TR-959,http://hdl.handle.net/1721.1/30487,"The IOA language provides notations for defining both primitive and composite I/O automata.This note describes, both formally and with examples, the constraints on these definitions, thecomposability requirements for the components of a composite automaton, and the transformationof a composite automaton into an equivalent primitive automaton.Section 2 introduces four examples used throughout this note to illustrate new definitions andoperations. Section 3 treats IOA programs for primitive I/O automata: it introduces notationsfor describing the syntactic structures that appear in these programs, and it lists syntactic andsemantic conditions that these programs must satisfy to represent valid primitive I/O automata.Section 4 describes how to reformulate primitive IOA programs into an equivalent but more regular(desugared) form that is used in later definitions in this note. Section 5 treats IOA programsfor composite I/O automata: it introduces notations for describing the syntactic structures thatappear in these programs, describes resortings induced by them, and lists syntactic and semanticconditions that these programs must satisfy to represent valid composite I/O automata. Section 6describes the translation of the name spaces of component automata into a unified name spacefor the composite automaton. Section 7 shows how to expand an IOA program for a compositeautomaton into an equivalent IOA program for a primitive automaton. The expansion is generatedby combining syntactic structures of the desugared programs for the component automata afterapplying appropriate replacements of sorts and variables. Section 8 details the expansion of thecomposite automaton introduced in Section 2 using the desugared forms developed throughoutSections 4Â–6 and the techniques described in Section 7. Finally, Section 9 gives a precise definitionof the resortings and substitutions used to replace sorts and variables.",91 p.; 77470182 bytes; 2979546 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Definition and Expansion of Composite Automata in IOA,,,
"Kuncak, Viktor; Nguyen, Huu Hai; Rinard, Martin",Computer Architecture,2005-12-22T01:35:58Z,2005-12-22T01:35:58Z,2004-07-19,MIT-CSAIL-TR-2004-049; MIT-LCS-TR-958,http://hdl.handle.net/1721.1/30488,"We describe an algorithm for deciding the first-order multisorted theory BAPA, which combines 1) Boolean algebras of sets of uninterpreted elements (BA) and 2) Presburger arithmetic operations (PA). BAPA can express the relationship between integer variables and cardinalities of sets, and supports arbitrary quantification over both sets and integers.Our motivation for BAPA is deciding verification conditions that arise in the static analysis of data structure consistency properties. Data structures often use an integer variable to keep track of the number of elements they store; an invariant of such a data structure is that the value of the integer variable is equal to the number of elements stored in the data structure. When the data structure content is represented by a set, the resulting constraints can be captured in BAPA. BAPA formulas with quantifier alternations arise when annotations contain quantifiers themselves, or when proving simulation relation conditions for refinement and equivalence of program fragments. Furthermore, BAPA constraints can be used to extend the techniques for proving the termination of integer programs to programs that manipulate data structures, and have applications in constraint databases.We give a formal description of a decision procedure for BAPA, which implies the decidability of the satisfiability and validity problems for BAPA. We analyze our algorithm and obtain an elementary upper bound on the running time, thereby giving the first complexity bound for BAPA. Because it works by a reduction to PA, our algorithm yields the decidability of a combination of sets of uninterpreted elements with any decidable extension of PA. Our algorithm can also be used to yield an optimal decision procedure for BA though a reduction to PA with bounded quantifiers.We have implemented our algorithm and used it to discharge verification conditions in the Jahob system for data structure consistency checking of Java programs; our experience with the algorithm is promising.",26 p.; 26003902 bytes; 1120584 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,An Algorithm for Deciding BAPA: Boolean Algebra with Presburger Arithmetic,,,
"Vaziri, Mandana; Tauber, Joshua A.; Tsai, Michael J.; Lynch, Nancy",Theory of Computation,2005-12-22T01:35:40Z,2005-12-22T01:35:40Z,2004-07-19,MIT-CSAIL-TR-2004-047; MIT-LCS-TR-960,http://hdl.handle.net/1721.1/30486,"The Input/Output  (I/O) automaton model  developed by Lynch and Tuttle models components in asynchronous concurrentsystems as labeled transition systems.  IOA is a precise language for describing I/O automata and for stating their properties.  A toolset is beingdeveloped for IOA  to support distributed software design and implementation. One of the tools consists of a userassisted code generator fromIOA into an imperative programming language such as C or Java. One aspect that distinguishes IOA programs from programs written inimperative languages  is the presence of nondeterminism  which comesin the form of explicit nondeterministic statements and implicit scheduling choices made during execution.  Code generation therefore consistspartially of systematically removing all forms of nondeterminism. In this paper, we describe our approach and design for code generation.We focus on the issue of removing implicit nondeterminism  and specify a transformation on IOA programs that makes all nondeterminismexplicit.  The programmer can then replace all explicit nondeterminismwith deterministic statements  prior to code generation.  We also describethis transformation at a semantic level  i.e., at the level of the I/O automaton mathematical model.  We show that the transformation definedat the IOA level conforms to the one at the semantic level.",16 p.; 14677208 bytes; 626419 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Systematic Removal of Nondeterminism for Code Generation in I/O Automata,,,
"Kemp, Charles; Griffiths, Thomas L.; Tenenbaum, Joshua B.",,2005-12-22T01:36:09Z,2005-12-22T01:36:09Z,2004-07-22,MIT-CSAIL-TR-2004-050; AIM-2004-019,http://hdl.handle.net/1721.1/30489,"We present a framework for learning abstract relational knowledge with the aimof explaining how people acquire intuitive theories of physical, biological, orsocial systems.  Our approach is based on a generative relational model withlatent classes, and simultaneously determines the kinds of entities that existin a domain, the number of these latent classes, and the relations betweenclasses that are possible or likely.  This model goes beyond previouspsychological models of category learning,  which consider attributesassociated with individual categories but not relationships between categories.We apply this domain-general framework to two specific problems: learning thestructure of kinship systems and learning causal theories.",12 p.; 13382538 bytes; 572002 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Discovering Latent Classes in Relational Data,AI; learning; categorization; relations; kinship,,
"Uzuner, Ozlem",,2005-12-22T01:36:15Z,2005-12-22T01:36:15Z,2004-07-25,MIT-CSAIL-TR-2004-051; AIM-2004-018,http://hdl.handle.net/1721.1/30490,"In this paper, we discuss a wireless grid in which users are highly mobile, and form ad-hoc and sometimes short-lived connections with other devices.  As they roam through networks, the users may choose to employ privacy-enhancing technologies to address their privacy needs and benefit from the computational power of the grid for a variety of tasks, including sharing content.  The high rate of mobility of the users on the wireless grid, when combined with privacy enhancing mechanisms and ad-hoc connections, makes it difficult to conclusively link devices and/or individuals with network activities and to hold them liable for particular downloads.  Protecting intellectual property in this scenario requires a solution that can work in absence of knowledge about behavior of particular individuals.  Building on previous work, we argue for a solution that ensures proper compensation to content owners without inhibiting use and dissemination of works.  Our proposal is based on digital tracking for measuring distribution volume of content and compensation of authors based on this accounting information.  The emphasis is on obtaining good estimates of rate of popularity of works, without keeping track of activities of individuals or devices.  The contribution of this paper is a revenue protection mechanism, Distribution Volume Tracking, that does not invade the privacy of users in the wireless grid and works even in the presence of privacy-enhancing technologies they may employ.",7 p.; 11942167 bytes; 409314 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Distribution Volume Tracking on Privacy-Enhanced Wireless Grid,AI; Intellectual Property Protection; Privacy; Wireless Computational Grid,,
