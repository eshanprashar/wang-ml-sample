dc.contributor.advisor,dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.relation,dc.subject,dc.title
Russ Tedrake,"Rohanimanesh, Khashayar; Roy, Nicholas; Tedrake, Russ",Robot Locomotion Group,2007-11-13T14:45:30Z,2007-11-13T14:45:30Z,2007-11-01,MIT-CSAIL-TR-2007-051,http://hdl.handle.net/1721.1/39427,"Choosing features for the critic in actor-critic algorithms with function approximation is known to be a challenge. Too few critic features can lead to degeneracy of the actor gradient, and too many features may lead to slower convergence of the learner. In this paper, we show that a well-studied class of actor policies satisfy the known requirements for convergence when the actor features are selected carefully. We demonstrate that two popular representations for value methods - the barycentric interpolators and the graph Laplacian proto-value functions - can be used to represent the actor in order to satisfy these conditions. A consequence of this work is a generalization of the proto-value function methods to the continuous action actor-critic domain. Finally, we analyze the performance of this approach using a simulation of a torque-limited inverted pendulum.",9 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,reinforcement learning,Towards Feature Selection In Actor-Critic Algorithms
Silvio Micali,"Valiant, Paul; Micali, Silvio",Theory of Computation,2007-11-02T20:30:07Z,2007-11-02T20:30:07Z,2007-11-02,MIT-CSAIL-TR-2007-052,http://hdl.handle.net/1721.1/39420,"In auctions of a single good, the second-price mechanism achieves, in dominantstrategies, a revenue benchmark that is naturally high and resilient to anypossible collusion.We show how to achieve, to the maximum extent possible, the same propertiesin combinatorial auctions.",20 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Worst Rational Setting; Natural Solution Pairs; Player-Monotone Benchmarks; Revenue Guarantees; Guaranteed Revenue,Collusion-Resilient Revenue In Combinatorial Auctions
Trevor Darrell,"Urtasun, Raquel; Quattoni, Ariadna; Darrell, Trevor",Vision,2007-11-13T14:45:17Z,2007-11-13T14:45:17Z,2007-11-06,MIT-CSAIL-TR-2007-053,http://hdl.handle.net/1721.1/39426,"When a series of problems are related, representations derived fromlearning earlier tasks may be useful in solving later problems. Inthis paper we propose a novel approach to transfer learning withlow-dimensional, non-linear latent spaces. We show how suchrepresentations can be jointly learned across multiple tasks in adiscriminative probabilistic regression framework. When transferred tonew tasks with relatively few training examples, learning can befaster and/or more accurate. Experiments on a digit recognition taskshow significantly improved performance when compared to baselineperformance with the original feature representation or with arepresentation derived from a semi-supervised learning approach.",8 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,transfer learning; latent variable models,Transfering Nonlinear Representations using Gaussian Processes with a Shared Latent Space
Michael Ernst,"Kim, Sunghun; Artzi, Shay; Ernst, Michael D.",Program Analysis,2007-11-20T15:45:09Z,2007-11-20T15:45:09Z,2007-11-20,MIT-CSAIL-TR-2007-054,http://hdl.handle.net/1721.1/39639,"It is difficult to fix a problem without being able to reproduce it.However, reproducing a problem is often difficult and time-consuming.This paper proposes a novel algorithm, ReCrash, that generatesmultiple unit tests that reproduce a given program crash.ReCrash dynamically tracks method calls during every execution of the target program. If the program crashes, ReCrash saves information about the relevant method calls and uses the saved information to create unit tests reproducing the crash.We present reCrashJ an implementation of ReCrash for Java. reCrashJ reproducedreal crashes from javac, SVNKit, Eclipse JDT, and BST. reCrashJ is efficient, incurring 13%-64% performance overhead. If this overhead is unacceptable, then reCrashJ has another mode that has negligible overhead until a crash occurs and 0%-1.7% overhead until a second crash, at which point the test cases are generated.",9 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,,ReCrash: Making Crashes Reproducible
Saman Amarasinghe,"Thies, William; Hall, Steven; Amarasinghe, Saman",Computer Architecture,2007-12-03T13:45:13Z,2007-12-03T13:45:13Z,2007-11-30,MIT-CSAIL-TR-2007-055,http://hdl.handle.net/1721.1/39651,"Due to the high data rates involved in audio, video, and signalprocessing applications, it is imperative to compress the data todecrease the amount of storage used. Unfortunately, this implies thatany program operating on the data needs to be wrapped by adecompression and re-compression stage. Re-compression can incursignificant computational overhead, while decompression swamps theapplication with the original volume of data.In this paper, we present a program transformation that greatlyaccelerates the processing of compressible data. Given a program thatoperates on uncompressed data, we output an equivalent program thatoperates directly on the compressed format. Our transformationapplies to stream programs, a restricted but useful class ofapplications with regular communication and computation patterns. Ourformulation is based on LZ77, a lossless compression algorithm that isutilized by ZIP and fully encapsulates common formats such as AppleAnimation, Microsoft RLE, and Targa.We implemented a simple subset of our techniques in the StreamItcompiler, which emits executable plugins for two popular video editingtools: MEncoder and Blender. For common operations such as coloradjustment and video compositing, mapping into the compressed domainoffers a speedup roughly proportional to the overall compressionratio. For our benchmark suite of 12 videos in Apple Animationformat, speedups range from 1.1x to 471x, with a median of 15x.",13 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,synchronous dataflow,Mapping Stream Programs into the Compressed Domain
Silvio Micali,"Lepinski, Matt; Micali, Silvio; Izmalkov, Sergei",Theory of Computation,2007-12-05T18:15:10Z,2007-12-05T18:15:10Z,2007-12-05,MIT-CSAIL-TR-2007-056,http://hdl.handle.net/1721.1/39659,"We put forward the notion of a verifiably secure device, in essence a stronger notion of secure computation, and achieve it in the ballot-box model. Verifiably secure devices1. Provide a perfect solution to the problem of achieving correlated equilibrium, an important and extensively investigated problem at the intersection of game theory, cryptography and efficient algorithms; and2. Enable the secure evaluation of multiple interdependent functions.",29 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,interdependent functions; correlated equilibrium; Implementation; interdependent mechanisms,Verifiably Secure Devices
Michael Ernst,"McCamant, Stephen; Ernst, Michael D.",Program Analysis,2007-12-10T14:00:11Z,2007-12-10T14:00:11Z,2007-12-10,MIT-CSAIL-TR-2007-057,http://hdl.handle.net/1721.1/39812,"We present a new technique for determining how much information abouta program's secret inputs is revealed by its public outputs. Incontrast to previous techniques based on reachability from secretinputs (tainting), it achieves a more precise quantitative result bycomputing a maximum flow of information between the inputs andoutputs. The technique uses static control-flow regions to soundlyaccount for implicit flows via branches and pointer operations, butoperates dynamically by observing one or more program executions andgiving numeric flow bounds specific to them (e.g., ""17 bits""). Themaximum flow in a network also gives a minimum cut (a set of edgesthat separate the secret input from the output), which can be used toefficiently check that the same policy is satisfied on futureexecutions. We performed case studies on 5 real C, C++, and ObjectiveC programs, 3 of which had more than 250K lines of code. The toolchecked multiple security policies, including one that was violated bya previously unknown bug.",12 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,Confidentiality; Privacy; Information disclosure; Tainting; Implicit flows; Valgrind; Memcheck,Quantitative Information Flow as Network Flow Capacity
John Leonard,"Leonard, John; Barrett, David; How, Jonathan; Teller, Seth; Antone, Matt; Campbell, Stefan; Epstein, Alex; Fiore, Gaston; Fletcher, Luke; Frazzoli, Emilio; Huang, Albert; Jones, Troy; Koch, Olivier; Kuwata, Yoshiaki; Mahelona, Keoni; Moore, David; Moyer, Katy; Olson, Edwin; Peters, Steven; Sanders, Chris; Teo, Justin; Walter, Matthew","Robotics, Vision & Sensor Networks",2007-12-17T13:50:57Z,2007-12-17T13:50:57Z,2007-12-14,MIT-CSAIL-TR-2007-058,http://hdl.handle.net/1721.1/39822,"This technical report describes Team MIT’s approach to theDARPA Urban Challenge. We have developed a novel strategy forusing many inexpensive sensors, mounted on the vehicle periphery,and calibrated with a new cross-­modal calibrationtechnique. Lidar, camera, and radar data streams are processedusing an innovative, locally smooth state representation thatprovides robust perception for real­ time autonomous control. Aresilient planning and control architecture has been developedfor driving in traffic, comprised of an innovative combination ofwell­proven algorithms for mission planning, situationalplanning, situational interpretation, and trajectory control. These innovations are being incorporated in two new roboticvehicles equipped for autonomous driving in urban environments,with extensive testing on a DARPA site visit course. Experimentalresults demonstrate all basic navigation and some basic trafficbehaviors, including unoccupied autonomous driving, lanefollowing using pure-­pursuit control and our local frameperception strategy, obstacle avoidance using kino-­dynamic RRTpath planning, U-­turns, and precedence evaluation amongst othercars at intersections using our situational interpreter. We areworking to extend these approaches to advanced navigation andtraffic scenarios.",26 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,autonomous vehicle; robotics; DARPA Grand Challenge; path planning; machine perception; tracking,Team MIT Urban Challenge Technical Report
Tomaso Poggio,"Masquelier, Timothee; Serre, Thomas; Thorpe, Simon; Poggio, Tomaso",Center for Biological and Computational Learning (CBCL),2007-12-27T13:45:13Z,2007-12-27T13:45:13Z,2007-12-26,MIT-CSAIL-TR-2007-060; CBCL-269,http://hdl.handle.net/1721.1/39833,"One of the most striking feature of the cortex is its ability to wire itself. Understanding how the visual cortex wires up through development and how visual experience refines connections into adulthood is a key question for Neuroscience. While computational models of the visual cortex are becoming increasingly detailed, the question of how such architecture could self-organize through visual experience is often overlooked. Here we focus on the class of hierarchical feedforward models of the ventral stream of the visual cortex, which extend the classical simple-to-complex cells model by Hubel and Wiesel (1962) to extra-striate areas, and have been shown to account for a host of experimental data. Such models assume two functional classes of simple and complex cells with specific predictions about their respective wiring and resulting functionalities.In these networks, the issue of learning, especially for complex cells, is perhaps the least well understood. In fact, in most of these models, the connectivity between simple and complex cells is not learned butrather hard-wired. Several algorithms have been proposed for learning invariances at the complex cell level based on a trace rule to exploit the temporal continuity of sequences of natural images, but very few can learn from natural cluttered image sequences.Here we propose a new variant of the trace rule that only reinforces the synapses between the most active cells, and therefore can handle cluttered environments. The algorithm has so far been developed and tested at the level of V1-like simple and complex cells: we verified that Gabor-like simple cell selectivity could emerge from competitive Hebbian learning. In addition, we show how the modified trace rule allows the subsequent complex cells to learn to selectively pool over simple cells with the same preferred orientation but slightly different positions thus increasing their tolerance to the precise position of the stimulus within their receptive fields.",19 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,primary visual cortex; slowness; temporal continuity; hubel and wiesel; feedforward hierarchical models,Learning complex cell invariance from natural videos: A plausibility proof
Leslie Kaelbling,"Gardiol, Natalia Hernandez",Learning and Intelligent Systems,2008-01-03T13:32:44Z,2008-01-03T13:32:44Z,2007-12-31,MIT-CSAIL-TR-2007-061,http://hdl.handle.net/1721.1/39838,"This thesis proposes a synthesis of logic and probability for solving stochastic sequential decision-making problems. We address two main questions: How can we take advantage of logical structure to speed up planning in a principled way? And, how can probability inform the production of a more robust, yet still compact, policy? We can take as inspiration a mobile robot acting in the world: it is faced with a varied amount ofsensory data and uncertainty in its action outcomes. Or, consider a logistics planning system: it must deliver a large number of objects to the right place at the right time. Many interesting sequential decision-making domains involve large statespaces, large stochastic action sets, and time pressure to act. In this work, we show how structured representations of the environment's dynamics can constrain and speed up the planning process. We start with a problem domain described in a probabilistic logical description language.Our technique is based on, first, identifying the most parsimonious representation that permits solution of the described problem. Next, we take advantage of the structured problem description to dynamically partition the action space into a set of equivalence classes with respect to this minimal representation. The partitioned action space results in fewer distinctactions. This technique can yield significant gains in planning efficiency.Next, we develop an anytime technique to elaborate on this initial plan. Our approach uses the envelope MDP framework, which creates a Markov decision process out of a subset of the possible state space. This strategy lets an agent begin acting quicklywithin a restricted part of the full state space, as informed by the original plan,and to judiciously expand its envelope as resources permit.Finally, we show how the representation space itself can be elaborated within the anytime framework. This approach balances the need to respond to time-pressure and to produce the most robust policies possible. We present experimental results in some synthetic planning domains and in a simulated military logistics domain.",143 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,,Relational Envelope-based Planning
Piotr Indyk,"Berinde, Radu; Indyk, Piotr",Theory of Computation,2008-01-15T14:15:14Z,2008-01-15T14:15:14Z,2008-01-10,MIT-CSAIL-TR-2008-001,http://hdl.handle.net/1721.1/40089,"We consider the approximate sparse recovery problem, where the goal is to (approximately) recover a high-dimensional vector x from its lower-dimensional sketch Ax. A popular way of performing this recovery is by finding x* such that Ax=Ax*, and ||x*||_1 is minimal. It is known that this approach ``works'' if A is a random *dense* matrix, chosen from a proper distribution.In this paper, we investigate this procedure for the case where A is binary and *very sparse*. We show that, both in theory and in practice, sparse matrices are essentially as ``good'' as the dense ones. At the same time, sparse binary matrices provide additional benefits, such as reduced encoding and decoding time.",13 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,,Sparse recovery using sparse matrices
Michael Ernst,"Saff, David; Boshernitsan, Marat; Ernst, Michael D.",Program Analysis,2008-01-15T14:15:58Z,2008-01-15T14:15:58Z,2008-01-14,MIT-CSAIL-TR-2008-002,http://hdl.handle.net/1721.1/40090,"Automated testing during development helps ensure that software works according to the test suite. Traditional test suites verify a few well-picked scenarios or example inputs. However, such example-based testing does not uncover errors in legal inputs that the test writer overlooked. We propose theory-based testing as an adjunct to example-based testing. A theory generalizes a (possibly infinite) set of example-based tests. A theory is an assertion that should be true for any data, and it can be exercised by human-chosen data or by automatic data generation. A theory is expressed in an ordinary programming language, it is easy for developers to use (often even easier than example-based testing), and it serves as a lightweight form of specification. Six case studies demonstrate the utility of theories that generalize existing tests to prevent bugs, clarify intentions, and reveal design problems.",10 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"JUnit, testing, partial specification",Theories in Practice: Easy-to-Write Specifications that Catch Bugs
Jovan Popovic,"Silva, Marco da; Abe, Yeuhi; Popovic, Jovan",Computer Graphics,2008-01-16T13:45:10Z,2008-01-16T13:45:10Z,2008-01-15,,http://hdl.handle.net/1721.1/40091,"Many data-driven animation techniques are capable of producing high quality motions of human characters. Few techniques, however, are capable of generating motions that are consistent with physically simulated environments. Physically simulated characters, in contrast, are automatically consistent with the environment, but their motionsare often unnatural because they are difficult to control. We present a model-predictive controller that yields natural motions by guiding simulated humans toward real motion data. During simulation, the predictive component of the controller solves a quadratic program to compute the forces for a short window of time into the future. These forces are then applied by a low-gain proportional-derivative component, which makes minor adjustments until the next planning cycle. The controller is fast enough for interactive systems such as games and training simulations. It requires no precomputation and little manual tuning. The controller is resilient to mismatches between the character dynamics and the input motion, which allows it to track motion capture data even where the real dynamics are not known precisely. The same principled formulation can generate natural walks, runs, and jumps in a number of different physically simulated surroundings.",N/A,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,Computer Graphics; Three Dimensional Graphics and Realism; Animation,Simulation of Human Motion Data using Short-Horizon Model-Predictive Control
Hari Balakrishnan,"Eriksson, Jakob; Balakrishnan, Hari; Madden, Sam",Networks & Mobile Systems,2008-01-29T14:15:28Z,2008-01-29T14:15:28Z,2008-01-17,MIT-CSAIL-TR-2008-003,http://hdl.handle.net/1721.1/40094,"This paper describes the design, implementation, and evaluation of Cabernet, a system to deliver data to and from moving vehicles using open 802.11 (WiFi) access points encountered opportunistically during travel. Network connectivity in Cabernet is both fleeting (access points are typicallywithin range for a few seconds) and intermittent (because the access points don't provide continuous coverage), and suffers from high packet loss rates over the wireless channel. On the positive side, in the absence of losses, achievable data rates over WiFi can reach many megabits per second. Unfortunately, current protocols don't establish end-to-end connectivity fast enough, don't cope well with intermittent connectivity, and don't handle high packet loss rates well enough to achieve this potential throughput. Cabernet incorporates two new techniques to improve data delivery throughput: QuickWifi, a streamlined client-side process to establish end-to-end connectivity quickly, reducing the mean time to establish connectivity from 12.9 seconds to less than 366 ms and CTP, a transport protocol that distinguishes congestion on the wired portion of the path from losses over the wireless link to reliably and efficiently deliver data to nodes in cars. We have deployed the system on a fleet of 10 taxis, each running several hours per day in the Boston area. Our experiments show that CTP improves throughput by a factor of 2x over TCP and that QuickWifi increases the number of connectionsby a factor of 4x over unoptimized approaches. Thus, Cabernet is perhaps the first practical system capable of delivering data to moving vehicles over existing short-range WiFi radios, with a mean transfer capacity of approximately 38 megabytes/hour per car, or a mean rate of 87 kbit/s.",14 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,"wifi, IEEE 802.11, vehicular networking",Cabernet: A Content Delivery Network for Moving Vehicles
David Karger,"Karger, David; Nikolova, Evdokia",Theory of Computation,2008-01-29T14:15:12Z,2008-01-29T14:15:12Z,2008-01-28,MIT-CSAIL-TR-2008-004,http://hdl.handle.net/1721.1/40093,"The Canadian Traveller problem is a stochastic shortest paths problem in which one learns the cost of an edge only when arriving at one of its endpoints. The goal is to find an adaptive policy (adjusting as one learns more edge lengths) that minimizes the expected cost of travel. The problem is known to be #P hard. Since there has been no significant progress on approximation algorithms for several decades, we have chosen to seek out special cases for which exact solutions exist, in the hope of demonstrating techniques that could lead to further progress. Applying techniques from the theory of Markov Decision Processes, we give an exact solution for graphs of parallel (undirected) paths from source to destination with random two-valued edge costs. We also offer a partial generalization to traversing perfect binary trees.",14 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,"Canadian Traveller, stochastic shortest path, route planning under uncertainty, path planning",Exact Algorithms for the Canadian Traveller Problem on Paths and Trees
Sam Madden,"Newton, Ryan; Girod, Lewis; Craig, Michael; Madden, Sam; Morrisett, Greg",Computation Structures,2008-01-31T19:00:11Z,2008-01-31T19:00:11Z,2008-01-31,MIT-CSAIL-TR-2008-005; CBCL-270,http://hdl.handle.net/1721.1/40095,"Applications that combine live data streams with embedded, parallel,and distributed processing are becoming more commonplace. WaveScriptis a domain-specific language that brings high-level, type-safe,garbage-collected programming to these domains. This is made possibleby three primary implementation techniques. First, we employ a novelevaluation strategy that uses a combination of interpretation andreification to partially evaluate programs into stream dataflowgraphs. Second, we use profile-driven compilation to enable manyoptimizations that are normally only available in the synchronous(rather than asynchronous) dataflow domain. Finally, we incorporatean extensible system for rewrite rules to capture algebraic propertiesin specific domains (such as signal processing).We have used our language to build and deploy a sensor-network for theacoustic localization of wild animals, in particular, theYellow-Bellied marmot. We evaluate WaveScript's performance on thisapplication, showing that it yields good performance on both embeddedand desktop-class machines, including distributed execution andsubstantial parallel speedups. Our language allowed us to implementthe application rapidly, while outperforming a previous Cimplementation by over 35%, using fewer than half the lines of code.We evaluate the contribution of our optimizations to this success.",11 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,,WaveScript: A Case-Study in Applying a Distributed Stream-Processing Language
Michael Ernst,"Artzi, Shay; Kiezun, Adam; Dolby, Julian; Tip, Frank; Dig, Danny; Paradkar, Amit; Ernst, Michael D.",Program Analysis,2008-02-06T14:15:11Z,2008-02-06T14:15:11Z,2008-02-06,MIT-CSAIL-TR-2008-006,http://hdl.handle.net/1721.1/40249,"Web script crashes and malformed dynamically-generated web pages are common errors, and they seriously impact usability of web applications. Currenttools for web-page validation cannot handle the dynamically-generatedpages that are ubiquitous on today's Internet.In this work, we apply a dynamic test generation technique, based oncombined concrete and symbolic execution, to the domain of dynamic webapplications. The technique generates tests automatically andminimizes the bug-inducing inputs to reduce duplication and to makethe bug reports small and easy to understand and fix.We implemented the technique in Apollo, an automated tool thatfound dozens of bugs in real PHP applications. Apollo generatestest inputs for the web application, monitors the application forcrashes, and validates that the output conforms to the HTMLspecification. This paper presents Apollo's algorithms andimplementation, and an experimental evaluation that revealed a totalof 214 bugs in 4 open-source PHP web applications.",12 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,html; syntax; validation; dynamic; bug,Finding Bugs In Dynamic Web Applications
David Karger,"Bernstein, Michael; Van Kleek, Max; Khushraj, Deepali; Nayak, Rajeev; Liu, Curtis; schraefel, mc; Karger, David R.",Undecided,2008-02-13T18:00:20Z,2008-02-13T18:00:20Z,2008-02-10,MIT-CSAIL-TR-2008-007,http://hdl.handle.net/1721.1/40281,"This paper is a case study of an artifact design and evaluation process; it is a reflection on how right thinking about design methods may at times result in sub-optimal results. Our goal has been to assess our decision making processthroughout the design and evaluation stages for a software prototype in order to consider where design methodology may need to be tuned to be more sensitive to the domain of practice, in this case software evaluation in personal information management. In particular, we reflect on design methods around (1) scale of prototype, (2) prototyping and design process, (3) study design, and (4) study population.",10 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,Case study; User-centered design; Personal information management,Wicked Problems and Gnarly Results: Reflecting on Design and Evaluation Methods for Idiosyncratic Personal Information Management Tasks
Karen Sollins,"Beverly, Robert; Sollins, Karen",Advanced Network Architecture,2008-02-19T13:45:28Z,2008-02-19T13:45:28Z,2008-02-15,MIT-CSAIL-TR-2008-008,http://hdl.handle.net/1721.1/40287,"In the arms race to secure electronic mail users and servers fromunsolicited messages (spam), the most successful solutions employtechniques that are difficult for spammers to circumvent. Thisresearch investigates the transport-layer characteristics ofemail in order to provide a new, novel and robust defense againstspam. We find that spam SMTP flows exhibit TCP behavior consistentwith traffic competing for link access, large round trip times andresource constrained hosts. Thus, SMTP flow characteristics providesufficient statistical power to differentiate between spam andlegitimate mail (ham). We build ""SpamFlow"" to learn and exploitthese differences. Using machine learning feature selection weidentify the most discriminatory flow properties and effect greaterthan 90% spam classification accuracy without content or reputationanalysis. SpamFlow correctly identifies 78% of the false negativesgenerated by a popular content filtering application -- demonstratingthe power in combining SpamFlow with existing techniques. Finally, weargue that SpamFlow is not easily subvertible due to economicand practical constraints inherent in sourcing spam.",12 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,,Exploiting Transport-Level Characteristics of Spam
Trevor Darrell,"Christoudias, C. Mario; Urtasun, Raquel; Darrell, Trevor",Vision,2008-02-19T13:45:16Z,2008-02-19T13:45:16Z,2008-02-17,MIT-CSAIL-TR-2008-009,http://hdl.handle.net/1721.1/40286,"Object recognition accuracy can be improved when information frommultiple views is integrated, but information in each view can oftenbe highly redundant. We consider the problem of distributed objectrecognition or indexing from multiple cameras, where thecomputational power available at each camera sensor is limited andcommunication between sensors is prohibitively expensive. In thisscenario, it is desirable to avoid sending redundant visual featuresfrom multiple views, but traditional supervised feature selectionapproaches are inapplicable as the class label is unknown at thecamera. In this paper we propose an unsupervised multi-view featureselection algorithm based on a distributed compression approach.With our method, a Gaussian Process model of the joint viewstatistics is used at the receiver to obtain a joint encoding of theviews without directly sharing information across encoders. Wedemonstrate our approach on recognition and indexing tasks withmulti-view image databases and show that our method comparesfavorably to an independent encoding of the features from eachcamera.",10 p.,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,Distributed Compression; Gaussian Processes; Multi-view Object Recognition,Unsupervised Distributed Feature Selection for Multi-view Object Recognition
