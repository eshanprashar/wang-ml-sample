dc.contributor.author,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.subject,dc.title,dc.contributor.other
"Morgenstern, Christian; Heisele, Bernd",2005-12-22T01:15:11Z,2005-12-22T01:15:11Z,2003-11-28,MIT-CSAIL-TR-2003-031; AIM-2003-024; CBCL-232,http://hdl.handle.net/1721.1/30436,We present a component-based approach for recognizing objectsunder large pose changes. From a set of training images of a givenobject we extract a large number of components which are clusteredbased on the similarity of their image features and their locations withinthe object image. The cluster centers build an initial set of componenttemplates from which we select a subset for the final recognizer.In experiments we evaluate different sizes and types of components andthree standard techniques for component selection. The component classifiersare finally compared to global classifiers on a database of fourobjects.,12 p.; 20676042 bytes; 965767 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; computer vision; object recognition; component object recognition,Component based recognition of objects in an office environment,
"Chang, Yu-Han; Ho, Tracey; Kaelbling, Leslie Pack",2005-12-22T01:15:17Z,2005-12-22T01:15:17Z,2003-12-04,MIT-CSAIL-TR-2003-032; AIM-2003-025,http://hdl.handle.net/1721.1/30437,"Research in mobile ad-hoc networks has focused on situations in whichnodes have no control over their movements.  We investigate animportant but overlooked domain in which nodes do have controlover their movements.  Reinforcement learning methods can be used tocontrol both packet routing decisions and node mobility, dramaticallyimproving the connectivity of the network.  We first motivate theproblem by presenting theoretical bounds for the connectivityimprovement of partially mobile networks and then present superiorempirical results under a variety of different scenarios in which themobile nodes in our ad-hoc network are embedded with adaptive routingpolicies and learned movement policies.",9 p.; 15523730 bytes; 577014 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; reinforcement learning; multi-agent learning; ad-hoc networking,Mobilized ad-hoc networks:  A reinforcement learning approach,
"Chang, Yu-Han; Ho, Tracey; Kaelbling, Leslie Pack",2004-10-08T20:43:04Z,2004-10-08T20:43:04Z,2003-12-04,AIM-2003-025,http://hdl.handle.net/1721.1/6732,"Research in mobile ad-hoc networks has focused on situations in which nodes have no control over their movements. We investigate an important but overlooked domain in which nodes do have control over their movements. Reinforcement learning methods can be used to control both packet routing decisions and node mobility, dramatically improving the connectivity of the network. We first motivate the problem by presenting theoretical bounds for the connectivity improvement of partially mobile networks and then present superior empirical results under a variety of different scenarios in which the mobile nodes in our ad-hoc network are embedded with adaptive routing policies and learned movement policies.",9 p.; 771382 bytes; 1199447 bytes,application/postscript; application/pdf,en_US,AIM-2003-025,AI; reinforcement learning; multi-agent learning; ad-hoc networking,Mobilized ad-hoc networks: A reinforcement learning approach,
"Grauman, Kristen; Darrell, Trevor",2005-12-22T01:15:24Z,2005-12-22T01:15:24Z,2003-12-05,MIT-CSAIL-TR-2003-033; AIM-2003-026,http://hdl.handle.net/1721.1/30438,"Weighted graph matching is a good way to align a pair of shapesrepresented by a set of descriptive local features; the set ofcorrespondences produced by the minimum cost of matching features fromone shape to the features of the other often reveals how similar thetwo shapes are.  However, due to the complexity of computing the exactminimum cost matching, previous algorithms could only run efficientlywhen using a limited number of features per shape, and could not scaleto perform retrievals from large databases.  We present a contourmatching algorithm that quickly computes the minimum weight matchingbetween sets of descriptive local features using a recently introducedlow-distortion embedding of the Earth Mover's Distance (EMD) into anormed space.  Given a novel embedded contour, the nearest neighborsin a database of embedded contours are retrieved in sublinear time viaapproximate nearest neighbors search.  We demonstrate our shapematching method on databases of 10,000 images of human figures and60,000 images of handwritten digits.",16 p.; 18655633 bytes; 2291372 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; contour matching; shape matching; EMD; image retrieval,Fast Contour Matching Using Approximate Earth Mover's Distance,
"Grauman, Kristen; Darrell, Trevor",2004-10-08T20:43:06Z,2004-10-08T20:43:06Z,2003-12-05,AIM-2003-026,http://hdl.handle.net/1721.1/6733,"Weighted graph matching is a good way to align a pair of shapes represented by a set of descriptive local features; the set of correspondences produced by the minimum cost of matching features from one shape to the features of the other often reveals how similar the two shapes are. However, due to the complexity of computing the exact minimum cost matching, previous algorithms could only run efficiently when using a limited number of features per shape, and could not scale to perform retrievals from large databases. We present a contour matching algorithm that quickly computes the minimum weight matching between sets of descriptive local features using a recently introduced low-distortion embedding of the Earth Mover's Distance (EMD) into a normed space. Given a novel embedded contour, the nearest neighbors in a database of embedded contours are retrieved in sublinear time via approximate nearest neighbors search. We demonstrate our shape matching method on databases of 10,000 images of human figures and 60,000 images of handwritten digits.",16 p.; 7561935 bytes; 7530316 bytes,application/postscript; application/pdf,en_US,AIM-2003-026,AI; contour matching; shape matching; EMD; image retrieval,Fast Contour Matching Using Approximate Earth Mover's Distance,
"Rodrigues, Rodrigo; Liskov, Barbara",2005-12-22T01:15:38Z,2005-12-22T01:15:38Z,2003-12-17,MIT-CSAIL-TR-2003-035; MIT-LCS-TR-932,http://hdl.handle.net/1721.1/30440,"This paper presents Rosebud, a new Byzantine faulttolerantstorage architecture designed to be highly scalableand deployable in the wide-area. To support massiveamounts of data, we need to partition the data among thenodes. To support long-lived operation, we need to allowthe set of nodes in the system to change. To our knowledge,we are the first to present a complete design and arunning implementation of Byzantine-fault-tolerant storagealgorithms for a large scale, dynamic membership.We deployed Rosebud in a wide area testbed and ran experimentsto evaluate its performance, and our experimentsshow that it performs well. We show that our storage algorithmsperform equivalently to highly optimized replicationalgorithms in the wide-area. We also show that performancedegradation is minor when the system reconfigures.",14 p.; 28245099 bytes; 1025372 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Rosebud: A Scalable Byzantine-Fault-Tolerant Storage Architecture,Programming Methodology
"Beal, Jacob; Gilbert, Seth",2004-10-08T20:43:07Z,2004-10-08T20:43:07Z,2003-12-17,AIM-2003-027,http://hdl.handle.net/1721.1/6734,"We present an algorithm to store data robustly in a large, geographically distributed network by means of localized regions of data storage that move in response to changing conditions. For example, data might migrate away from failures or toward regions of high demand. The PersistentNode algorithm provides this service robustly, but with limited safety guarantees. We use the RAMBO framework to transform PersistentNode into RamboNode, an algorithm that guarantees atomic consistency in exchange for increased cost and decreased liveness. In addition, a half-life analysis of RamboNode shows that it is robust against continuous low-rate failures. Finally, we provide experimental simulations for the algorithm on 2000 nodes, demonstrating how it services requests and examining how it responds to failures.",22 p.; 1312502 bytes; 499111 bytes,application/postscript; application/pdf,en_US,AIM-2003-027,AI; ad-hoc networks distributed algorithms atomic distributed shared memory,RamboNodes for the Metropolitan Ad Hoc Network,
"Beal, Jacob; Gilbert, Seth",2005-12-22T01:15:30Z,2005-12-22T01:15:30Z,2003-12-17,MIT-CSAIL-TR-2003-034; AIM-2003-027,http://hdl.handle.net/1721.1/30439,"We present an algorithm to store data robustly in a large, geographically distributed network by means of localized regions of data storage that move in response to changing conditions. For example, data might migrate away from failures or toward regions of high demand. The PersistentNode algorithm provides this service robustly, but with limited safety guarantees. We use the RAMBO framework to transform PersistentNode into RamboNode, an algorithm that guarantees atomic consistency in exchange for increased cost and decreased liveness. In addition, a half-life analysis of RamboNode shows that it is robust against continuous low-rate failures. Finally, we provide experimental simulations for the algorithm on 2000 nodes, demonstrating how it services requests and examining how it responds to failures.",22 p.; 23886105 bytes; 803571 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; ad-hoc networks distributed algorithms atomic distributed shared memory,RamboNodes for the Metropolitan Ad Hoc Network,
"Lam, Patrick; Kuncak, Viktor; Rinard, Martin",2005-12-22T01:15:47Z,2005-12-22T01:15:47Z,2003-12-18,MIT-CSAIL-TR-2003-036; MIT-LCS-TR-933,http://hdl.handle.net/1721.1/30441,"We present a technique that enables the focused applicationof multiple analyses to different modules in the same program. Our researchhas two goals: 1) to address the scalability limitations of preciseanalyses by focusing the analysis on only those parts of the program thatare relevant to the properties that the analysis is designed to verify, and2) to enable the application of specialized analyses that verify propertiesof specifc classes of data structures to programs that simultaneouslymanipulate several dfferent kinds of data structures.In our approach, each module encapsulates a data structure and usesmembership in abstract sets to characterize how objects participate inits data structure. Each analysis verifies that the implementation of themodule 1) preserves important internal data structure representationinvariants and 2) conforms to a specification that uses formulas in a setalgebra to characterize the effects of operations on the data structure.The analyses use the common set abstraction to 1) characterize howobjects participate in multiple data structures and to 2) enable the interanalysiscommunication required to verify properties that depend onmultiple modules analyzed by different analyses.We characterize the key soundness property that an analysis plugin mustsatisfy to successfully participate in our system and present several analysisplugins that satisfy this property: a flag plugin that analyzes modulesin which abstract set membership is determined by a flag  field in eachobject, and a graph types plugin that analyzes modules in which abstractset membership is determined by reachability properties of objects storedin tree-like data structures.",34 p.; 31854752 bytes; 1275133 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,On Modular Pluggable Analyses Using Set Interfaces,Computer Architecture
"Schneider, Robert; Riesenhuber, Maximilian",2004-10-20T21:05:18Z,2004-10-20T21:05:18Z,2004-01-14,AIM-2004-004; CBCL-235,http://hdl.handle.net/1721.1/7280,"Numerous psychophysical experiments have shown an important role for attentional modulations in vision. Behaviorally, allocation of attention can improve performance in object detection and recognition tasks. At the neural level, attention increases firing rates of neurons in visual cortex whose preferred stimulus is currently attended to. However, it is not yet known how these two phenomena are linked, i.e., how the visual system could be ""tuned"" in a task-dependent fashion to improve task performance. To answer this question, we performed simulations with the HMAX model of object recognition in cortex [45]. We modulated firing rates of model neurons in accordance with experimental  results about effects of feature-based attention on single neurons and measured changes in the model's performance in a variety of object recognition tasks. It turned out that recognition performance could only be improved under very limited circumstances and that attentional influences on the process of object  recognition per se tend to display a lack of specificity or raise false alarm rates. These observations lead us to postulate a new role for the observed attention-related neural response modulations.",38 p.; 4871469 bytes; 1392271 bytes,application/postscript; application/pdf,en_US,AIM-2004-004; CBCL-235,AI; object recognition; attention; vision; modeling,On the difficulty of feature-based attentional modulations in visual object recognition: A modeling study.,
"Schneider, Robert; Riesenhuber, Maximilian",2005-12-22T01:18:52Z,2005-12-22T01:18:52Z,2004-01-14,MIT-CSAIL-TR-2004-001; AIM-2004-004; CBCL-235,http://hdl.handle.net/1721.1/30442,"Numerous psychophysical experiments have shown an important role for attentional modulations in vision. Behaviorally, allocation of attention can improve performance in object detection and recognition tasks. At the neural level, attention increases firing rates of neurons in visual cortex whose preferredstimulus is currently attended to. However, it is not yet known how these two phenomena are linked, i.e., how the visual system could be ""tuned"" in a task-dependent fashion to improve task performance. To answer this question, we performed simulations with the HMAX model of object recognition in cortex [45].We modulated firing rates of model neurons in accordance with experimental   results about effects of feature-based attention on single neurons and measured changes in the model's performance in a variety of object recognition tasks. It turned out that recognition performance could only be improved under very limited circumstances and that attentional influences on the process of object recognition per se tend to display a lack of specificity or raise false alarm rates. These observations lead us to postulate a new role for the observed attention-related neural response modulations.",38 p.; 65171868 bytes; 2503743 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; object recognition; attention; vision; modeling,On the difficulty of feature-based attentional modulations in visual object recognition: A modeling study.,
"Rakhlin, Alexander; Panchenko, Dmitry; Mukherjee, Sayan",2005-12-22T01:18:58Z,2005-12-22T01:18:58Z,2004-01-27,MIT-CSAIL-TR-2004-002; AIM-2004-001; CBCL-233,http://hdl.handle.net/1721.1/30443,"In this paper we focus on the problem of estimating a boundeddensity using a finite combination of densities from a givenclass. We consider the Maximum Likelihood Procedure (MLE) and the greedy procedure described by Li and Barron. Approximation and estimation bounds are given for the above methods. We extend and improve upon the estimation results of Li and Barron, and in particular prove an $O(\frac{1}{\sqrt{n}})$ bound on the estimation error which does not depend on the number of densities in the estimated combination.",11 p.; 9297095 bytes; 498791 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; density estimation; MLE,Risk Bounds for Mixture Density Estimation,
"Wolf, Lior; Amnon Shashua,; Mukherjee, Sayan",2004-10-20T21:05:21Z,2004-10-20T21:05:21Z,2004-01-27,AIM-2004-002; CBCL-234,http://hdl.handle.net/1721.1/7282,"Array technologies have made it possible to record simultaneously the expression pattern of thousands of genes. A fundamental problem in the analysis of gene expression data is the identification of highly relevant genes that either discriminate between phenotypic labels or are important with respect to the cellular process studied in the experiment: for example cell cycle or heat shock in yeast experiments, chemical or genetic perturbations of mammalian cell lines, and genes involved in class discovery for human tumors. In this paper we focus on the task of unsupervised gene selection. The problem of selecting a small subset of genes is particularly challenging as the datasets involved are typically characterized by a very small sample size ?? the order of few tens of tissue samples ??d by a very large feature space as the number of genes tend to be in the high thousands. We propose a model independent approach which scores candidate gene selections using spectral properties of the candidate affinity matrix. The algorithm is very straightforward to implement yet contains a number of remarkable properties which guarantee consistent sparse selections. To illustrate the value of our approach we applied our algorithm on five different datasets. The first consists of time course data from four well studied Hematopoietic cell lines (HL-60, Jurkat, NB4, and U937). The other four datasets include three well studied treatment outcomes (large cell lymphoma, childhood medulloblastomas, breast tumors) and one unpublished dataset (lymph status). We compared our approach both with other unsupervised methods (SOM,PCA,GS) and with supervised methods (SNR,RMB,RFE). The results clearly show that our approach considerably outperforms all the other unsupervised approaches in our study, is competitive with supervised methods and in some case even outperforms supervised approaches.",2062939 bytes; 836436 bytes,application/postscript; application/pdf,en_US,AIM-2004-002; CBCL-234,AI,Selecting Relevant Genes with a Spectral Approach,
"Wolf, Lior; Shashua, Amnon; Mukherjee, Sayan",2005-12-22T01:19:04Z,2005-12-22T01:19:04Z,2004-01-27,MIT-CSAIL-TR-2004-003; AIM-2004-002; CBCL-234,http://hdl.handle.net/1721.1/30444,"Array technologies have made it possible to record simultaneouslythe expression pattern of thousands of genes. A fundamental problemin the analysis of gene expression data is the identification ofhighly relevant genes that either discriminate between phenotypiclabels or are important with respect to the cellular process studied inthe experiment: for example cell cycle or heat shock in yeast experiments,chemical or genetic perturbations of mammalian cell lines,and genes involved in class discovery for human tumors. In this paperwe focus on the task of unsupervised gene selection. The problemof selecting a small subset of genes is particularly challengingas the datasets involved are typically characterized by a very smallsample size Â— in the order of few tens of tissue samples Â— andby a very large feature space as the number of genes tend to bein the high thousands. We propose a model independent approachwhich scores candidate gene selections using spectral properties ofthe candidate affinity matrix. The algorithm is very straightforwardto implement yet contains a number of remarkable properties whichguarantee consistent sparse selections. To illustrate the value of ourapproach we applied our algorithm on five different datasets. Thefirst consists of time course data from four well studied Hematopoieticcell lines (HL-60, Jurkat, NB4, and U937). The other fourdatasets include three well studied treatment outcomes (large celllymphoma, childhood medulloblastomas, breast tumors) and oneunpublished dataset (lymph status). We compared our approachboth with other unsupervised methods (SOM,PCA,GS) and withsupervised methods (SNR,RMB,RFE). The results clearly showthat our approach considerably outperforms all the other unsupervisedapproaches in our study, is competitive with supervised methodsand in some case even outperforms supervised approaches.",0 p.; 12089662 bytes; 629163 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI,Selecting Relevant Genes with a Spectral Approach,
"Rakhlin, Alexander; Panchenko, Dmitry; Mukherjee, Sayan",2004-10-20T21:05:19Z,2004-10-20T21:05:19Z,2004-01-27,AIM-2004-001; CBCL-233,http://hdl.handle.net/1721.1/7281,"In this paper we focus on the problem of estimating a bounded density using a finite combination of densities from a given class. We consider the Maximum Likelihood Procedure (MLE) and  the greedy procedure described by Li and Barron. Approximation  and estimation bounds are given for the above methods. We extend and improve upon the estimation results of Li and Barron, and in particular prove an $O(\\frac{1}{\\sqrt{n}})$ bound on the estimation error which does not depend on the number of densities in the estimated combination.",11 p.; 1656004 bytes; 658609 bytes,application/postscript; application/pdf,en_US,AIM-2004-001; CBCL-233,AI; density estimation; MLE,Risk Bounds for Mixture Density Estimation,
"Grauman, Kristen; Shakhnarovich, Gregory; Darrell, Trevor",2004-10-08T20:43:09Z,2004-10-08T20:43:09Z,2004-01-28,AIM-2004-003,http://hdl.handle.net/1721.1/6735,"Recovering a volumetric model of a person, car, or other object of interest from a single snapshot would be useful for many computer graphics applications. 3D model estimation in general is hard, and currently requires active sensors, multiple views, or integration over time. For a known object class, however, 3D shape can be successfully inferred from a single snapshot. We present a method for generating a ``virtual visual hull''-- an estimate of the 3D shape of an object from a known class, given a single silhouette observed from an unknown viewpoint. For a given class, a large database of multi-view silhouette examples from calibrated, though possibly varied, camera rigs are collected. To infer a novel single view input silhouette's virtual visual hull, we search for 3D shapes in the database which are most consistent with the observed contour. The input is matched to component single views of the multi-view training examples. A set of viewpoint-aligned virtual views are generated from the visual hulls corresponding to these examples. The 3D shape estimate for the input is then found by interpolating between the contours of these aligned views. When the underlying shape is ambiguous given a single view silhouette, we produce multiple visual hull hypotheses; if a sequence of input images is available, a dynamic programming approach is applied to find the maximum likelihood path through the feasible hypotheses over time. We show results of our algorithm on real and synthetic images of people.",25 p.; 7098694 bytes; 2050007 bytes,application/postscript; application/pdf,en_US,AIM-2004-003,AI; visual hulls; silhouettes; nearest neighbors,Virtual Visual Hulls: Example-Based 3D Shape Estimation from a Single Silhouette,
"Grauman, Kristen; Shakhnarovich, Gregory; Darrell, Trevor",2005-12-22T01:19:14Z,2005-12-22T01:19:14Z,2004-01-28,MIT-CSAIL-TR-2004-004; AIM-2004-003,http://hdl.handle.net/1721.1/30445,"Recovering a volumetric model of a person, car, or other objectof interest from a single snapshot would be useful for many computergraphics applications.  3D model estimation in general is hard, andcurrently requires active sensors, multiple views, or integration overtime.  For a known object class, however, 3D shape can be successfullyinferred from a single snapshot.  We present a method for generating a``virtual visual hull''-- an estimate of the 3D shape of an objectfrom a known class, given a single silhouette observed from an unknownviewpoint.  For a given class, a large database of multi-viewsilhouette examples from calibrated, though possibly varied, camerarigs are collected.  To infer a novel single view input silhouette'svirtual visual hull, we search for 3D shapes in the database which aremost consistent with the observed contour.  The input is matched tocomponent single views of the multi-view training examples.  A set ofviewpoint-aligned virtual views are generated from the visual hullscorresponding to these examples.  The 3D shape estimate for the inputis then found by interpolating between the contours of these alignedviews.  When the underlying shape is ambiguous given a single viewsilhouette, we produce multiple visual hull hypotheses; if a sequenceof input images is available, a dynamic programming approach isapplied to find the maximum likelihood path through the feasiblehypotheses over time.  We show results of our algorithm on real andsynthetic images of people.",25 p.; 47215444 bytes; 7506667 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; visual hulls; silhouettes; nearest neighbors,Virtual Visual Hulls: Example-Based 3D Shape Estimation from a Single Silhouette,
"Rinard, Martin; Cadar, Cristian; Dumitran, Daniel; Roy, Daniel M.; Jr., William S. Beebee",2005-12-22T01:19:21Z,2005-12-22T01:19:21Z,2004-02-06,MIT-CSAIL-TR-2004-005; MIT-LCS-TR-935,http://hdl.handle.net/1721.1/30446,"We present a new technique, failure-oblivious computing,that enables programs to continue to execute through memoryerrors without memory corruption. Our safe compilerfor C inserts checks that dynamically detect invalid memoryaccesses. Instead of terminating the execution or throwingan exception, the generated code simply discards invalidwrites and manufactures values to return for invalid reads,enabling the program to continue its normal execution.We have applied failure-oblivious computing to a set ofwidely-used programs that are part of the Linux-based opensourceinteractive computing environment. Our results showthat our techniques 1) make these programs invulnerableto known security attacks that exploit memory errors, and2) enable the programs to continue to operate successfullyto service legitimate requests and satisfy the needs of theirusers even after attacks trigger their memory errors.",10 p.; 21109742 bytes; 788444 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Enhancing Availability and Security Through Failure-Oblivious Computing,Computer Architecture
"Shrobe, Howard; Laddaga, Robert",2005-12-22T01:19:31Z,2005-12-22T01:19:31Z,2004-02-09,MIT-CSAIL-TR-2004-006; AIM-2004-005,http://hdl.handle.net/1721.1/30447,"Traditionally, we've focussed on the question of how to make a system easy to code the first time, or perhaps on how to ease the system's continued evolution.  But if we look at life cycle costs, then we must conclude that the important question is how to make a system easy to operate.  To do this we need to make it easy for the operators to see what's going on and to then manipulate the system so that it does what it is supposed to.  This is a radically different criterion for success.What makes a computer system visible and controllable?  This is a difficult question, but it's clear that today's modern operating systems with nearly 50 million source lines of code are neither.  Strikingly, the MIT Lisp Machine and its commercial successors provided almost the same functionality as today's mainstream sytsems, but with only 1 Million lines of code.  This paper is a retrospective examination of the features of the Lisp Machine hardware and software system.  Our key claim is that by building the Object Abstraction into the lowest tiers of the system, great synergy and clarity were obtained.It is our hope that this is a lesson that can impact tomorrow's designs.  We also speculate on how the spirit of the Lisp Machine could be extended to include a comprehensive access control model and how new layers of abstraction could further enrich this model.",52 p.; 54496871 bytes; 1580494 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; Software Environments; Computer Archicture,New Architectural Models for Visibly Controllable Computing: The Relevance of Dynamic Object Oriented Architecturesand Plan Based Computing Models,
"Shrobe, Howard; Laddaga, Robert",2004-10-22T20:14:43Z,2004-10-22T20:14:43Z,2004-02-09,AIM-2004-005,http://hdl.handle.net/1721.1/7286,"Traditionally, we've focussed on the question of how to make a system easy to code the first time, or  perhaps on how to ease the system's continued evolution. But if we look at life cycle costs, then we  must conclude that the important question is how to make a system easy to operate. To do this we  need to make it easy for the operators to see what's going on and to then manipulate the system so  that it does what it is supposed to. This is a radically different criterion for success.  What makes a computer system visible and controllable? This is a difficult question, but it's clear that  today's modern operating systems with nearly 50 million source lines of code are neither. Strikingly,  the MIT Lisp Machine and its commercial successors provided almost the same functionality as today's  mainstream sytsems, but with only 1 Million lines of code. This paper is a retrospective examination of  the features of the Lisp Machine hardware and software system. Our key claim is that by building the  Object Abstraction into the lowest tiers of the system, great synergy and clarity were obtained. It is our hope that this is a lesson that can impact tomorrow's designs. We also speculate on how the  spirit of the Lisp Machine could be extended to include a comprehensive access control model and how  new layers of abstraction could further enrich this model.",52 p.; 2594625 bytes; 829436 bytes,application/postscript; application/pdf,en_US,AIM-2004-005,AI; Software Environments; Computer Archicture,New Architectural Models for Visibly Controllable Computing: The Relevance of Dynamic Object Oriented Architectures and Plan Based Computing Models,
