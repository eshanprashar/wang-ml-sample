dc.contributor.advisor,dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.title,dc.subject,dc.identifier.citation,dc.description,dc.relation.replaces,dc.relation.uri,dc.relation.isreplacedby,dc.relation,dc.rights,dc.rights.uri,dc.date.updated
Gerald Sussman,"Beal, Jacob",Mathematics and Computation,2006-06-01T16:22:12Z,2006-06-01T16:22:12Z,2006-05-27,MIT-CSAIL-TR-2006-038,http://hdl.handle.net/1721.1/32984,"Distributed computing and live-action roleplaying share many of thesame fundamental problems, as live-action roleplaying games commonly include simulations carried out by their players.Games run by the MIT Assassin's Guild are particularly illustrative ofdistributed computing issues due to their large scope and highcomplexity.I discuss three distributed computing issues addressed by Assassin'sGuild game design---information hiding, error correction, andliveness/consistency tradeoffs---and the relevance of the solutionsused by game writers to current problems in distributed computing.",9 p.; 168640 bytes; 609620 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,What the Assassin's Guild Taught Me About Distributed Computing,,,,,,,,,,
Howard Shrobe,"Bachrach, Jonathan; Beal, Jacob",AIRE,2006-10-03T14:06:44Z,2006-10-03T14:06:44Z,2006-06,MIT-CSAIL-TR-2006-069,http://hdl.handle.net/1721.1/34223,"In many sensor network applications, the network is deployedto approximate a physical space. The network itself is not ofinterest: rather, we are interested in measuring the propertiesof the space it fills, and of establishing control over thebehavior of that space.The spatial nature of sensor network applications meansthat many can be expressed naturally and succinctly in termsof the global behavior of an amorphous medium---a continuouscomputational material filling the space of interest. Althoughwe cannot construct such a material, we can approximateit using a sensor network.Using this amorphous medium abstraction separates sensornetwork problems into two largely independent domains.Above the abstraction barrier we are concerned with longrangecoordination and concise description of applications,while below the barrier we are concerned with fast, efficient,and robust communication between neighboring devices.We apply the amorphous medium abstraction with Proto,a high-level language for programming sensor/actuator networks.Existing applications, such as target tracking andthreat avoidance, can be expressed in only a few lines of Protocode. The applications are then compiled for execution on akernel that approximates an amorphous medium. Programswritten using our Proto implementation have been verified insimulation on over ten thousand nodes, as well as on a networkof Berkeley Motes.",6 p.; 374454 bytes; 4831946 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Programming a Sensor Network as an Amorphous Medium,amorphous computing,DCOSS 2006 (Extended Abstract),,,,,,,,
Eric Grimson,"Dalley, Gerald; Izo, Tomas",Vision,2006-06-12T18:36:58Z,2006-06-12T18:36:58Z,2006-06-12,MIT-CSAIL-TR-2006-043,http://hdl.handle.net/1721.1/32999,"In dealing with long-term tracking databases withwide-area coverage, an important problem is in formulating anintuitive and fast query system for analysis. In such a querysystem, a user who is not a computer vision research should beable to readily specify a novel query to the system and obtainthe desired results. Furthermore, these queries should be able tonot only search out individual actors (e.g. ""find all white cars"")but also find interactions amongst multiple actors (e.g. ""find alldrag racing activities in the city""). Informally, we have foundthat people often use sketches when describing activities andinteractions. In this paper, we demonstrate a preliminary systemthat automatically interprets schematic drawings of activities.The system transforms the schematics into executable code thatsearches a tracking database. Through our query optimization,these queries tend to take orders of magnitude less time to executethan equivalent queries running on a partially-optimized SQLdatabase.",7 p.; 391836 bytes; 7529339 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Schematic Querying of Large Tracking Databases,,,,,,,,,,
Barbara Liskov,"Leong, Ben",Programming Methodology,2006-06-14T14:57:35Z,2006-06-14T14:57:35Z,2006-06-14,MIT-CSAIL-TR-2006-044,http://hdl.handle.net/1721.1/33000,"As wireless sensor networks continue to grow in size, we are facedwith the prospect of emerging wireless networks with hundreds orthousands of nodes. Geographic routing algorithms are a promisingalternative to tradition ad hoc routing algorithms in this new domainfor point-to-point routing, but deployments of such algorithms arecurrently uncommon because of some practical difficulties.This dissertation explores techniques that address two major issues inthe deployment of geographic routing algorithms: (i) the costsassociated with distributed planarization and (ii) the unavailabilityof location information.  We present and evaluate two new algorithmsfor geographic routing: Greedy Distributed Spanning Tree Routing(GDSTR) and Greedy Embedding Spring Coordinates (GSpring).Unlike previous geographic routing algorithms which require theplanarization of the network connectivity graph, GDSTR switches torouting on a spanning tree instead of a planar graph when packets endup at dead ends during greedy forwarding. To choose a direction on thetree that is most likely to make progress towards the destination,each GDSTR node maintains a summary of the area covered by the subtreebelow each of its tree neighbors using convex hulls. This distributeddata structure is called a hull tree. GDSTR not only requires an orderof magnitude less bandwidth to maintain these hull trees than CLDP,the only distributed planarization algorithm that is known to workwith practical radio networks, it often achieves better routingperformance than previous planarization-based geographic routingalgorithms.GSpring is a new virtual coordinate assignment algorithm that derivesgood coordinates for geographic routing when location information isnot available. Starting from a set of initial coordinates for a set ofelected perimeter nodes, GSpring uses a modified spring relaxationalgorithm to incrementally adjust virtual coordinates to increase theconvexity of voids in the virtual routing topology. This reduces theprobability that packets will end up in dead ends during greedyforwarding, and improves the routing performance of existinggeographic routing algorithms.The coordinates derived by GSpring yield comparable routingperformance to that for actual physical coordinates and significantlybetter performance than that for NoGeo, the best existing algorithmfor deriving virtual coordinates for geographic routing. Furthermore,GSpring is the first known algorithm that is able to derivecoordinates that achieve better geographic routing performance thanactual physical coordinates for networks with obstacles.",150 p.; 3957081 bytes; 32739307 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,New Techniques for Geographic Routing,,,PhD thesis,,,,,,,
Trevor Darrell,"Grauman, Kristen; Darrell, Trevor",Vision,2006-06-15T21:37:00Z,2006-06-15T21:37:00Z,2006-06-15,MIT-CSAIL-TR-2006-045,http://hdl.handle.net/1721.1/33002,"Pyramid intersection is an efficient method for computing an approximate partial matching between two sets of feature vectors. We introduce a novel pyramid embedding based on a hierarchy of non-uniformly shaped bins that takes advantage of the underlying structure of the feature space and remains accurate even for sets with high-dimensional feature vectors.  The matching similarity is computed in linear time and forms a Mercer kernel.  We also show how the matching itself (a correspondence field) may be extracted for a small increase in computational cost. Whereas previous matching approximation algorithms suffer from distortion factors that increase linearly with the feature dimension, we demonstrate thatour approach can maintain constant accuracy even as the feature dimension increases. When used as a kernel in a discriminative classifier, our approach achieves improved object recognition results over a state-of-the-art set kernel.",10 p.; 14140112 bytes; 5515480 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Approximate Correspondences in High Dimensions,,,,,,,,,,
Nancy Lynch,"Canetti, Ran; Cheung, Ling; Kaynar, Dilsun; Liskov, Moses; Lynch, Nancy; Pereira, Olivier; Segala, Roberto",Theory of Computation,2006-06-19T18:52:04Z,2006-06-19T18:52:04Z,2006-06-19,MIT-CSAIL-TR-2006-046,http://hdl.handle.net/1721.1/33154,"We demonstrate how to carry out cryptographic security analysis ofdistributed protocols within the Probabilistic I/O Automataframework of Lynch, Segala, and Vaandrager. This framework providestools for arguing rigorously about the concurrency and schedulingaspects of protocols, and about protocols presented at differentlevels of abstraction. Consequently, it can help in makingcryptographic analysis more precise and less susceptible to errors.We concentrate on a relatively simple two-party Oblivious Transferprotocol, in the presence of a semi-honest adversary (essentially,an eavesdropper). For the underlying cryptographic notion ofsecurity, we use a version of Canetti's Universally Composablesecurity.In spite of the relative simplicity of the example, the exercise isquite nontrivial. It requires taking many fundamental issues intoaccount, including nondeterministic behavior, scheduling,resource-bounded computation, and computational hardness assumptionsfor cryptographic primitives.",129 p.; 1111678 bytes; 7337435 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Using Probabilistic I/O Automata to Analyze an Oblivious Transfer Protocol,,"January 10, 2006",,http://hdl.handle.net/1721.1/30566,http://hdl.handle.net/1721.1/30566,,,,,
Nancy Lynch,"Canetti, Ran; Cheung, Ling; Kaynar, Dilsun; Liskov, Moses; Lynch, Nancy; Pereira, Olivier; Segala, Roberto",Theory of Computation,2006-06-20T21:18:08Z,2006-06-20T21:18:08Z,2006-06-20,MIT-CSAIL-TR-2006-047,http://hdl.handle.net/1721.1/33217,"The Probabilistic I/O Automata framework of Lynch, Segala and Vaandrager provides tools for precisely specifying protocols and reasoning about theircorrectness using multiple  levels of abstraction, based on implementation relationships between these levels. We enhance this framework to allow analyzingprotocols that use cryptographic primitives. This requires resolving andreconciling issues such as nondeterministic behavior and scheduling, randomness,resource-bounded computation, and computational hardness assumptions.  The enhanced framework allows for more rigorous and systematic analysis of cryptographic protocols. To demonstrate the use of this framework, we present an example analysis that we have  done for an Oblivious Transfer protocol.",98 p.; 898579 bytes; 5581045 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Using Task-Structured Probabilistic I/O Automata to Analyze an Oblivious Transfer Protocol,,"June 19, 2006",,http://hdl.handle.net/1721.1/31310,http://hdl.handle.net/1721.1/35918; http://hdl.handle.net/1721.1/31310,http://hdl.handle.net/1721.1/35918,,,,
Peter Szolovits,"Sibanda, Tawanda Carleton",Clinical Decision-Making,2006-06-29T13:22:10Z,2006-06-29T13:22:10Z,2006-06-28,MIT-CSAIL-TR-2006-048,http://hdl.handle.net/1721.1/33223,"In this thesis, we detail an approach to extracting key information in medical discharge summaries. Starting with a narrative patient report, we first identify and remove information that compromises privacy (de-identification);next we recognize words and phrases in the text belonging to semantic categories of interest to doctors (semantic category recognition).For disease and symptoms, we determine whether the problem is present, absent, uncertain, or associated with somebody else (assertion classification). Finally, we classify the semantic relationships existing between our categories (semantic relationship classification).Our approach utilizes a series of statistical models that rely heavily on local lexical and syntactic context, and achieve competitive results compared to more complexNLP solutions. We conclude the thesis by presenting the design for the Category and Relationship Extractor (CaRE). CaRE combines our solutions to de-identification, semantic category recognition, assertion classification, and semantic relationship classification into a singleapplication that facilitates the easy extraction of semantic information from medical text.",108 p.; 2366072 bytes; 9070788 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Was the Patient Cured? Understanding Semantic Categories and Their Relationships in Patient Records,medical language processing; MLP; discharge summary,,MEng thesis,,,,,,,
Dina Katabi,"Chachulski, Szymon; Jennings, Michael; Katti, Sachin; Katabi, Dina",Networks & Mobile Systems,2006-07-03T14:16:54Z,2006-07-03T14:16:54Z,2006-06-30,MIT-CSAIL-TR-2006-049,http://hdl.handle.net/1721.1/33230,"Opportunistic routing has the potential to substantially increase wireless network throughput. Prior work on opportunistic routing, however, requires tight node coordination. Different nodes in a network must have knowledge of which packets other nodes have received. Furthermore, the nodes have to agree on which nodes should transmit which packets. Such coordination becomes fragile in dense or large networks.This paper introduces MORe, a new opportunistic routing protocol that avoids node-coordination. Our design is rooted in the theory of network coding.Routers code packets going to the same destination and forward the coded versions. The destination decodes and recovers the original packets. This approach needs no coordination and provably maximizes network throughput. We have implemented our design and evaluated it in a 25-node testbed. Our results show that MORE provides an average throughput increase of 60% and a maximum of 10-fold, demonstrating that the theoretical gains promised by network coding are realizable in practice.",12 p.; 22051455 bytes; 883727 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,MORE: A Network Coding Approach to Opportunistic Routing,Network Coding; Opportunistic Routing; Wireless Networks,,,,,,,,,
Dina Katabi,"Teow, Loo Nin; Katabi, Dina",Networks & Mobile Systems,2006-07-12T17:06:52Z,2006-07-12T17:06:52Z,2006-07-04,MIT-CSAIL-TR-2006-050,http://hdl.handle.net/1721.1/33234,"This paper introduces a new application: predicting the Internet provider-customer market. We cast the problem in the collaborative filtering framework, where we use current and past customer-provider relationships to compute for each Internet customer a ranking of potential future service providers. Furthermore, for each Internet service provider (ISP), we rank potential future customers. We develop a novel iterative ranking algorithm that draws inspiration from several sources, including collaborative filtering, webpage ranking, and kernel methods. Further analysis of our algorithm shows that it can be formulated in terms of an affine eigenvalue problem. Experiments on the actual Internet customer-provider data show promising results.",9 p.; 1308662 bytes; 269609 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Iterative Collaborative Ranking of  Customers and Providers,Network Analysis; Autonomous Systems,,,,,,,,,
Tomaso Poggio,"Das, Sanmay",Center for Biological and Computational Learning (CBCL),2006-07-13T11:26:51Z,2006-07-13T11:26:51Z,2006-07-12,MIT-CSAIL-TR-2006-051; CBCL-262,http://hdl.handle.net/1721.1/33235,"This thesis seeks to contribute to the understanding of markets populated by boundedly rational agents who learn from experience. Bounded rationality and learning have both been the focus of much research in computer science, economics and finance theory. However, we are at a critical stage in defining the direction of future research in these areas. It is now clear that realistic learning problems faced by agents in market environments are often too hard to solve in a classically rational fashion. At the same time, the greatly increased computational power available today allows us to develop and analyze richer market models and to evaluate different learning procedures and algorithms within these models. The danger is that the ease with which complex markets can be simulated could lead to a plethora of models that attempt to explain every known fact about different markets. The first two chapters of this thesis define a principled approach to studying learning in rich models of market environments, and the rest of the thesis provides a proof of concept by demonstrating the applicability of this approach in modeling settings drawn from two different broad domains, financial market microstructure and search theory. In the domain of market microstructure, this thesis extends two important models from the theoretical finance literature. The third chapter introduces an algorithm for setting prices in dealer markets based on the model of Glosten and Milgrom (1985), and produces predictions about the behavior of prices in securities markets. In some cases, these results confirm economic intuitions in a significantly more complex setting (like the existence of a local profit maximum for a monopolistic market-maker) and in others they can be used to provide quantitative guesses for variables such as rates of convergence to efficient market conditions following price jumps that provide insider information. The fourth chapter studies the problem faced by a trader with insider information in KyleÂ’s (1985) model. I show how the insider trading problem can be usefully analyzed from the perspective of reinforcement learning when some important market parameters are unknown, and that the equilibrium behavior of an insider who knows these parameters can be learned by one who does not, but also that the time scale of convergence to the equilibrium behavior may be impractical, and agents with limited time horizons may be better off using approximate algorithms that do not converge to equilibrium behavior. The fifth and sixth chapters relate to search problems. Chapter 5 introduces models for a class of problems in which there is a search Â“seasonÂ” prior to hiring or matching, like academic job markets. It solves for expected values in many cases, and studies the difference between a Â“high informationÂ” process where applicants are immediately told when they have been rejected and a Â“low informationÂ” process where employers do not send any signal when they reject an applicant. The most important intuition to emerge from the results is that the relative benefit of the high information process is much greater when applicants do not know their own Â“attractiveness,Â” which implies that search markets might be able to eliminate inefficiencies effectively by providing good information, and we do not always have to think about redesigning markets as a whole. Chapter 6 studies two-sided search explicitly and introduces a new class of multi-agent learning problems, two-sided bandit problems, that capture the learning and decision problems of agents in matching markets in which agents must learn their preferences. It also empirically studies outcomes under different periodwise matching mechanisms and shows that some basic intuitions about the asymptotic stability of matchings are preserved in the model. For example, when agents are matched in each period using the Gale-Shapley algorithm, asymptotic outcomes are always stable, while a matching mechanism that induces a stopping problem for some agents leads to the lowest probabilities of stability. By contributing to the state of the art in modeling different domains using computational techniques, this thesis demonstrates the success of the approach to modeling complex economic and social systems that is prescribed in the first two chapters.",149 p.; 860631 bytes; 5532424 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"Dealers, Insiders and Bandits: Learning and its Effects on Market Outcomes",,,PhD thesis,,,,,,,
Nancy Lynch,"Fan, Rui; Lynch, Nancy",Theory of Computation,2008-07-28T13:30:11Z,2008-07-28T13:30:11Z,2006-07-23,MIT-CSAIL-TR-2008-047,http://hdl.handle.net/1721.1/41890,"We prove an $\Omega(n \log n)$ lower bound on the number ofnon-busywaiting memory accesses by any deterministic algorithm solving$n$ process mutual exclusion that communicates via shared registers.The cost of the algorithm is measured in the \emph{state change} costmodel, a variation of the cache coherent model. Our bound is tight inthis model. We introduce a novel information theoretic prooftechnique. We first establish a lower bound on the information neededby processes to solve mutual exclusion. Then we relate the amount ofinformation processes can acquire through shared memory accesses tothe cost they incur. We believe our proof technique is flexible andintuitive, and may be applied to a variety of other problems andsystem models.",14 p.,,,,An $\Omega(n \log n)$ Lower Bound on the Cost of Mutual Exclusion,Mutual exclusion; Time complexity; Lower bound techniques,,,,,,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,,,
Dina Katabi,"Jaggi, Sidharth; Langberg, Michael; Katti, Sachin; Ho, Tracy; Katabi, Dina; Medard, Muriel",Networks & Mobile Systems,2006-08-14T12:43:17Z,2006-08-14T12:43:17Z,2006-08-05,MIT-CSAIL-TR-2006-053,http://hdl.handle.net/1721.1/33790,"Network coding substantially increases network throughput. But since it involves mixing of information inside the network, a single corrupted packet generated by a malicious node can end up contaminating all the information reaching a destination, preventing decoding. This paper introduces the first distributed polynomial-time rate-optimal network codes that work in the presence of Byzantine nodes. We present algorithms that target adversaries with different attacking capabilities. When the adversary can eavesdrop on all links and jam Z links , our first algorithm achieves a rate of C-2Z, where C is the network capacity. In contrast, when the adversary has limited snooping capabilities, we provide algorithms that achieve the higher rate of C-Z.",9 p.; 347172 bytes; 1152836 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Resilient Network Coding In the Presence of Byzantine Adversaries,"Coding Theory; Security, trust, & privacy; Network Coding; Byzantine Adversarie",,,,,,,,,
Tomaso Poggio,"Wolf, Florian; Poggio, Tomaso; Sinha, Pawan",Center for Biological and Computational Learning (CBCL),2006-08-14T12:29:13Z,2006-08-14T12:29:13Z,2006-08-09,MIT-CSAIL-TR-2006-054; CBCL-263,http://hdl.handle.net/1721.1/33789,"Humans are remarkably adept at classifying text documents into cate-gories.  For instance, while reading a news story, we are rapidly able to assess whether it belongs to the domain of finance, politics or sports.  Automating this task would have applications for content-based search or filtering of digital documents.  To this end, it is interesting to investigate the nature of information humans use to classify documents.  Here we report experimental results suggesting that this information might, in fact, be quite simple.  Using a paradigm of progressive revealing, we determined classification performance as a function of number of words.  We found that subjects are able to achieve similar classification accuracy with or without syntactic information across a range of passage sizes.  These results have implications for models of human text-understanding and also allow us to estimate what level of performance we can expect, in principle, from a system without requiring a prior step of complex natural language processing.",7 p.; 1617611 bytes; 134084 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Human Document Classification Using Bags of Words,text classification,,,,,,,,,
Trevor Darrell,"Grauman, Kristen Lorraine",Vision,2008-06-16T14:15:28Z,2008-06-16T14:15:28Z,2006-08-11,MIT-CSAIL-TR-2008-035,http://hdl.handle.net/1721.1/41864,"In numerous domains it is useful to represent a single example by the collection of local features or parts that comprise it. In computer vision in particular, local image features are a powerful way to describe images of objects and scenes. Their stability under variable image conditions is critical for success in a wide range of recognition and retrieval applications. However, many conventional similarity measures and machine learning algorithms assume vector inputs. Comparing and learning from images represented by sets of local features is therefore challenging, since each set may vary in cardinality and its elements lack a meaningful ordering. In this thesis I present computationally efficient techniques to handle comparisons, learning, and indexing with examples represented by sets of features. The primary goal of this research is to design and demonstrate algorithms that can effectively accommodate this useful representation in a way that scales with both the representation size as well as the number of images available for indexing or learning.I introduce the pyramid match algorithm, which efficiently forms an implicit partial matching between two sets of feature vectors. The matching has a linear time complexity, naturally forms a Mercer kernel, and is robust to clutter or outlier features, a critical advantage for handling images with variable backgrounds, occlusions, and viewpoint changes. I provide bounds on the expected error relative to the optimal partial matching. For very large databases, even extremely efficient pairwise comparisons may not offer adequately responsive query times. I show how to perform sub-linear time retrievals under the matching measure with randomized hashing techniques, even when input sets have varying numbers of features.My results are focused on several important vision tasks, including applications to content-based image retrieval, discriminative classification for object recognition, kernel regression, and unsupervised learning of categories. I show how the dramatic increase in performance enables accurate and flexible image comparisons to be made on large-scale data sets, and removes the need to artificially limit the number of local descriptions used per image when learning visual categories.",153 p.,,,,Matching Sets of Features for Efficient Retrieval and Recognition,"object recognition, partial match, matching approximation, pyramid match kernel, image matching, image search, correspondences, local image features",,,,,,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory; ,,,
Brian Williams,"Effinger, Robert",Model-based Embedded and Robotic Systems,2018-01-30T23:46:07Z,2018-01-30T23:46:07Z,2006-08-25,,http://hdl.handle.net/1721.1/113365,"Autonomous robots are being considered for increasingly capable roles in our society, such as urban search and rescue, automation for assisted living, and lunar habitat construction. To fulfill these roles, teams of autonomous robots will need to cooperate together to accomplish complex mission objectives in uncertain and dynamic environments. In these environments, autonomous robots face a host of new challenges, such as responding robustly to timing uncertainties and perturbations, task and coordination failures, and equipment malfunctions. In order to address these challenges, this thesis advocates a novel planning approach, called temporally-flexible contingent planning. A temporally-flexible contingent plan is a compact encoding of methods for achieving the mission objectives which incorporates robustness through flexible task durations, redundant methods, constraints on when methods are applicable, and preferences between methods. This approach enables robots to adapt to unexpected changes on-the-fly by selecting alternative methods at runtime in order to satisfy as best possible the mission objectives. The drawback to this approach, however, is the computational overhead involved in selecting alternative methods at runtime in response to changes. If a robot takes too long to select a new plan, it could fail to achieve its near-term mission objectives and potentially incur damage. To alleviate this problem, and extend the range of applicability of temporally-flexible contingent planning to more demanding real-time systems, this thesis proposes a temporally-flexible contingent plan executive that selects new methods quickly and optimally in response to changes in a robot's health and environment. We enable fast and optimal method selection through two complimentary approaches. First, we frame optimal method selection as a constraint satisfaction problem (CSP) variant, called an Optimal Conditional CSP (OCCSP). Second, we extend fast CSP search algorithms, such as Dynamic Backtracking and Branch-and-Bound Search, to solve OCCSPs. Experiments on an autonomous rover test-bed and on randomly generated plans show that these contributions significantly improve the speed at which robots perform optimal method selection in response to changes in their health status and environment.",115 p.,,,MIT-CSAIL-TR-2018-005,Optimal Temporal Planning at Reactive Time Scales via Dynamic Backtracking Branch and Bound,,,SM thesis,,,,,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,2018-01-30T23:46:07Z
Peter Szolovits,"Hug, Caleb W.",Clinical Decision-Making,2006-08-31T14:29:11Z,2006-08-31T14:29:11Z,2006-08-30,MIT-CSAIL-TR-2006-055,http://hdl.handle.net/1721.1/33957,"Using artificial intelligence to assist physicians in patient care has received sustained interest over the past several decades.  Recently, with automated systems at most bedsides, the amount of patient information collected continues to increase, providing specific impetus for intelligent systems that can interpret this information. In fact, the large set of sensors and test results, often measured repeatedly over long periods of time, make it challenging for caregivers to quickly utilize all of the data for optimal patient treatment.This research focuses on predicting the survival of ICU patients throughout their stay.  Unlike traditional static mortality models, this survival prediction is explored as an indicator of patient state and trajectory.  Using survival analysis techniques and machine learning, models are constructed that predict individual patient survival probabilities at fixed intervals in the future.  These models seek to help physicians interpret the large amount of data available in order to provide optimal patient care.We find that the survival predictions from our models are comparable to survival predictions using the SAPS score, but are available throughout the patient's ICU course instead of only at 24 hours after admission.  Additionally, we demonstrate effective prediction of patient mortality over fixed windows in the future.",126 p.; 3075332 bytes; 103809024 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Predicting the Risk and Trajectory of Intensive Care Patients Using Survival Models,Intelligent Monitoring,,SM thesis,,,,,,,
Michael Ernst,"Artzi, Shay; Ernst, Michael D.; Kiezun, Adam; Pacheco, Carlos; Perkins, Jeff H.",Program Analysis,2006-09-05T16:31:22Z,2006-09-05T16:31:22Z,2006-08-31,MIT-CSAIL-TR-2006-056,http://hdl.handle.net/1721.1/33959,"A test input for an object-oriented program typically consists of asequence of method calls that use the API defined by the programunder test. Generating legal test inputs can be challenging because,for some programs, the set of legal method sequences is much smallerthan the set of all possible sequences; without a formalspecification of legal sequences, an input generator is bound toproduce mostly illegal sequences.We propose a scalable technique that combines dynamic analysis withrandom testing to help an input generator create legal test inputswithout a formal specification, even for programs in whichmost sequences are illegal. The technique uses an example executionof the program to infer a model of legal call sequences, and usesthe model to guide a random input generator towards legal butbehaviorally-diverse sequences.We have implemented our technique for Java, in a tool calledPalulu, and evaluated its effectiveness in creating legal inputsfor real programs. Our experimental results indicate that thetechnique is effective and scalable. Our preliminary evaluationindicates that the technique can quickly generate legal sequencesfor complex inputs: in a case study, Palulu created legal testinputs in seconds for a set of complex classes, for which it took anexpert thirty minutes to generate a single legal input.",8 p.; 412269 bytes; 923064 bytes,application/pdf; application/postscript,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Finding the needles in the haystack: Generating legal test inputs for object-oriented programs,,,,,,,,,,
Tommi Jaakkola,"Monteleoni, Claire E.",Tommi's Machine Learning,2006-09-05T16:26:12Z,2006-09-05T16:26:12Z,2006-09-01,MIT-CSAIL-TR-2006-057,http://hdl.handle.net/1721.1/33958,"Many practical problems such as forecasting, real-time decisionmaking, streaming data applications, and resource-constrainedlearning, can be modeled as learning with online constraints.  Thisthesis is concerned with analyzing and designing algorithms forlearning under the following online constraints: 1) The algorithm hasonly sequential, or one-at-time, access to data.  2) The time andspace complexity of the algorithm must not scale with the number ofobservations.  We analyze learning with online constraints in avariety of settings, including active learning.  The active learningmodel is applicable to any domain in which unlabeled data is easy tocome by and there exists a (potentially difficult or expensive)mechanism by which to attain labels.First, we analyze a supervised learning framework in which nostatistical assumptions are made about the sequence of observations,and algorithms are evaluated based on their regret, i.e. theirrelative prediction loss with respect to the hindsight-optimalalgorithm in a comparator class.  We derive a lower bound on regretfor a class of online learning algorithms designed to track shiftingconcepts in this framework.  We apply an algorithm we provided inprevious work, that avoids this lower bound, to an energy-managementproblem in wireless networks, and demonstrate this application in anetwork simulation. Second, we analyze a supervised learning frameworkin which the observations are assumed to be iid, and algorithms arecompared by the number of prediction mistakes made in reaching atarget generalization error.  We provide a lower bound on mistakes forPerceptron, a standard online learning algorithm, for this framework.We introduce a modification to Perceptron and show that it avoids thislower bound, and in fact attains the optimal mistake-complexity forthis setting.Third, we motivate and analyze an online active learning framework.The observations are assumed to be iid, and algorithms are judged bythe number of label queries to reach a target generalizationerror. Our lower bound applies to the active learning setting as well,as a lower bound on labels for Perceptron paired with any activelearning rule.  We provide a new online active learning algorithm thatavoids the lower bound, and we upper bound its label-complexity.  Theupper bound is optimal and also bounds the algorithm's total errors(labeled and unlabeled).  We analyze the algorithm further, yielding alabel-complexity bound under relaxed assumptions.  Using opticalcharacter recognition data, we empirically compare the new algorithmto an online active learning algorithm with data-dependent performanceguarantees, as well as to the combined variants of these twoalgorithms.",102 p.; 11237521 bytes; 2402633 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Learning with Online Constraints: Shifting Concepts and Active Learning,,,PhD thesis,,,,,,,
William Freeman,"Fergus, Rob; Torralba, Antonio; Freeman, William T.",Vision,2006-09-07T18:46:57Z,2006-09-07T18:46:57Z,2006-09-02,MIT-CSAIL-TR-2006-058,http://hdl.handle.net/1721.1/33962,"We call a random lens one for which the function relating the input light ray to the output sensor location is pseudo-random. Imaging systems with random lensescan expand the space of possible camera designs, allowing new trade-offs in optical design and potentially adding new imaging capabilities. Machine learningmethods are critical for both camera calibration and image reconstruction from the sensor data. We develop the theory and compare two different methods for calibration and reconstruction: an MAP approach, and basis pursuit from compressive sensing. We show proof-of-concept experimental results from a random lens made from a multi-faceted mirror, showing successful calibration and image reconstruction. We illustrate the potential for super-resolution and 3D imaging.",9 p.; 52671890 bytes; 1133927 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Random Lens Imaging,,,,,,,,,,
