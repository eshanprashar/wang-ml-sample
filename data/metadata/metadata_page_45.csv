dc.contributor.advisor,dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.uri,dc.description,dc.description.abstract,dc.format.extent,dc.relation.ispartofseries,dc.rights,dc.rights.uri,dc.title,dc.date.updated,dc.subject,dc.language.rfc3066,dc.publisher,dc.contributor,dc.contributor.editor,dc.description.sponsorship,dc.identifier.citation
Brian Williams,"Ono, Masahiro",Model-based Embedded and Robotic Systems,2018-01-31T00:01:17Z,2018-01-31T00:01:17Z,2012-01-20,http://hdl.handle.net/1721.1/113370,SM thesis,"The goal of this thesis is to develop a distributed control system for a smart grid with sustainable homes. A central challenge is how to enhance energy efficiency in the presence of uncertainty. A major source of uncertainty in a smart grid is intermittent energy production by renewable energy sources. In the face of global climate change, it is crucial to reduce dependence on fossil fuels and shift to renewable energy sources, such as wind and solar. However, a large-scale introduction of wind and solar generation to an electrical grid poses a significant risk of blackouts since the energy supplied by the renewables is unpredictable and intermittent. The uncertain behavior of renewable energy sources increases the risk of blackouts. Therefore, an important challenge is to develop an intelligent control mechanism for the electrical grid that is both reliable and efficient. Uncertain weather conditions and human behavior pose challenges for a smart home. For example, autonomous room temperature control of a residential building may occasionally make the room environment uncomfortable for residents. Autonomous controllers must be able to take residents' preferences as an input, and to control the indoor environment in an energy-efficient manner while limiting the risk of failure to meet the residents' requirements in the presence of uncertainties. In order to overcome these challenges, we propose a distributed robust control method for a smart grid that includes smart homes as its building components. The proposed method consists of three algorithms: 1) market-based contingent energy dispatcher for an electrical grid, 2) a risk-sensitive plan executive for temperature control of a residential building, and 3) a chance-constrained model-predictive controller with a probabilistic guarantee of constraint satisfaction, which can control continuously operating systems such as an electrical grid and a building. We build the three algorithms upon the chance-constrained programming framework: minimization of a given cost function with chance constraints, which bound the probability of failure to satisfy given state constraints. Although these technologies provide promising capabilities, they cannot contribute to sustainability unless they are accepted by the society. In this thesis we specify policy challenges for a smart grid and a smart home, and discuss policy options that gives economical and regulatory incentives for the society to introduce these technologies on a large scale.",145 p.,MIT-CSAIL-TR-2018-010,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,Energy-efficient Control of a Smart Grid with Sustainable Homes based on Distributing Risk,2018-01-31T00:01:18Z,,,,,,,
Nick Roy,"Tellex, Stefanie; Thaker, Pratiksha; Deits, Robin; Simeonov, Dimitar; Kollar, Thomas; Roy, Nicholas","Robotics, Vision & Sensor Networks",2012-01-24T22:30:02Z,2012-01-24T22:30:02Z,2012-01-23,http://hdl.handle.net/1721.1/68651,,"Our goal is to build robots that can robustly interact with humans using natural language. This problem is extremely challenging because human language is filled with ambiguity, and furthermore, the robot's model of the environment might be much more limited than the human partner. When humans encounter ambiguity in dialog with each other, a key strategy to resolve it is to ask clarifying questions about whatthey do not understand. This paper describes an approach for enabling robots to take the same approach: asking the human partner clarifying questions about ambiguous commands in order to infer better actions. The robot fuses information from the command, the question, and the answer by creating a joint probabilistic graphical model in the Generalized Grounding Graph framework. We demonstrate that by performing inference using information from the command, question and answer, the robot is able to infer object groundings and follow commands with higher accuracythan by using the command alone.",2 p.,MIT-CSAIL-TR-2012-002,,,Toward a Probabilistic Approach to Acquiring Information from Human Partners Using Language,,"dialog, robotics, question-asking",en-US,,,,,
Tomaso Poggio,"Tacchetti, Andrea; Mallapragada, Pavan S.; Santoro, Matteo; Rosasco, Lorenzo",Center for Biological and Computational Learning (CBCL),2012-02-06T21:15:06Z,2012-02-06T21:15:06Z,2012-01-31,http://hdl.handle.net/1721.1/69034,,"We present GURLS, a toolbox for supervised learning based on the regularized least squares algorithm. The toolbox takes advantage of all the favorable properties of least squares and is tailored to deal in particular with multi-category/multi-label problems. One of the main advantages of GURLS is that it allows training and tuning a multi-category classifier at essentially the same cost of one single binary classifier. The toolbox provides a set of basic functionalities including different training strategies and routines to handle computations with very large matrices by means of both memory-mapped storage and distributed task execution. The system is modular and can serve as a basis for easily prototyping new algorithms. The toolbox is available for download, easy to set-up and use.",6 p.,MIT-CSAIL-TR-2012-003; CBCL-306,,,GURLS: a Toolbox for Regularized Least Squares Learning,,"Matlab; Computational Learning; Regularized Least Squares; Large Scale, Multiclass problems; C++",en-US,MIT CSAIL,,,,
Brian Williams,"Effinger, Robert",Model-based Embedded and Robotic Systems,2018-01-30T23:46:14Z,2018-01-30T23:46:14Z,2012-02-02,http://hdl.handle.net/1721.1/113366,PhD thesis,"In this thesis, we argue that autonomous robots operating in hostile and uncertain environments can improve robustness by computing and reasoning explicitly about risk. Autonomous robots with a keen sensitivity to risk can be trusted with critical missions, such as exploring deep space and assisting on the battlefield. We introduce a novel, risk-minimizing approach to program execution that utilizes program flexibility and estimation of risk in order to make runtime decisions that minimize the probability of program failure. Our risk-minimizing executive, called Murphy, utilizes two forms of program flexibility, 1) flexible scheduling of activity timing, and 2) redundant choice between subprocedures, in order to minimize two forms of program risk, 1) exceptions arising from activity failures, and 2) exceptions arising from timing constraint violations in a program. Murphy takes two inputs, a program written in a nondeterministic variant of the Reactive Model-based Programming Language (RMPL) and a set of stochastic activity failure models, one for each activity in a program, and computes two outputs, a risk-minimizing decision policy and value function. The decision policy informs Murphy which decisions to make at runtime in order to minimize risk, while the value function quantifies risk. In order to execute with low latency, Murphy computes the decision policy and value function offline, as a compilation step prior to program execution. In this thesis, we develop three approaches to RMPL program execution. First, we develop an approach that is guaranteed to minimize risk. For this approach, we reason probabilistically about risk by framing program execution as a Markov Decision Process (MDP). Next, we develop an approach that avoids risk altogether. For this approach, we frame program execution as a novel form of constraint-based temporal reasoning. Finally, we develop an execution approach that trades optimality in risk avoidance for tractability. For this approach, we leverage prior work in hierarchical decomposition of MDPs in order to mitigate complexity. We benchmark the tractability of each approach on a set of representative RMPL programs, and we demonstrate the applicability of the approach on a humanoid robot simulator.",161 p.,MIT-CSAIL-TR-2018-006,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,Risk-minimizing program execution in robotic domains,2018-01-30T23:46:14Z,,,,Brian Williams; Model-based Embedded and Robotic Systems,,,
Brian Williams,"Ono, Masahiro",Model-based Embedded and Robotic Systems,2018-01-31T00:01:14Z,2018-01-31T00:01:14Z,2012-02-02,http://hdl.handle.net/1721.1/113369,PhD thesis,"There is an increasing need for robust optimal plan execution for multi-agent systems in uncertain environments, while guaranteeing an acceptable probability of success. For ex- ample, a fleet of unmanned aerial vehicles (UAVs) and autonomous underwater vehicles (AUVs) are required to operate autonomously for an extensive mission duration in an uncertain environment. Previous work introduced the concept of a model-based executive, which increases the level of autonomy, elevating the level at which systems are commanded. This thesis develops model-based executives that reason explicitly from a stochastic plant model to find the optimal course of action, while ensuring that the probability of failure is within a user-specified risk bound. This thesis presents two robust mode-based executives: probabilisticSulu orp-Sulu, and distributedprobabilisticSulu or dp-Sulu. The objective for p-Sulu and dp-Sulu is to allow users to command continuous, stochastic multi-agent systems in a manner that is both intuitive and safe. The user specifies the desired evolution of the plant state, as well as the acceptable probabilities of failure, as a temporal plan on states called a chance-constrained qualitative state plan (CCQSP). An example of a CCQSP statement is ""go to A through B within 30 minutes, with less than 0.001% probability of failure."" p-Sulu and dp-Sulu take a CCQSP, a continuous plant model with stochastic uncertainty, and an objective function as inputs, and outputs an optimal continuous control sequence, as well as an optimal discrete schedule. The difference between p-Sulu and dp-Sulu is that p-Sulu plans in a centralized manner while dp-Sulu plans in a distributed manner. dp-Sulu enables robust CCQSP execution for multi-agent systems. We solve the problem based on the key concept of risk allocation, which achieves tractability by allocating the specified risk to individual constraints and mapping the result into an equivalent deterministic constrained optimization problem. Risk allocation also enables a distributed plan execution for multi-agent systems by distributing the risk among agents to decompose the optimization problem. Building upon the risk allocation approach, we develop our first CCQSP executive, p-Sulu, in four spirals. First, we develop the Convex Risk Allocation (CRA) algorithm, which can solve a CCQSP planning problem with a convex state space and a fixed schedule, highlighting the capability of optimally allocating risk to individual constraints. Second, we develop the Non-convex Iterative Risk Allocation (NIRA) algorithm, which can handle non-convex state space. Third, we build upon NIRA a full-horizon CCQSP planner, p-Sulu FH, which can optimize not only the control sequence but also the schedule. Fourth, we develop p-Sulu, which enables the real-time execution of CCQSPs by employing the receding horizon approach. Our second CCQSP executive, dp-Sulu, is developed in two spirals. First, we develop the Market-based Iterative Risk Allocation (MIRA) algorithm, which can control a multi-agent system in a distributed manner by optimally distributing risk among agents through the market-based method called tatonnement. Second and finally, we integrate the capability of MIRA into p-Sulu to build the robust model-based executive, dp-Sulu, which can execute CCQSPs on multi-agent systems in a distributed manner. Our simulation results demonstrate that our executives can efficiently execute CCQSP planning problems with significantly reduced suboptimality compared to prior art.",283 p.,MIT-CSAIL-TR-2018-009,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,"Robust, Goal-directed Plan Execution with Bounded Risk",2018-01-31T00:01:14Z,,,,Brian Williams; Model-based Embedded and Robotic Systems,,,
Li-Shiuan Peh,"Sun, Chen; Chen, Chia-Hsin Owen; Kurian, George; Wei, Lan; Miller, Jason; Agarwal, Anant; Peh, Li-Shiuan; Stojanovic, Vladimir",Computer Architecture,2012-02-08T20:15:04Z,2012-02-08T20:15:04Z,2012-02-08,http://hdl.handle.net/1721.1/69050,,"With the advent of many-core chips that place substantial demand on the NoC, photonics has been investigated as a promising alternative to electrical NoCs. While numerous opto-electronic NoCs have been proposed, their evaluations tend to be based on fixed numbers for both photonic and electrical components, making it difficult to co-optimize. Through our own forays into opto-electronic NoC design, we observe that photonics and electronics are very much intertwined, reflecting a strong need for a NoC modeling tool that accurately models parameterized electronic and photonic components within a unified framework, capturing their interactions faithfully. In this paper, we present a tool, DSENT, for design space exploration of electrical and opto-electrical networks. We form a framework that constructs basic NoC building blocks from electrical and photonic technology parameters. To demonstrate potential use cases, we perform a network case study illustrating data-rate tradeoffs, a comparison with scaled electrical technology, and sensitivity to photonics parameters.",8 p.,MIT-CSAIL-TR-2012-004,Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported,http://creativecommons.org/licenses/by-nc-sa/3.0/,DSENT - A Tool Connecting Emerging Photonics with Electronics for Opto-Electronic Networks-on-Chip Modeling,,,en-US,,,,,
,"Rinard, Martin",Program Analysis,2012-02-23T20:30:03Z,2012-02-23T20:30:03Z,2012-02-23,http://hdl.handle.net/1721.1/69177,,"We present a new synchronization-free space-subdivision tree construction algorithm. Despite data races, this algorithm produces trees that are consistent enough for the client Barnes-Hut center of mass and force computation phases to use successfully. Our performance results show that eliminating synchronization improves the performance of the parallel algorithm by approximately 20%. End-to-end accuracy results show that the resulting partial data structure corruption has a neglible effect on the overall accuracy of the Barnes-Hut N-body simulation. We note that many data structure manipulation algorithms use many of the same basic operations (linked data structure updates and array insertions) as our tree construction algorithm. We therefore anticipate that the basic principles the we develop in this paper may effectively guide future efforts in this area.",12 p.,MIT-CSAIL-TR-2012-005,,,"A Lossy, Synchronization-Free, Race-Full, But Still Acceptably Accurate Parallel Space-Subdivision Tree Construction Algorithm",,Data Structure Repair; Data Races; Acceptability; Parallel Computing; Synchronization,,,,,,
Nickolai Zeldovich,"Popa, Raluca Ada; Zeldovich, Nickolai",Parallel and Distributed Operating Systems,2012-03-26T18:00:05Z,2012-03-26T18:00:05Z,2012-03-25,http://hdl.handle.net/1721.1/69859,,"In this document, we provide a cryptographic treatment of the adjustable join protocol from CryptDB. We also discuss how our scheme could be used outside of CryptDB because it provides a simple functionality that may be needed in other settings. Intuitively, it is a pseudorandom permutation where an external party not knowing the secret key can nonetheless adjust a ciphertext under one key to a ciphertext under a different key, given an adjustment token from a party that knows the secret key.",14 p.,MIT-CSAIL-TR-2012-006,,,Cryptographic Treatment of CryptDB's Adjustable Join,,SQL queries; encrypted database,en-US,,,,,
Ron Weiss,"Beal, Jacob; Weiss, Ron; Yaman, Fusun; Davidsohn, Noah; Adler, Aaron",Synthetic Biology,2012-04-09T17:15:07Z,2012-04-09T17:15:07Z,2012-04-07,http://hdl.handle.net/1721.1/69973,,"Engineering biological systems with predictable behavior is a foundational goal of synthetic biology. To accomplish this, it is important to accurately characterize the behavior of biological devices. Prior characterization efforts, however, have generally not yielded enough high-quality information to enable compositional design. In the TASBE (A Tool-Chain to Accelerate Synthetic Biological Engineering) project we have developed a new characterization technique capable of producing such data. This document describes the techniques we have developed, along with examples of their application, so that the techniques can be accurately used by others.",25 p.,MIT-CSAIL-TR-2012-008,Creative Commons Attribution-NoDerivs 3.0 Unported,http://creativecommons.org/licenses/by-nd/3.0/,"A Method for Fast, High-Precision Characterization of Synthetic Biology Devices",,Synthetic biology; characterization; TASBE,en-US,,,,,
Tomaso Poggio,"Isik, Leyla; Meyers, Ethan M.; Leibo, Joel Z.; Poggio, Tomaso",Center for Biological and Computational Learning (CBCL),2012-04-26T18:15:04Z,2012-04-26T18:15:04Z,2012-04-20,http://hdl.handle.net/1721.1/70170,,"Decoding analysis has been applied to electrophysiology and fMRI data to study the visual system, however, this method has only been applied to MEG visual data in a few instances. Here we use the Neural Decoding Toolbox for Matlab to show that it is possible to decode visual stimuli based on MEG data.",5 p.,MIT-CSAIL-TR-2012-010; CBCL-307,,,Preliminary MEG decoding results,,Vision; Decoding; MEG,en-US,,,,,
Silvio Micali,"Azar, Pablo; Micali, Silvio",,2012-05-09T22:45:07Z,2012-05-09T22:45:07Z,2012-05-08,http://hdl.handle.net/1721.1/70556,,"We study the problem of profit maximization in auctions of one good where the buyers' valuations are drawn from independent distributions. When these distributions are known to the seller, Myerson's optimal auction is a well-known mechanism for maximizing revenue. In many cases, however, the seller may not know the buyers' distributions. We propose an alternative model where the seller only knows the mean and the variance of each distribution. We call parametric an auction whose mechanism only uses these parameters. We construct parametric auctions both when the seller only has one copy of the good to sell, and when she has an infinite number of identical copies (i.e., when the good is digital). For a very large class of distributions, including (but not limited to) distributions with a monotone hazard rate, our auctions achieve a constant fraction of the revenue of Myerson's auction. When the seller has absolutely no knowledge about the distributions, it is well known that no auction can achieve a constant fraction of the optimal revenue when the players are not identically distributed. Our parametric model gives the seller a small amount of extra information, allowing her to construct auctions for which (1) no two bidders need to be drawn from identical distributions and (2) the revenue obtained is a constant fraction of the revenue in Myerson's optimal auction.",18 p.,MIT-CSAIL-TR-2012-011,,,Optimal Parametric Auctions,,,,,,Theory of Computation,,
Srini Devadas,"Kurian, George; Khan, Omer; Devadas, Srinivas",Computation Structures,2012-05-22T20:15:03Z,2012-05-22T20:15:03Z,2012-05-22,http://hdl.handle.net/1721.1/70909,,"As transistor density continues to grow geometrically, processor manufacturers are already able to place a hundred cores on a chip (e.g., Tilera TILE-Gx 100), with massive multicore chips on the horizon. Programmers now need to invest more effort in designing software capable of exploiting multicore parallelism. The shared memory paradigm provides a convenient layer of abstraction to the programmer, but will current memory architectures scale to hundreds of cores? This paper directly addresses the question of how to enable scalable memory systems for future multicores. We develop a scalable, efficient shared memory architecture that enables seamless adaptation between private and logically shared caching at the fine granularity of cache lines. Our data-centric approach relies on in hardware runtime profiling of the locality of each cache line and only allows private caching for data blocks with high spatio-temporal locality. This allows us to better exploit on-chip cache capacity and enable low-latency memory access in large-scale multicores.",11 p.,MIT-CSAIL-TR-2012-012,,,A Case for Fine-Grain Adaptive Cache Coherence,,,,,,,,
John Leonard,"Johannsson, Hordur; Kaess, Michael; Fallon, Maurice; Leonard, John J.",Marine Robotics,2012-05-25T19:15:05Z,2012-05-25T19:15:05Z,2012-05-25,http://hdl.handle.net/1721.1/70952,,"In this paper, we demonstrate a system for temporally scalable visual SLAM using a reduced pose graph representation. Unlike previous visual SLAM approaches that use keyframes, our approach continually uses new measurements to improve the map, yet achieves efficiency by avoiding adding redundant frames and not using marginalization to reduce the graph. To evaluate our approach, we present results using an online binocular visual SLAM system that uses place recognition for both robustness and multi-session operation. To allow large-scale indoor mapping, our system automatically handles elevator rides based on accelerometer data. We demonstrate long-term mapping in a large multi-floor building, using approximately nine hours of data collected over the course of six months. Our results illustrate the capability of our visual SLAM system to scale in size with the area of exploration instead of the time of exploration.",9 p.,MIT-CSAIL-TR-2012-013,,,Temporally Scalable Visual SLAM using a Reduced Pose Graph,,robotics navigation,,,,,,
Tomaso Poggio,"Poggio, Tomaso",Center for Biological and Computational Learning (CBCL),2012-05-31T20:15:04Z,2012-05-31T20:15:04Z,2012-05-31,http://hdl.handle.net/1721.1/70970,,"I discuss the ""levels of understanding"" framework described in Marr's Vision and propose a revised and updated version of it to capture the changes in computation and neuroscience over the last 30 years.",9 p.,MIT-CSAIL-TR-2012-014; CBCL-308,,,"The Levels of Understanding framework, revised",,"artificial intelligence, computer vision",en-US,,,,,
Silvio Micali,"Azar, Pablo Daniel; Micali, Silvio",Theory of Computation,2012-06-18T19:30:03Z,2012-06-18T19:30:03Z,2012-06-14,http://hdl.handle.net/1721.1/71170,,"We study the problem of an auctioneer who wants to maximize her profits. In our model, there are n buyers with private valuations drawn from independent distributions F_1,...,F_n. When these distributions are known to the seller, Myerson's optimal auction is a well known mechanism that maximizes revenue. However, in many cases it is too strong to assume that the seller knows these distributions. We propose an alternative model where the seller only knows the mean mu_i and variance sigma_i^2 of each distribution F_i. We call mechanisms that only use this information parametric auctions. We construct such auctions for all single-dimensional downward closed environments. For a very large class of distributions, including (but not limited to) distributions with a monotone hazard rate, our auctions achieve a constant fraction of the revenue of Myerson's auction. When the seller has absolutely no knowledge about the distributions, it is well known that no auction can achieve a constant fraction of the optimal revenue when the players are not identically distributed. Our parametric model gives the seller a small amount of extra information, allowing her to construct auctions for which (1) she does not know the full distribution of valuations, (2) no two bidders need to be drawn from identical distributions and (3) the revenue obtained is a constant fraction of the revenue in Myerson's optimal auction. For digital goods environments we present a different parametric auction that not only gives a better approximation to the optimal auction, but that is also optimal in a new sense, which we call maximin optimality. Informally, an auction is maximin optimal if it maximizes revenue in the worst case over an adversary's choice of the distribution. We show that our digital parametric is maximin optimal among the class of posted price mechanisms.",19 p.,MIT-CSAIL-TR-2012-015,,,Optimal Parametric Auctions,,Auctions; Optimization,,,,,,
Silvio Micali,"Chen, Jing; Micali, Silvio; Pass, Rafael",Theory of Computation,2012-06-27T20:15:03Z,2012-06-27T20:15:03Z,2012-06-22,http://hdl.handle.net/1721.1/71232,,"In settings of incomplete information we put forward an epistemic framework for designing mechanisms that successfully leverage the players' arbitrary higher-order beliefs, even when such beliefs are totally wrong, and even when the players are rational in a very weak sense. Following Aumann (1995), we consider a player i rational if he uses a pure strategy s_i such that no alternative pure strategy s_i' performs better than s_i in every world i considers possible, and consider him order-k rational if he is rational and believes that all other players are order-(k-1) rational. We then introduce an iterative deletion procedure of dominated strategies and use it to precisely characterize the strategies consistent with the players being order-k rational. We exemplify the power of our framework in single-good auctions by introducing and achieving a new class of revenue benchmarks, defined over the players' arbitrary beliefs, that can be much higher than classical ones, and are unattainable by traditional mechanisms. Namely, we exhibit a mechanism that, for every k greater than or equal to 0 and epsilon>0 and whenever the players are order-(k+1) rational, guarantees revenue greater than or equal to G^k-epsilon, where G^k is the second highest belief about belief about ... (k times) about the highest valuation of some player, even when such a player's identity is not precisely known. Importantly, our mechanism is possibilistic interim individually rational. Essentially this means that, based on his beliefs, a player's utility is non-negative not in expectation, but in each world he believes possible. We finally show that our benchmark G^k is so demanding that it separates the revenue achievable with order-k rational players from that achievable with order-(k+1) rational ones. That is, no possibilistic interim individually rational mechanism can guarantee revenue greater than or equal to G^k-c, for any constant c>0, when the players are only order-k rational.",31 p.,MIT-CSAIL-TR-2012-017,,,Epistemic Implementation and The Arbitrary-Belief Auction,,higher-order beliefs; higher-order rationality; revenue,en-US,,,,,
Leslie Kaelbling; Tomas Lozano-Perez,"Kaelbling, Leslie Pack; Lozano-Perez, Tomas",Learning and Intelligent Systems,2012-07-02T17:15:07Z,2012-07-02T17:15:07Z,2012-06-29,http://hdl.handle.net/1721.1/71521,,"This paper provides an approach to integrating geometric motion planning with logical task planning for long-horizon tasks in domains with many objects. We propose a tight integration between the logical and geometric aspects of planning. We use a logical representation which includes entities that refer to poses, grasps, paths and regions, without the need for a priori discretization. Given this representation and some simple mechanisms for geometric inference, we characterize the pre-conditions and effects of robot actions in terms of these logical entities. We then reason about the interaction of the geometric and non-geometric aspects of our domains using the general-purpose mechanism of goal regression (also known as pre-image backchaining). We propose an aggressive mechanism for temporal hierarchical decomposition, which postpones the pre-conditions of actions to create an abstraction hierarchy that both limits the lengths of plans that need to be generated and limits the set of objects relevant to each plan. We describe an implementation of this planning method and demonstrate it in a simulated kitchen environment in which it solves problems that require approximately 100 individual pick or place operations for moving multiple objects in a complex domain.",68 p.,MIT-CSAIL-TR-2012-018,,,Integrated Robot Task and Motion Planning in the Now,,robot manipulation; motion planning,,,,,"This work was supported in part by the NSF under Grant No. 1117325. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. We also gratefully acknowledge support from ONR MURI grant N00014-09-1-1051, from AFOSR grant AOARD-104135 and from
the Singapore Ministry of Education under a grant to the Singapore-MIT International Design Center. We thank Willow Garage for the use of the PR2 robot as part of the PR2 Beta Program.",
Leslie Kaelbling; Tomas Lozano-Perez,"Kaelbling, Leslie Pack; Lozano-Perez, Tomas",Learning and Intelligent Systems,2012-07-03T18:00:04Z,2012-07-03T18:00:04Z,2012-07-03,http://hdl.handle.net/1721.1/71529,,"In this paper, we describe an integrated strategy for planning, perception, state-estimation and action in complex mobile manipulation domains. The strategy is based on planning in the belief space of probability distribution over states. Our planning approach is based on hierarchical goal regression (pre-image back-chaining). We develop a vocabulary of fluents that describe sets of belief states, which are goals and subgoals in the planning process. We show that a relatively small set of symbolic operators lead to task-oriented perception in support of the manipulation goals. An implementation of this method is demonstrated in simulation and on a real PR2 robot, showing robust, flexible solution of mobile manipulation problems with multiple objects and substantial uncertainty.",80 p.,MIT-CSAIL-TR-2012-019,Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,Integrated robot task and motion planning in belief space,,,,,,,"This work was supported in part by the NSF under Grant No. 1117325. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. We also gratefully acknowledge support from ONR MURI grant N00014-09-1-1051, from AFOSR grant AOARD-104135 and from the Singapore Ministry of Education under a grant to the Singapore-MIT International Design Center. We thank Willow Garage for the use of the PR2 robot as part of the PR2 Beta Program.",
John Leonard,"Whelan, Thomas; Kaess, Michael; Fallon, Maurice; Johannsson, Hordur; Leonard, John; McDonald, John",Marine Robotics,2012-07-23T17:45:03Z,2012-07-23T17:45:03Z,2012-07-19,http://hdl.handle.net/1721.1/71756,,"In this paper we present an extension to the KinectFusion algorithm that permits dense mesh-based mapping of extended scale environments in real-time. This is achieved through (i) altering the original algorithm such that the region of space being mapped by the KinectFusion algorithm can vary dynamically, (ii) extracting a dense point cloud from the regions that leave the KinectFusion volume due to this variation, and, (iii) incrementally adding the resulting points to a triangular mesh representation of the environment. The system is implemented as a set of hierarchical multi-threaded components which are capable of operating in real-time. The architecture facilitates the creation and integration of new modules with minimal impact on the performance on the dense volume tracking and surface reconstruction modules. We provide experimental results demonstrating the system's ability to map areas considerably beyond the scale of the original KinectFusion algorithm including a two story apartment and an extended sequence taken from a car at night. In order to overcome failure of the iterative closest point (ICP) based odometry in areas of low geometric features we have evaluated the Fast Odometry from Vision (FOVIS) system as an alternative. We provide a comparison between the two approaches where we show a trade off between the reduced drift of the visual odometry approach and the higher local mesh quality of the ICP-based approach. Finally we present ongoing work on incorporating full simultaneous localisation and mapping (SLAM) pose-graph optimisation.",8 p.,MIT-CSAIL-TR-2012-020,,,Kintinuous: Spatially Extended KinectFusion,,,,,,,,
Barbara Liskov,"Liskov, Barbara; Cowling, James",Programming Methodology,2012-07-23T19:15:02Z,2012-07-23T19:15:02Z,2012-07-23,http://hdl.handle.net/1721.1/71763,,"This paper presents an updated version of Viewstamped Replication, a replication technique that handles failures in which nodes crash. It describes how client requests are handled, how the group reorganizes when a replica fails, and how a failed replica is able to rejoin the group. The paper also describes a number of important optimizations and presents a protocol for handling reconfigurations that can change both the group membership and the number of failures the group is able to handle.",14 p.,MIT-CSAIL-TR-2012-021,,,Viewstamped Replication Revisited,,VR; state machine replication; consensus; fault-tolerance; agreement,,,,,,
