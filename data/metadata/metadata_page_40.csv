dc.contributor.advisor,dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.relation.ispartofseries,dc.rights,dc.rights.uri,dc.subject,dc.title,dc.identifier.citation,dc.contributor.department,dc.description,dc.description.sponsorship,dc.relation.uri,dc.contributor,dc.relation.isreferencedby,dc.relation.replaces,dc.relation.requires,dc.relation.isreplacedby,dc.contributor.editor
Fredo Durand,"Ragan-Kelley, Jonathan; Doggett, Michael; Lehtinen, Jaakko; Chen, Jiawen; Durand, Fredo",Computer Graphics,2010-03-29T18:45:17Z,2010-03-29T18:45:17Z,2010-03-29,http://hdl.handle.net/1721.1/53330,"We propose decoupled sampling, an approach that decouples shading from visibility sampling in order to enable motion blur and depth-of-field at reduced cost. More generally, it enables extensions of modern real-time graphics pipelines that provide controllable shading rates to trade off quality for performance. It can be thought of as a generalization of GPU-style multisample antialiasing (MSAA) to support unpredictable shading rates, with arbitrary mappings from visibility to shading samples as introduced by motion blur, depth-of-field, and adaptive shading. It is inspired by the Reyes architecture in offline rendering, but targets real-time pipelines by driving shading from visibility samples as in GPUs, and removes the need for micropolygon dicing or rasterization. Decoupled Sampling works by defining a many-to-one hash from visibility to shading samples, and using a buffer to memoize shading samples and exploit reuse across visibility samples. We present extensions of two modern GPU pipelines to support decoupled sampling: a GPU-style sort-last fragment architecture, and a Larrabee-style sort-middle pipeline. We study the architectural implications and derive end-to-end performance estimates on real applications through an instrumented functional simulator. We demonstrate high-quality motion blur and depth-of-field, as well as variable and adaptive shading rates.",16 p.,MIT-CSAIL-TR-2010-015,Creative Commons Attribution-Share Alike 3.0 Unported,http://creativecommons.org/licenses/by-sa/3.0/,Computer Graphics; Graphics Systems; Graphics Hardware,Decoupled Sampling for Real-Time Graphics Pipelines,"RAGAN-KELLEY, J., LEHTINEN, J., CHEN, J., DOGGETT, M., and DURAND, F. 2010. Decoupled Sampling for Real-Time Graphics Pipelines. MIT Computer Science and Artificial Intelligence Laboratory Technical Report Series, MIT-CSAIL-TR-2010-015.",,,,,,,,,,
Fredo Durand,"Agarwala, Aseem; Bae, Soonmin; Durand, Fredo",,2010-04-14T17:30:08Z,2010-04-14T17:30:08Z,2010-04-07,http://hdl.handle.net/1721.1/53705,"Rephotographers aim to recapture an existing photograph from the same viewpoint. A historical photograph paired with a well-aligned modern rephotograph can serve as a remarkable visualization of the passage of time. However, the task of rephotography is tedious and often imprecise, because reproducing the viewpoint of the original photograph is challenging. The rephotographer must disambiguate between the six degrees of freedom of 3D translation and rotation, and the confounding similarity between the effects of camera zoom and dolly. We present a real-time estimation and visualization technique for rephotography that helps users reach a desired viewpoint during capture. The input to our technique is a reference image taken from the desired viewpoint. The user moves through the scene with a camera and follows our visualization to reach the desired viewpoint. We employ computer vision techniques to compute the relative viewpoint difference. We guide 3D movement using two 2D arrows. We demonstrate the success of our technique by rephotographing historical images and conducting user studies.",15 p.,MIT-CSAIL-TR-2010-016,Creative Commons Attribution-Noncommercial 3.0 Unported,http://creativecommons.org/licenses/by-nc/3.0/,Rephotography; Computational photography; Pose estimation,Computational Re-Photography,,Computer Graphics,,,,,,,,,
Brian Williams,"Li, Hui X.",Model-based Embedded and Robotic Systems,2010-04-16T16:15:05Z,2010-04-16T16:15:05Z,2010-04-09,http://hdl.handle.net/1721.1/53720,"Most unmanned missions in space and undersea are commanded by a ""script"" that specifies a sequence of discrete commands and continuous actions. Currently such scripts are mostly hand-generated by human operators. This introduces inefficiency, puts a significant cognitive burden on the engineers, and prevents re-planning in response to environment disturbances or plan execution failure. For discrete systems, the field of autonomy has elevated the level of commanding by developing goal-directed systems, to which human operators specify a series of temporally extended goals to be accomplished, and the goal-directed systems automatically output the correct, executable command sequences. Increasingly, the control of autonomous systems involves performing actions with a mix of discrete and continuous effects. For example, a typical autonomous underwater vehicle (AUV) mission involves discrete actions, like get GPS and take sample, and continuous actions, like descend and ascend, which are influenced by the dynamical model of the vehicle. A hybrid planner generates a sequence of discrete and continuous actions that achieve the mission goals. In this thesis, I present a novel approach to solve the generative planning problem for temporally extended goals for hybrid systems, involving both continuous and discrete actions. The planner, Kongming, incorporates two innovations. First, it employs a compact representation of all hybrid plans, called a Hybrid Flow Graph, which combines the strengths of a Planning Graph for discrete actions and Flow Tubes for continuous actions. Second, it engages novel reformulation schemes to handle temporally flexible actions and temporally extended goals. I have successfully demonstrated controlling an AUV in the Atlantic ocean using mission scripts solely generated by Kongming. I have also empirically evaluated Kongming on various real-world scenarios in the underwater domain and the air vehicle domain, and found it successfully and efficiently generates valid and optimal plans.",237 p.,MIT-CSAIL-TR-2010-018,,,combinatorial optimization; AI planning; autonomous systems,Kongming: A Generative Planner for Hybrid Systems with Temporally Extended Goals,,,PhD thesis,Funded by the Boeing Company under contract MIT-BA-GTA-1,,,,,,,
Srini Devadas,"Devadas, Srinivas; Lis, Mieszko; Khan, Omer",Computation Structures,2010-04-23T17:15:07Z,2010-04-23T17:15:07Z,2010-04-17,http://hdl.handle.net/1721.1/53748,"We introduce the Execution Migration Machine (EM²), a novel data-centric multicore memory system architecture based on computation migration. Unlike traditional distributed memory multicores, which rely on complex cache coherence protocols to move the data to the core where the computation is taking place, our scheme always moves the computation to the core where the data resides. By doing away with the cache coherence protocol, we are able to boost the effectiveness of per-core caches while drastically reducing hardware complexity. To evaluate the potential of EM² architectures, we developed a series of PIN/Graphite-based models of an EM² multicore with 64 x86 cores and, under some simplifying assumptions (a timing model restricted to data memory performance, no instruction cache modeling, high-bandwidth fixed-latency interconnect allowing concurrent migrations), compared them against corresponding directory-based cache-coherent architecture models. We justify our assumptions and show that our conclusions are valid even if our assumptions are removed. Experimental results on a range of SPLASH-2 and PARSEC benchmarks indicate that EM2 can significantly improve per-core cache performance, decreasing overall miss rates by as much as 84% and reducing average memory latency by up to 58%.",13 p.,MIT-CSAIL-TR-2010-019,,,,Instruction-Level Execution Migration,,,,,,,,,,,
Frans Kaashoek,"Kaashoek, Frans; Morris, Robert; Mao, Yandong",Parallel and Distributed Operating Systems,2010-05-03T23:15:05Z,2010-05-03T23:15:05Z,2010-05-02,http://hdl.handle.net/1721.1/54692,"MapReduce is a programming model for data-parallel programs originally intended for data centers. MapReduce simplifies parallel programming, hiding synchronization and task management. These properties make it a promising programming model for future processors with many cores, and existing MapReduce libraries such as Phoenix have demonstrated that applications written with MapReduce perform competitively with those written with Pthreads. This paper explores the design of the MapReduce data structures for grouping intermediate key/value pairs, which is often a performance bottleneck on multicore processors. The paper finds the best choice depends on workload characteristics, such as the number of keys used by the application, the degree of repetition of keys, etc. This paper also introduces a new MapReduce library, Metis, with a compromise data structure designed to perform well for most workloads. Experiments with the Phoenix benchmarks on a 16-core AMD-based servershow that Metisâ   data structure performs better than simpler alternatives, including Phoenix.",13 p.,MIT-CSAIL-TR-2010-020,,,,Optimizing MapReduce for Multicore Architectures,,,,,,,,,,,
Fredo Durand,"Igarashi, Takeo; Durand, Fredo; Rivers, Alec",Computer Graphics,2010-05-06T17:45:04Z,2010-05-06T17:45:04Z,2010-05-05,http://hdl.handle.net/1721.1/54731,"We describe a user study comparing 3D Modeling with Silhouettes and Google SketchUp. In the user study, ten users were asked to create 3D models of three different objects, using either 3D Modeling with Silhouettes or Google SketchUp. Ten different users were then asked to rank images of the models produced by the first group. We show that the models made with 3D Modeling with Silhouettes were ranked significantly higher on average than those made with Google SketchUp.",4 p.,MIT-CSAIL-TR-2010-023,Creative Commons Attribution 3.0 Unported,http://creativecommons.org/licenses/by/3.0/,sketch-based modeling,A User Study Comparing 3D Modeling with Silhouettes and Google SketchUp,,,,,,,,,,,
Martin Rinard,"Jayaraman, Karthick; Rinard, Martin C.; Tripunitara, Mahesh; Ganesh, Vijay; Chapin, Steve",Computer Architecture,2010-05-06T17:30:07Z,2010-05-06T17:30:07Z,2010-05-05,http://hdl.handle.net/1721.1/54730,"Access-control policies are a key infrastructural technology for computer security. However, a significant problem is that system administrators need to be able to automatically verify whether their policies capture the intended security goals. To address this important problem, researchers have proposed many automated verification techniques. Despite considerable progress in verification techniques, scalability is still a significant issue. Hence, in this paper we propose that error finding complements verification, and is a fruitful way of checking whether or not access control policies implement the security intent of system administrators. Error finding is more scalable (at the cost of completeness), and allows for the use of a wider variety of techniques. In this paper, we describe an abstraction-refinement based technique and its implementation, the Mohawk tool, aimed at finding errors in ARBAC access-control policies. The key insight behind our abstraction-refinement technique is that it is more efficient to look for errors in an abstract policy (with successive refinements, if necessary) than its complete counterpart. Mohawk accepts as input an access-control policy and a safety question. If Mohawk finds an error in the input policy, it terminates with a sequence of actions that cause the error. We provide an extensive comparison of Mohawk with the current state-of-the-art analysis tools. We show that Mohawk scales very well as the size and complexity of the input policies increase, and is orders of magnitude faster than competing tools. The Mohawk tool is open source and available from the Google Code website: http://code.google.com/p/mohawk/",12 p.,MIT-CSAIL-TR-2010-022,Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,access-control policies; error finding; bounded model-checking; abstraction refinement,Automatic Error Finding in Access-Control Policies,,,,,http://code.google.com/p/mohawk/,,,,,,
,"Kaelbling, Leslie Pack; Lozano-Perez, Tomas",Learning and Intelligent Systems,2010-05-12T23:00:07Z,2010-05-12T23:00:07Z,2010-05-07,http://hdl.handle.net/1721.1/54780,"In this paper we outline an approach to the integration of task planning and motion planning that has the following key properties: It is aggressively hierarchical. It makes choices and commits to them in a top-down fashion in an attempt to limit the length of plans that need to be constructed, and thereby exponentially decrease the amount of search required. Importantly, our approach also limits the need to project the effect of actions into the far future. It operates on detailed, continuous geometric representations and partial symbolic descriptions. It does not require a complete symbolic representation of the input geometry or of the geometric effect of the task-level operations.",9 p.,MIT-CSAIL-TR-2010-026,Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,,Hierarchical Task and Motion Planning in the Now,,,"Workshop on Mobile Manipulation, IEEE International Conference on Robotics and Automation",This work was supported in part by the National Science Foundation under Grant No. 0712012.,,,,,,,
William Freeman,"Freeman, William T.; Torralba, Antonio; Yuen, Jenny; Liu, Ce",Vision,2010-05-13T19:30:03Z,2010-05-13T19:30:03Z,2010-05-08,http://hdl.handle.net/1721.1/54787,"While image alignment has been studied in different areas of computer vision for decades, aligning images depicting different scenes remains a challenging problem. Analogous to optical flow where an image is aligned to its temporally adjacent frame, we propose SIFT flow, a method to align an image to its nearest neighbors in a large image corpus containing a variety of scenes. The SIFT flow algorithm consists of matching densely sampled, pixel-wise SIFT features between two images, while preserving spatial discontinuities. The SIFT features allow robust matching across different scene/object appearances, whereas the discontinuity-preserving spatial model allows matching of objects located at different parts of the scene. Experiments show that the proposed approach robustly aligns complex scene pairs containing significant spatial differences. Based on SIFT flow, we propose an alignment-based large database framework for image analysis and synthesis, where image information is transferred from the nearest neighbors to a query image according to the dense scene correspondence. This framework is demonstrated through concrete applications, such as motion field prediction from a single image, motion synthesis via object transfer, satellite image registration and face recognition.",17 p.,MIT-CSAIL-TR-2010-024,,,,SIFT Flow: Dense Correspondence across Scenes and its Applications,,,,,,,,,,,
Patrick Winston,"Finlayson, Mark Alan; Hervas, Raquel",Genesis,2010-08-19T18:15:22Z,2010-08-19T18:15:22Z,2010-05-12,http://hdl.handle.net/1721.1/57507,"The corpus comprises 62 files in ""Story Workbench"" annotation format: 30 folktales in English from a variety of sources, and 32 Wall Street Journal articles selected to coincide with articles found in the Penn Treebank. The files are annotated with the location of referring expressions, coreference relations between the referring expressions, and so-called ""indication structures"", which split referring expressions into constituents (nuclei and modifiers) and mark each constituent as either 'distinctive' or 'descriptive', indicating whether or not the constituent contains information required for uniquely identifying the referent. The files distributed in this corpus archive are the gold-standard files, which were constructed by merging annotations done by two trained annotators. The contents of this corpus, the annotation procedure, and the indication structures are described in more detail in a paper titled ""The Prevalence of Descriptive Referring Expressions in News and Narrative"" published in the proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, held in July 2010 in Uppsala, Sweden (ACL-2010). A near-final version of the paper is included in the doc/ directory of the compressed corpus archive file.
This is version 1.1 of the UMIREC corpus, in which the coreference annotations have been fixed relative to version 1.0. UMIREC v1.0 suffered from a bug in the export script that corrupted the coreference data.",877 ko,,Creative Commons Attribution 3.0 Unported,http://creativecommons.org/licenses/by/3.0/,,"UCM/MIT Indications, Referring Expressions, and Coreference Corpus (UMIREC corpus) v1.1","Finlayson, M.A. & Hervás, R. (2010) UCM/MIT Indications, Referring Expressions, and Co-Reference Corpus v1.1 (UMIREC corpus). MIT CSAIL Work Product.",,,,,Patrick Winston; Genesis,http://hdl.handle.net/1721.1/54765,http://hdl.handle.net/1721.1/54766,,,
Patrick Winston,"Hervas, Raquel; Finlayson, Mark Alan",Genesis,2010-05-12T15:30:09Z,2010-05-12T15:30:09Z,2010-05-12,http://hdl.handle.net/1721.1/54765,"This is the annotation guide given to the annotators who created the UCM/MIT Indications, Referring Expressions, and Coreference (UMIREC) Corpus version 1.0. The corpus comprises texts annotated for referring expressions, coreference relations between the referring expressions, and so-called ""indication structures"", which split referring expressions into constituents (nuclei and modifiers) and mark each constituent as either 'distinctive' or 'descriptive', which indicate whether or not the constituent contains information required for uniquely identifying the referent. The contents of this corpus, the annotation procedure, and the indication structures are described in more detail in a paper titled ""The Prevalence of Descriptive Referring Expressions in News and Narrative"" published in the proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, held in July 2010 in Uppsala, Sweden (ACL-2010).",15 p.,MIT-CSAIL-TR-2010-025,Creative Commons Attribution 3.0 Unported,http://creativecommons.org/licenses/by/3.0/,,"Annotation Guide for the UCM/MIT Indications, Referential Expressions, and Coreference Corpus (UMIREC Corpus)","Finlayson, M.A. & Hervás, R. (2010) Annotation Guide for the UCM/MIT Indications, Referring Expressions, and Co-Reference Corpus (UMIREC corpus). MIT CSAIL Technical Report No. 2010-025.",,,,,,,,http://hdl.handle.net/1721.1/57507,,
Patrick Winston,"Hervas, Raquel; Finlayson, Mark Alan",Genesis,2010-05-12T15:30:19Z,2010-05-12T15:30:19Z,2010-05-12,http://hdl.handle.net/1721.1/54766,"This version of the UMIREC corpus has been superseded by version 1.1, found at http://hdl.handle.net/1721.1/57507.  Please do not use version 1.0, as it contains corrupted coreference information.  The correct, uncorrupted data is found in version 1.1.",,,Creative Commons Attribution 3.0 Unported,http://creativecommons.org/licenses/by/3.0/,,"UCM/MIT Indications, Referring Expressions, and Coreference Corpus (UMIREC corpus)","Finlayson, M.A. & Hervás, R. (2010) UCM/MIT Indications, Referring Expressions, and Co-Reference Corpus v1.0 (UMIREC corpus). MIT CSAIL Work Product.",,,,,,http://hdl.handle.net/1721.1/54765,,,http://hdl.handle.net/1721.1/57507,
Martin Rinard,"Misailovic, Sasa; Agarwal, Anant; Carbin, Michael; Sidiroglou, Stelios; Hoffmann, Henry; Rinard, Martin",Program Analysis,2010-05-14T22:00:04Z,2010-05-14T22:00:04Z,2010-05-14,http://hdl.handle.net/1721.1/54799,"We present PowerDial, a system for dynamically adapting application behavior to execute successfully in the face of load and power fluctuations. PowerDial transforms static configuration parameters into dynamic knobs that the PowerDial control system can manipulate to dynamically trade off the accuracy of the computation in return for reductions in the computational resources that the application requires to produce its results. These reductions translate into power savings. Our experimental results show that PowerDial can enable our benchmark applications to execute responsively in the face of power caps (imposed, for example, in response to cooling system failures) that would otherwise significantly impair the delivered performance. They also show that PowerDial can reduce the number of machines required to meet peak load, in our experiments enabling up to a 75% reduction in direct power and capital costs.",16 p.,MIT-CSAIL-TR-2010-027,Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,Autonomic Computing; Dynamic Analysis; Runtime control; Power Aware computing,Power-Aware Computing with Dynamic Knobs,,,,,,,,,,,
Dina Katabi,"Katabi, Dina; Gollakota, Shyamnath",Networks & Mobile Systems,2010-06-07T19:15:07Z,2010-06-07T19:15:07Z,2010-06-07,http://hdl.handle.net/1721.1/55650,"Wireless is inherently less secure than wired networks because of its broadcast nature. Attacks that simply snoop on the wireless medium successfully defeat the security of even 802.11 networks using the most recent security standards (WPA2-PSK). In this paper we ask the following question: Can we prevent this kind of eavesdropping from happening? If so, we can potentially defeat the entire class of attacks that rely on snooping. This paper presents iJam, a PHY-layer protocol for OFDM-based wireless systems. iJam ensures that an eavesdropper cannot successfully demodulate a wireless signal not intended for it. To achieve this iJam strategically introduces interference that prevents an eavesdropper from decoding the data, while allowing the intended receiver to decode it. iJam exploits the properties of 802.11â  s OFDM signals to ensure that an eavesdropper cannot even tell which parts of the signal are jammed. We implement iJam and evaluate it in a testbed of GNURadios with an 802.11-like physical layer. We show that iJam makes the data bits at the adversary look random, i.e., the BER becomes close to 50%, whereas the receiver can perfectly decode the data.",13 p.,MIT-CSAIL-TR-2010-028,,,Physical Layer Security,iJam: Jamming Oneself for Secure Wireless Communication,,,,,,,,,,,
Nancy Lynch,"Oshman, Rotem; Richa, Andrea; Newport, Calvin; Lynch, Nancy; Kuhn, Fabian",Theory of Computation,2010-06-08T16:00:03Z,2010-06-08T16:00:03Z,2010-06-08,http://hdl.handle.net/1721.1/55721,"Practitioners agree that unreliable links, which fluctuate between working and not working, are an important characteristic of wireless networks. In contrast, most theoretical models of radio networks fix a static set of links and assume that these links work reliably throughout an execution. This gap between theory and practice motivates us to investigate how unreliable links affect theoretical bounds on broadcast in radio networks. To that end we consider a model that includes two types of links: reliable links, which always deliver messages, and unreliable links, which sometimes deliver messages and sometimes do not. It is assumed that the graph induced by the reliable links is connected, and unreliable links are controlled by a worst-case adversary. In the new model we show an(n log n) lower bound on deterministic broadcast in undirected graphs, even when all processes are initially awake and have collision detection, and an (n) lower bound on randomized broadcast in undirected networks of constant diameter. This clearly separates the new model from the classical, reliable model. On the positive side, we give two algorithms that tolerate the inherent unreliability: an O(n3=2plog n)-time deterministic algorithm and a randomized algorithm which terminates in O(n log2 n) rounds with high probability.",25 p.,MIT-CSAIL-TR-2010-029,,,,Broadcasting in Unreliable Radio Networks,,,,,,,,,,,
Srini Devadas,"Khan, Omer; Lis, Mieszko; Devadas, Srini",Computation Structures,2010-06-18T19:00:10Z,2010-06-18T19:00:10Z,2010-06-12,http://hdl.handle.net/1721.1/55944,"We introduce the Execution Migration Machine (EM2), a novel, scalable shared-memory architecture for large-scale multicores constrained by off-chip memory bandwidth. EM2 reduces cache miss rates, and consequently off-chip memory usage, by permitting only one copy of data to be stored anywhere in the system: when a thread wishes to access an address not locally cached on the core it is executing on, it migrates to the appropriate core and continues execution. Using detailed simulations of a range of 256-core configurations on the SPLASH-2 benchmark suite, we show that EM2 improves application completion times by 18% on the average while remaining competitive with traditional architectures in silicon area.",22 p.,MIT-CSAIL-TR-2010-030,,,parallel processing; parallel architecture; distributed memory,EM2: A Scalable Shared-Memory Multicore Architecture,,,,,,,,,,,
Dina Katabi,"Wang, Jue; Katabi, Dina",Networks & Mobile Systems,2010-07-07T21:15:12Z,2010-07-07T21:15:12Z,2010-07-05,http://hdl.handle.net/1721.1/56252,"Video chat is increasingly popular among Internet users. Often, however, chatting sessions suffer from packet loss, which causes video outage and poor quality. Existing solutions however are unsatisfying. Retransmissions increase the delay and hence can interact negatively with the strict timing requirements of interactive video. FEC codes introduce extra overhead and hence reduce the bandwidth available for video data even in the absence of packet loss. This paper presents ChitChat, a new approach for reliable video chat that neither delays frames nor introduces bandwidth overhead. The key idea is to ensure that the information in each packet describes the whole frame. As a result, even when some packets are lost, the receiver can still use the received packets to decode a smooth version of the original frame. This reduces frame loss and the resulting video freezes and improves the perceived video quality. We have implemented ChitChat and evaluated it over multiple Internet paths. In comparison to Windows Live Messenger 2009, our method reduces the occurrences of video outage events by more than an order of magnitude.",12 p.,MIT-CSAIL-TR-2010-031,,,,ChitChat: Making Video Chat Robust to Packet Loss,,,,,,,,,,,
Whitman Richards,"Richards, Whitman; Macindoe, Owen",,2010-07-27T20:15:27Z,2010-07-27T20:15:27Z,2010-07-27,http://hdl.handle.net/1721.1/57462,"Two dozen networks are analyzed using three parameters that attempt to capture important properties of social networks: leadership L, member bonding B, and diversity of expertise D. The first two of these parameters have antecedents, the third is new. A key part of the analysis is to examine networks at multiple scales by dissecting the entire network into its n subgraphs of a given radius of two edge steps about each of the n nodes. This scale-based analysis reveals constraints on what we have dubbed ""cognitive"" networks, as contrasted with biological or physical networks. Specifically, ""cognitive"" networks appear to maximize bonding and diversity over a range of leadership dominance. Asymptotic relations between the bonding and diversity measures are also found when small, nearly complete subgraphs are aggregated to form larger networks. This aggregation probably underlies changes in a regularity among the LBD parameters; this regularity is a U-shaped function of networks size, n, which is minimal for networks around 80 or so nodes.",38 p.,MIT-CSAIL-TR-2010-033,,,constraints on social networks; network evolution; small group aggregation; multi-scale analysis,Characteristics of Small Social Networks,,,,,,,,,,,Belief Dynamics
Saman Amarasinghe,"Ansel, Jason; Wong, Yee Lok; Chan, Cy; Olszewski, Marek; Edelman, Alan; Amarasinghe, Saman",Computer Architecture,2010-07-27T20:15:11Z,2010-07-27T20:15:11Z,2010-07-27,http://hdl.handle.net/1721.1/57461,"Approximating ideal program outputs is a common technique for solving computationally difficult problems, for adhering to processing or timing constraints, and for performance optimization in situations where perfect precision is not necessary. To this end, programmers often use approximation algorithms, iterative methods, data resampling, and other heuristics. However, programming such variable accuracy algorithms presents difficult challenges since the optimal algorithms and parameters may change with different accuracy requirements and usage environments. This problem is further compounded when multiple variable accuracy algorithms are nested together due to the complex way that accuracy requirements can propagate across algorithms and because of the resulting size of the set of allowable compositions. As a result, programmers often deal with this issue in an ad-hoc manner that can sometimes violate sound programming practices such as maintaining library abstractions. In this paper, we propose language extensions that expose trade-offs between time and accuracy to the compiler. The compiler performs fully automatic compile-time and install-time autotuning and analyses in order to construct optimized algorithms to achieve any given target accuracy. We present novel compiler techniques and a structured genetic tuning algorithm to search the space of candidate algorithms and accuracies in the presence of recursion and sub-calls to other variable accuracy code. These techniques benefit both the library writer, by providing an easy way to describe and search the parameter and algorithmic choice space, and the library user, by allowing high level specification of accuracy requirements which are then met automatically without the need for the user to understand any algorithm-specific parameters. Additionally, we present a new suite of benchmarks, written in our language, to examine the efficacy of our techniques. Our experimental results show that by relaxing accuracy requirements, we can easily obtain performance improvements ranging from 1.1x to orders of magnitude of speedup.",18 p.,MIT-CSAIL-TR-2010-032,,,,Language and Compiler Support for Auto-Tuning Variable-Accuracy Algorithms,,,,,,,,,,,
Tomaso Poggio,"Meyers, Ethan; Embark, Hamdy; Freiwald, Winrich; Serre, Thomas; Kreiman, Gabriel; Poggio, Tomaso",Center for Biological and Computational Learning (CBCL),2010-07-29T18:45:19Z,2010-07-29T18:45:19Z,2010-07-29,http://hdl.handle.net/1721.1/57463,"Humans and other primates can rapidly categorize objects even when they are embedded in complex visual scenes (Thorpe et al., 1996; Fabre-Thorpe et al., 1998). Studies by Serre et al., 2007 have shown that the ability of humans to detect animals in brief presentations of natural images decreases as the size of the target animal decreases and the amount of clutter increases, and additionally, that a feedforward computational model of the ventral visual system, originally developed to account for physiological properties of neurons, shows a similar pattern of performance. Motivated by these studies, we recorded single- and multi-unit neural spiking activity from macaque superior temporal sulcus (STS) and anterior inferior temporal cortex (AIT), as a monkey passively viewed images of natural scenes. The stimuli consisted of 600 images of animals in natural scenes, and 600 images of natural scenes without animals in them, captured at four different viewing distances, and were the same images used by Serre et al. to allow for a direct comparison between human psychophysics, computational models, and neural data. To analyze the data, we applied population ""readout"" techniques (Hung et al., 2005; Meyers et al., 2008) to decode from the neural activity whether an image contained an animal or not. The decoding results showed a similar pattern of degraded decoding performance with increasing clutter as was seen in the human psychophysics and computational model results. However, overall the decoding accuracies from the neural data lower were than that seen in the computational model, and the latencies of information in IT were long (~125ms) relative to behavioral measures obtained from primates in other studies. Additional tests also showed that the responses of the model units were not capturing several properties of the neural responses, and that detecting animals in cluttered scenes using simple model units based on V1 cells worked almost as well as using more complex model units that were designed to model the responses of IT neurons. While these results suggest AIT might not be the primary brain region involved in this form of rapid categorization, additional studies are needed before drawing strong conclusions.",50 p.,MIT-CSAIL-TR-2010-034; CBCL-289,,,decoding; readout; rapid categorization; inferior temporal cortex; object recognition; scene understanding; neuroscience; visual clutter; electrophysiology,Examining high level neural representations of cluttered scenes,,,,,,,,,,,
