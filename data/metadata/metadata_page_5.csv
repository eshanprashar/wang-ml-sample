dc.contributor.author,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.subject,dc.title
"Dror, Ron O.; Adelson, Edward H.; Willsky, Alan S.",2004-10-08T20:36:32Z,2004-10-08T20:36:32Z,2001-09-01,AIM-2001-023,http://hdl.handle.net/1721.1/6656,"Humans recognize optical reflectance properties of surfaces such as metal, plastic, or paper from a single image without knowledge of illumination. We develop a machine vision system to perform similar recognition tasks automatically. Reflectance estimation under unknown, arbitrary illumination proves highly underconstrained due to the variety of potential illumination distributions and surface reflectance properties. We have found that the spatial structure of real-world illumination possesses some of the statistical regularities observed in the natural image statistics literature. A human or computer vision system may be able to exploit this prior information to determine the most likely surface reflectance given an observed image. We develop an algorithm for reflectance classification under unknown real-world illumination, which learns relationships between surface reflectance and certain features (statistics) computed from a single observed image. We also develop an automatic feature selection method.",22 p.; 7750699 bytes; 706071 bytes,application/postscript; application/pdf,en_US,AIM-2001-023,AI; reflectance; lighting; BRDF; surface; illumination statistics; natural images,Surface Reflectance Estimation and Natural Illumination Statistics
"Lee, Lily",2004-10-08T20:36:33Z,2004-10-08T20:36:33Z,2001-09-01,AIM-2001-019,http://hdl.handle.net/1721.1/6657,"This paper describes a representation of the dynamics of human walking action for the purpose of person identification and classification by gait appearance. Our gait representation is based on simple features such as moments extracted from video silhouettes of human walking motion. We claim that our gait dynamics representation is rich enough for the task of recognition and classification. The use of our feature representation is demonstrated in the task of person recognition from video sequences of orthogonal views of people walking. We demonstrate the accuracy of recognition on gait video sequences collected over different days and times, and under varying lighting environments. In addition, preliminary results are shown on gender classification using our gait dynamics features.",12 p.; 1128480 bytes; 92054 bytes,application/postscript; application/pdf,en_US,AIM-2001-019,AI; gait; recognition; gender classification,Gait Dynamics for Recognition and Classification
"Miller, Erik G.; Tieu, Kinh; Stauffer, Chris P.",2004-10-08T20:36:37Z,2004-10-08T20:36:37Z,2001-09-01,AIM-2001-021,http://hdl.handle.net/1721.1/6659,"We present a unifying framework in which ""object-independent"" modes of variation are learned from continuous-time data such as video sequences. These modes of variation can be used as ""generators"" to produce a manifold of images of a new object from a single  example of that object.   We develop the framework in the context of a well-known example: analyzing the modes of spatial deformations of a scene under camera movement. Our method learns a close approximation to the standard affine deformations that are expected from the geometry of the situation, and  does so in a completely unsupervised (i.e. ignorant of the geometry of the situation) fashion. We stress that it is learning a ""parameterization"", not just the parameter values, of the data. We then demonstrate how we have used the same framework to derive a novel  data-driven model of joint color change in images due to common lighting variations. The model is superior to previous models of color change in describing non-linear color changes due to lighting.",9 p.; 8233900 bytes; 814636 bytes,application/postscript; application/pdf,en_US,AIM-2001-021,AI; Invariance; Optical Flow; Color Constancy; Object Recognition; image manifold,Learning Object-Independent Modes of Variation with Feature Flow Fields
"Yu, Angela J.; Giese, Martin A.; Poggio, Tomaso A.",2004-10-20T21:03:51Z,2004-10-20T21:03:51Z,2001-09-01,AIM-2001-022; CBCL-207,http://hdl.handle.net/1721.1/7240,"Object recognition in the visual cortex is based on a hierarchical architecture, in which specialized brain regions along the ventral pathway extract object features of increasing levels of complexity, accompanied by greater invariance in stimulus size, position, and orientation. Recent theoretical studies postulate a non-linear pooling function, such as the maximum (MAX) operation could be fundamental in achieving such invariance. In this paper, we are concerned with neurally plausible mechanisms that may be involved in realizing the MAX operation. Four canonical circuits are proposed, each based on neural mechanisms that have been previously discussed in the context of cortical processing. Through simulations and mathematical analysis, we examine the relative performance and robustness of these mechanisms. We derive experimentally verifiable predictions for each circuit and discuss their respective physiological considerations.",28 p.; 2197042 bytes; 930880 bytes,application/postscript; application/pdf,en_US,AIM-2001-022; CBCL-207,AI; maximum operation; invariance; recurrent inhibition; shunting inhibition,Biologically Plausible Neural Circuits for Realization of Maximum Operations
"Taycher, Leonid; Darrell, Trevor",2004-10-08T20:36:35Z,2004-10-08T20:36:35Z,2001-09-01,AIM-2001-024,http://hdl.handle.net/1721.1/6658,"Visibility constraints can aid the segmentation of foreground objects observed with multiple range images. In our approach, points are defined as foreground if they can be determined to occlude some {em empty space} in the scene. We present an efficient algorithm to estimate foreground points in each range view using explicit epipolar search. In cases where the background pattern is stationary, we show how visibility constraints from other views can generate virtual background values at points with no valid depth in the primary view. We demonstrate the performance of both algorithms for detecting people in indoor office environments.",10 p.; 15686301 bytes; 1574798 bytes,application/postscript; application/pdf,en_US,AIM-2001-024,AI,Range Segmentation Using Visibility Constraints
"Arkoudas, Konstantine",2004-10-08T20:36:40Z,2004-10-08T20:36:40Z,2001-10-05,AIM-2001-025,http://hdl.handle.net/1721.1/6661,"This paper introduces Denotational Proof Languages (DPLs). DPLs are languages for presenting, discovering, and checking formal proofs. In particular, in this paper we discus type-alpha DPLs---a simple class of DPLs  for which termination is guaranteed and proof checking can be  performed in time linear in the size of the proof.  Type-alpha DPLs allow for lucid proof presentation and for efficient proof checking, but not for proof search.  Type-omega DPLs allow for search as well as simple presentation and checking, but termination is no longer guaranteed and  proof checking may diverge. We do not study type-omega DPLs here.   We start by listing some common characteristics of DPLs. We  then illustrate with a particularly simple example: a toy  type-alpha DPL called PAR, for deducing parities. We present the abstract syntax of PAR, followed by two  different kinds of formal semantics: evaluation and denotational.  We then relate the two semantics and show how proof checking  becomes tantamount to evaluation. We proceed to develop the  proof theory of PAR, formulating and studying certain  key notions such as observational equivalence that pervade all DPLs.   We then present NDL, a type-alpha DPL for classical zero-order  natural deduction. Our presentation of NDL mirrors that of PAR,  showing how every basic concept that was introduced in PAR resurfaces in NDL. We present sample proofs of several well-known tautologies of propositional logic that demonstrate our thesis that DPL proofs are  readable, writable, and concise. Next we contrast DPLs to typed logics based  on the Curry-Howard isomorphism, and discuss the distinction between pure and augmented DPLs. Finally we consider the issue of  implementing DPLs, presenting an implementation of PAR in SML and one in Athena, and end with some concluding remarks.",27 p.; 1766438 bytes; 815435 bytes,application/postscript; application/pdf,en_US,AIM-2001-025,AI; Deduction; formal proofs; semantics; proof checking; soundness; logic,Type-alpha DPLs
"Arkoudas, Konstantine",2004-10-08T20:36:42Z,2004-10-08T20:36:42Z,2001-10-16,AIM-2001-027,http://hdl.handle.net/1721.1/6662,"Type-omega DPLs (Denotational Proof Languages) are languages for proof presentation and search that offer strong soundness guarantees. LCF-type systems such as HOL offer similar guarantees, but their soundness relies heavily on static type systems. By contrast, DPLs  ensure soundness dynamically, through their evaluation semantics; no type system is necessary. This is possible owing to a novel two-tier syntax  that separates deductions from computations, and to the abstraction of assumption bases, which is factored into the semantics of the language and allows for sound evaluation.   Every type-omega DPL properly contains a type-alpha DPL, which can be used to present proofs in a lucid and detailed form, exclusively in terms of primitive inference rules. Derived inference rules are expressed  as user-defined methods, which are ""proof recipes"" that take arguments  and dynamically perform appropriate deductions. Methods arise naturally  via parametric abstraction over type-alpha proofs. In that light, the  evaluation of a method call can be viewed as a computation that carries  out a type-alpha deduction. The type-alpha proof ""unwound"" by such a method  call is called the ""certificate"" of the call. Certificates can be checked  by exceptionally simple type-alpha interpreters, and thus they are useful  whenever we wish to minimize our trusted base.   Methods are statically closed over lexical environments, but dynamically scoped over assumption bases. They can take other methods as arguments, they can iterate, and they can branch conditionally. These capabilities,  in tandem with the bifurcated syntax of type-omega DPLs and their dynamic assumption-base semantics, allow the user to define methods in  a style that is disciplined enough to ensure soundness yet fluid enough  to permit succinct and perspicuous expression of arbitrarily sophisticated derived inference rules.   We demonstrate every major feature of type-omega DPLs by defining and studying NDL-omega, a higher-order, lexically scoped, call-by-value type-omega DPL for classical zero-order natural deduction---a simple choice that allows us to focus on type-omega syntax and semantics rather than on the subtleties of the underlying logic. We start by illustrating how type-alpha DPLs naturally lead to type-omega DPLs by way of abstraction; present the formal syntax and semantics of NDL-omega; prove several results about it, including soundness; give numerous examples of methods; point out connections to the lambda-phi calculus, a very general framework for type-omega DPLs; introduce a notion of computational and deductive cost; define several instrumented interpreters for computing such costs and for generating certificates; explore the use of type-omega DPLs as general programming languages; show that DPLs do not have to be type-less by formulating a static Hindley-Milner polymorphic type system for NDL-omega; discuss some idiosyncrasies of type-omega DPLs such as the potential divergence of proof checking; and compare type-omega DPLs to other approaches to proof presentation and discovery. Finally, a complete implementation of NDL-omega in SML-NJ is given for users who want to run the examples and experiment with the language.",62 p.; 3794425 bytes; 787916 bytes,application/postscript; application/pdf,en_US,AIM-2001-027,AI; deduction; computation; proof search; soundness; logic,Type-omega DPLs
"Rennie, Jason D. M.; Rifkin, Ryan",2004-10-20T21:03:52Z,2004-10-20T21:03:52Z,2001-10-16,AIM-2001-026; CBCL-210,http://hdl.handle.net/1721.1/7241,"We compare Naive Bayes and Support Vector Machines on the task of multiclass text classification. Using a variety of approaches to combine the underlying binary classifiers, we find that SVMs substantially outperform Naive Bayes. We present full multiclass results on two well-known text data sets, including the lowest error to date on both data sets. We develop a new indicator of binary performance to show that the SVM's lower multiclass error is a result of its improved binary performance. Furthermore, we demonstrate and explore the surprising result that one-vs-all classification performs favorably compared to other approaches even though it has no error-correcting properties.",14 p.; 1240992 bytes; 1091543 bytes,application/postscript; application/pdf,en_US,AIM-2001-026; CBCL-210,AI; text classification; support vector machine; multiclass classification,Improving Multiclass Text Classification with the Support Vector Machine
"Fleming, Roland W.; Dror, Ron O.; Adelson, Edward H.",2004-10-08T20:36:44Z,2004-10-08T20:36:44Z,2001-10-21,AIM-2001-032,http://hdl.handle.net/1721.1/6663,"Under normal viewing conditions, humans find it easy to distinguish between objects made out of different materials such as plastic, metal, or paper. Untextured materials such as these have different surface reflectance properties, including lightness and gloss. With single isolated images and unknown illumination conditions, the task of estimating surface reflectance is highly underconstrained, because many combinations of reflection and illumination are consistent with a given image. In order to work out how humans estimate surface reflectance properties, we asked subjects to match the appearance of isolated spheres taken out of their original contexts. We found that subjects were able to perform the task accurately and reliably without contextual information to specify the illumination. The spheres were rendered under a variety of artificial illuminations, such as a single point light source, and a number of photographically-captured real-world illuminations from both indoor and outdoor scenes. Subjects performed more accurately for stimuli viewed under real-world patterns of illumination than under artificial illuminations, suggesting that subjects use stored assumptions about the regularities of real-world illuminations to solve the ill-posed problem.",9 p.; 7609556 bytes; 945959 bytes,application/postscript; application/pdf,en_US,AIM-2001-032,AI; illumination; reflectance; natural image statistics; human vision; BRDF,How do Humans Determine Reflectance Properties under Unknown Illumination?
"Dror, Ron O.; Edward H. Adelson,; Willsky, Alan S.",2004-10-08T20:36:53Z,2004-10-08T20:36:53Z,2001-10-21,AIM-2001-033,http://hdl.handle.net/1721.1/6664,"This paper describes a machine vision system that classifies reflectance properties of surfaces such as metal, plastic, or paper, under unknown real-world illumination. We demonstrate performance of our algorithm for surfaces of arbitrary geometry. Reflectance estimation under arbitrary omnidirectional illumination proves highly underconstrained. Our reflectance estimation algorithm succeeds by learning relationships between surface reflectance and certain statistics computed from an observed image, which depend on statistical regularities in the spatial structure of real-world illumination. Although the algorithm assumes known geometry, its statistical nature makes it robust to inaccurate geometry estimates.",9 p.; 5961528 bytes; 831200 bytes,application/postscript; application/pdf,en_US,AIM-2001-033,AI; illumination; reflectance; computer vision; geometry; natural image statistics,Recognition of Surface Reflectance Properties from a Single Image under Unknown Real-World Illumination
"Larsen, Samuel; Witchel, Emmett; Amarasinghe, Saman",2023-03-29T14:42:27Z,2023-03-29T14:42:27Z,2001-11,,https://hdl.handle.net/1721.1/149310,"Memory alignment is an important property in memory system performance. Extraction of alignment information at compile-time enables the possibility for new classes of program optimization. In this paper, we present methods for increasing and detecting the alignment of memory references in a program. Our transformations and analyses do not require interprocedural analysis and introduce almost no overhead. As a result, they can be incorporated into real compilation systems. On average, our techniques are able to achieve a five-fold increase in the number of dynamically aligned memory references. We are then able to detect 94% of these operations. This success is invaluable in providing performance gains in a range of different areas. When alignment information is incorporated into a vectorizing compiler, we can increase the performance of a G4 AltiVec processor by more than a factor of two. Using the same methods, we are able to reduce energy consumption in a data cache by as much as 35%.",,,,MIT-LCS-TM-621,,Techniques for Increasing and Detecting Memory Alignment
"Ostrovsky, Yuri; Cavanagh, Patrick; Sinha, Pawan",2004-10-20T21:03:57Z,2004-10-20T21:03:57Z,2001-11-05,AIM-2001-029; CBCL-209,http://hdl.handle.net/1721.1/7243,"The human visual system is adept at detecting and encoding statistical regularities in its spatio-temporal environment. Here we report an unexpected failure of this ability in the context of perceiving inconsistencies in illumination distributions across a scene. Contrary to predictions from previous studies [Enns and Rensink, 1990; Sun and Perona, 1996a, 1996b, 1997], we find that the visual system displays a remarkable lack of sensitivity to illumination inconsistencies, both in experimental stimuli and in images of real scenes. Our results allow us to draw inferences regarding how the visual system encodes illumination distributions across scenes. Specifically, they suggest that the visual system does not verify the global consistency of locally derived estimates of illumination direction.",13 p.; 3418249 bytes; 947913 bytes,application/postscript; application/pdf,en_US,AIM-2001-029; CBCL-209,AI; Illumination; natural scene perception; lighting direction; pop-out,Perceiving Illumination Inconsistencies in Scenes
"Torralba, Antonio; Sinha, Pawan",2004-10-20T21:03:55Z,2004-10-20T21:03:55Z,2001-11-05,AIM-2001-028; CBCL-208,http://hdl.handle.net/1721.1/7242,"The ability to detect faces in images is of critical ecological significance. It is a pre-requisite for other important face perception tasks such as person identification, gender classification and affect analysis. Here we address the question of how the visual system classifies images into face and non-face patterns. We focus on face detection in impoverished images, which allow us to explore information thresholds required for different levels of performance. Our experimental results provide lower bounds on image resolution needed for reliable discrimination between face and non-face patterns and help characterize the nature of facial representations used by the visual system under degraded viewing conditions. Specifically, they enable an evaluation of the contribution of luminance contrast, image orientation and local context on face-detection performance.",14 p.; 20987363 bytes; 1810477 bytes,application/postscript; application/pdf,en_US,AIM-2001-028; CBCL-208,AI; Face detection; image resolution; contrast negation; vertical inversion,Detecting Faces in Impoverished Images
"Corduneanu, Adrian; Jaakkola, Tommi",2004-10-08T20:37:18Z,2004-10-08T20:37:18Z,2001-11-08,AIM-2001-030,http://hdl.handle.net/1721.1/6679,"An increasing number of parameter estimation tasks involve the use of at least two information sources, one complete but limited, the other abundant but incomplete. Standard algorithms such as EM (or em) used in this context are unfortunately not stable in the sense that they can lead to a dramatic loss of accuracy with the inclusion of incomplete observations. We provide a more controlled solution to this problem through differential equations that govern the evolution of locally optimal solutions (fixed points) as a function of the source weighting. This approach permits us to explicitly identify any critical (bifurcation) points leading to choices unsupported by the available complete data. The approach readily applies to any graphical model in O(n^3) time where n is the number of parameters. We use the naive Bayes model to illustrate these ideas and demonstrate the effectiveness of our approach in the context of text classification problems.",9 p.; 1207127 bytes; 733599 bytes,application/postscript; application/pdf,en_US,AIM-2001-030,AI; semi-supervised learning; incomplete data; EM; stable estimation,Stable Mixing of Complete and Incomplete Information
"Arkoudas, Konstantine",2004-10-08T20:37:19Z,2004-10-08T20:37:19Z,2001-11-13,AIM-2001-031,http://hdl.handle.net/1721.1/6680,"This paper presents an algorithm for simplifying NDL deductions. An array of simplifying transformations are rigorously defined. They are shown to be terminating, and to respect the formal semantis of the language. We also show that the transformations never increase the size or complexity of a deduction---in the worst case, they produce deductions of the same size and complexity as the original. We present several examples of proofs containing various types of ""detours"", and explain how our procedure eliminates them, resulting in smaller and cleaner deductions. All of the given transformations are fully implemented in SML-NJ. The complete code listing is presented, along with explanatory comments. Finally, although the transformations given here are defined for NDL, we point out that they can be applied to any type-alpha DPL that satisfies a few simple conditions.",45 p.; 2306816 bytes; 532283 bytes,application/postscript; application/pdf,en_US,AIM-2001-031,AI; deduction; proofs; simplifiation; proof optimization; deduction complexity,Simplifying transformations for type-alpha certificates
"Wang, Karen",2023-03-29T15:34:42Z,2023-03-29T15:34:42Z,2001-12,,https://hdl.handle.net/1721.1/149932,This thesis proposes a new Active Queue Management (AQM) scheme called 2RegionRED.  It is superior to the classic Random Early Detection (RED) algorithm in that there is an intuitive way to set its parameters and it is self-tuning.  Its design is motivated by an original principle to sustain the smallest queue possible while still allowing for maximum link utilization.  2RegionRED uses the number of competing TCPs as its measure of load.  However it does not keep an explicit count.  The result is a novel algorithm that adjusts the drop rate according to two regions of operation: that requiring less than and greater than one drop per round-trip time (RTT).  This thesis also analyzes methods for measuring the persistent queue and proposes the ABSMIN method.  Simulations of 2RegionRED using ABSMIN reveal some difficulties and insights.  Basic comparisons to the Adaptive RED and Flow Proportional Queuing (FPQ) adaptive algorithms are also demonstrated through simulation,,,,MIT-LCS-TR-829,,2RegionRED: a Congestion Control Mechanism for the High Speed Internet
"Katabi, Dina; Blake, Charles",2023-03-29T15:34:40Z,2023-03-29T15:34:40Z,2001-12,,https://hdl.handle.net/1721.1/149931,,,,,MIT-LCS-TR-828,,Inferring Congestion Sharing and Path Characteristics from Packet Interarrival Times
"Torralba, Antonio; Oliva, Aude",2004-10-20T21:04:45Z,2004-10-20T21:04:45Z,2001-12-01,AIM-2001-036; CBCL-213,http://hdl.handle.net/1721.1/7267,"In the absence of cues for absolute depth measurements as binocular disparity, motion, or defocus, the absolute distance between the observer and a scene cannot be measured. The interpretation of shading, edges and junctions may provide a 3D model of the scene but it will not inform about the actual ""size"" of the space. One possible source of information for absolute depth estimation is the image size of known objects. However, this is computationally complex due to the difficulty of the object recognition process. Here we propose a source of information for absolute depth estimation that does not rely on specific objects: we introduce a procedure for absolute depth estimation based on the recognition of the whole scene. The shape of the space of the scene and the structures present in the scene are strongly related to the scale of observation. We demonstrate that, by recognizing the properties of the structures present in the image, we can infer the scale of the scene, and therefore its absolute mean depth. We illustrate the interest in computing the mean depth of the scene with application to scene recognition and object detection.",22 p.; 40226611 bytes; 7425856 bytes,application/postscript; application/pdf,en_US,AIM-2001-036; CBCL-213,AI; depth; monocular; scale selection; natural images; scene recognition,Global Depth Perception from Familiar Scene Structure
"Riesenhuber, Maximilian",2004-10-20T21:04:38Z,2004-10-20T21:04:38Z,2001-12-10,AIM-2001-034; CBCL-211,http://hdl.handle.net/1721.1/7265,"Baylis & Driver (Nature Neuroscience, 2001) have recently presented data on the response of neurons in macaque inferotemporal cortex (IT) to various stimulus transformations. They report that neurons can generalize over contrast and mirror reversal, but not over figure-ground reversal. This finding is taken to demonstrate that ``the selectivity of IT neurons is not determined simply by the distinctive contours in a display, contrary to simple edge-based models of shape recognition'', citing our recently presented model of object recognition in cortex (Riesenhuber & Poggio, Nature Neuroscience, 1999). In this memo, I show that the main effects of the experiment can be obtained by performing the appropriate simulations in our simple feedforward model. This suggests for IT cell tuning that the possible contributions of explicit edge assignment processes postulated in (Baylis & Driver, 2001) might be smaller than expected.",3 p.; 798352 bytes; 91696 bytes,application/postscript; application/pdf,en_US,AIM-2001-034; CBCL-211,AI; AI; computational neuroscience; object recognition; macaque; IT; invariance,"Generalization over contrast and mirror reversal, but not figure-ground reversal, in an ""edge-based"
"Yip, Andrew; Sinha, Pawan",2004-10-20T21:04:40Z,2004-10-20T21:04:40Z,2001-12-13,AIM-2001-035; CBCL-212,http://hdl.handle.net/1721.1/7266,"One of the key challenges in face perception lies in determining the contribution of different cues to face identification. In this study, we focus on the role of color cues. Although color appears to be a salient attribute of faces, past research has suggested that it confers little recognition advantage for identifying people. Here we report experimental results suggesting that color cues do play a role in face recognition and their contribution becomes evident when shape cues are degraded. Under such conditions, recognition performance with color images is significantly better than that with grayscale images. Our experimental results also indicate that the contribution of color may lie not so much in providing diagnostic cues to identity as in aiding low-level image-analysis processes such as segmentation.",12 p.; 1469164 bytes; 237772 bytes,application/postscript; application/pdf,en_US,AIM-2001-035; CBCL-212,AI; Face recognition; color; low-resolution; grayscale,Role of color in face recognition
