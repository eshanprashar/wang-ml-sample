dc.contributor.advisor,dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.relation.ispartofseries,dc.subject,dc.title,dc.language.iso,dc.relation.replaces,dc.relation.uri,dc.description,dc.rights,dc.rights.uri,dc.description.degree,dc.contributor.department
Anant Agarwal,"Liu, Jifeng; Psota, James; Beckmann, Nathan; Miller, Jason; Michel, Jurgen; Eastep, Jonathan; Kurian, George; Kimerling, Lionel; Agarwal, Anant; Beals, Mark",Computer Architecture,2009-05-06T18:30:04Z,2009-05-06T18:30:04Z,2009-05-05,http://hdl.handle.net/1721.1/45510,"Ever since industry has turned to parallelism instead of frequency scaling to improve processor performance, multicore processors have continued to scale to larger and larger numbers of cores. Some believe that multicores will have 1000 cores or more by the middle of the next decade. However, their promise of increased performance will only be reached if their inherent scaling and programming challenges are overcome. Meanwhile, recent advances in nanophotonic device manufacturing are making chip-stack optics a reality; interconnect technology which can provide significantly more bandwidth at lower power than conventional electrical analogs. Perhaps more importantly, optical interconnect also has the potential to enable new, easy-to-use programming models enabled by an inexpensive broadcast mechanism. This paper introduces ATAC, a new manycore architecture that capitalizes on the recent advances in optics to address a number of the challenges that future manycore designs will face. The new constraints and opportunities associated with on-chip optical interconnect are presented and explored in the design of ATAC. Furthermore, this paper introduces ACKwise, a novel directory-based cache coherence protocol that takes advantage of the special properties of ATAC to achieve high performance and scalability on large-scale manycores. Early performance results show that a 1000-core ATAC chip achieves a speedup of as much as 39% when compared with a similarly sized manycore with an electrical mesh network.",14 p.,MIT-CSAIL-TR-2009-018,Many-core processors; Processor interconnects; Optical interconnects,ATAC: A Manycore Processor with On-Chip Optical Network,,,,,,,,
William Freeman,"Levin, Anat; Hasinoff, Samuel W.; Freeman, William T.; Green, Paul; Durand, Fredo",Vision,2009-05-08T15:45:09Z,2009-05-08T15:45:09Z,2009-05-08,http://hdl.handle.net/1721.1/45513,"Depth of field (DOF), the range of scene depths that appear sharp in a photograph, poses a fundamental tradeoff in photography---wide apertures are important to reduce imaging noise, but they also increase defocus blur. Recent advances in computational imaging modify the acquisition process to extend the DOF through deconvolution. Because deconvolution quality is a tight function of the frequency power spectrum of the defocus kernel, designs with high spectra are desirable. In this paper we study how to design effective extended-DOF systems, and show an upper bound on the maximal power spectrum that can be achieved. We analyze defocus kernels in the 4D light field space and show that in the frequency domain, only a low-dimensional 3D manifold contributes to focus. Thus, to maximize the defocus spectrum, imaging systems should concentrate their limited energy on this manifold. We review several computational imaging systems and show either that they spend energy outside the focal manifold or do not achieve a high spectrum over the DOF. Guided by this analysis we introduce the lattice-focal lens, which concentrates energy at the low-dimensional focal manifold and achieves a higher power spectrum than previous designs. We have built a prototype lattice-focal lens and present extended depth of field results.",18 p.,MIT-CSAIL-TR-2009-019,light fields; Fourier analysis; Computational cameras; depth of field,4D Frequency Analysis of Computational Cameras for Depth of Field Extension,,,,,,,,
Tomaso Poggio,"Terashima, Yoshito",Center for Biological and Computational Learning (CBCL),2009-05-11T17:30:10Z,2009-05-11T17:30:10Z,2009-05-10,http://hdl.handle.net/1721.1/45516,"We present a biologically motivated method for scene image classification. The core of the method is to use shape based image property that is provided by a hierarchical feedforward model of the visual cortex [18]. Edge based and color based image properties are additionally used to improve the accuracy. The method consists of two stages of image analysis. In the first stage, each of three paths of classification uses each image property (i.e. shape, edge or color based features) independently. In the second stage, a single classifier assigns the category of an image based on the probability distributions of the first stage classifier outputs. Experiments show that the method boosts the classification accuracy over the shape based model. We demonstrate that this method achieves a high accuracy comparable to other reported methods on publicly available color image dataset.",8 p.,CBCL-277; MIT-CSAIL-TR-2009-020,image classification; vision,Scene Classification with a Biologically Inspired Method,,,,,,,,
Nancy Lynch,"Kuhn, Fabian; Newport, Calvin; Lynch, Nancy",Theory of Computation,2009-05-11T17:30:04Z,2009-05-11T17:30:04Z,2009-05-11,http://hdl.handle.net/1721.1/45515,"A diversity of possible communication assumptions complicates the study of algorithms and lower bounds for radio networks. We address this problem by defining an Abstract MAC Layer. This service provides reliable local broadcast communication, with timing guarantees stated in terms of a collection of abstract \emph{delay functions} applied to the relevant contention. Algorithm designers can analyze their algorithms in terms of these functions, independently of specific channel behavior. Concrete implementations of the Abstract MAC Layer over basic radio network models generate concrete definitions for these delay functions, automatically adapting bounds proven for the abstract service to bounds for the specific radio network under consideration. To illustrate this approach, we use the Abstract MAC Layer to study the new problem of Multi-Message Broadcast, a generalization of standard single-message broadcast, in which any number of messages arrive at any processes at any times.We present and analyze two algorithms for Multi-Message Broadcast in static networks: a simple greedy algorithm and one that uses regional leaders. We then indicate how these results can be extended to mobile networks.",27 p.,MIT-CSAIL-TR-2009-021,network modeling; mobile networks; wireless networks; medium-acccess protocols,The Abstract MAC Layer,en,MIT-CSAIL-TR-2009-009,http://hdl.handle.net/1721.1/44620,,,,,
Boris Katz,"Marton, Gregory Adam; Westrick, Linda Brown",Infolab,2009-05-28T19:00:05Z,2009-05-28T19:00:05Z,2009-05-28,http://hdl.handle.net/1721.1/45548,"To help explore linguistic semantics in the context of computational natural language understanding, Sepia provides a realization the central theoretical idea of categorial grammar: linking words and phrases to compositional lambda semantics.  The Sepia framework provides a language in 
which to express complex transformations from text to data structures, and tools surrounding that language for parsing and machine learning.  Lambda semantics are expressed as arbitrary Scheme programs, unlimited in the semantic representations they may build, and the rules for transformation are expressed in Combinatory Categorial Grammar, though the details of grammar formalism may be easily changed.  This report explains the major design decisions, and is meant to teach the reader how to understand Sepia semantics and how to create lexical items for a new language understanding task.",25 p.,,,Sepia: a Framework for Natural Language Semantics,,,,Source code and technical description,Creative Commons Attribution-Share Alike 3.0 Unported,http://creativecommons.org/licenses/by-sa/3.0/,,
Nancy Lynch,"Locher, Thomas; Kuhn, Fabian; Oshman, Rotem",Theory of Computation,2009-05-29T16:00:04Z,2009-05-29T16:00:04Z,2009-05-29,http://hdl.handle.net/1721.1/45549,"Over the last years, large-scale decentralized computer networks such as peer-to-peer and mobile ad hoc networks have become increasingly prevalent. The topologies of many of these networks are often highly dynamic. This is especially true for ad hoc networks formed by mobile wireless devices. In this paper, we study the fundamental problem of clock synchronization in dynamic networks. We show that there is an inherent trade-off between the skew S guaranteed along sufficiently old links and the time needed to guarantee a small skew along new links. For any sufficiently large initial skew on a new link, there are executions in which the time required to reduce the skew on the link to O(S) is at least Omega(n/S). We show that this bound is tight for moderately small values of S. Assuming a fixed set of n nodes and an arbitrary pattern of edge insertions and removals, a weak dynamic connectivity requirement suffices to prove the following results. We present an algorithm that always maintains a skew of O(n) between any two nodes in the network. For a parameter S = Omega(sqrt{rho n}), where rho is the maximum hardware clock drift, it is further guaranteed that if a communication link between two nodes u, v persists in the network for at least Omega(n/S) time, the clock skew between u and v is reduced to no more than O(S).",33 p.,MIT-CSAIL-TR-2009-022,time synchronization; distributed algorithms; lower bound,Gradient Clock Synchronization in Dynamic Networks,,,,,,,,
Nancy Lynch,"Lynch, Nancy; Newport, Calvin",Theory of Computation,2009-06-05T15:30:06Z,2009-06-05T15:30:06Z,2009-06-04,http://hdl.handle.net/1721.1/45553,"We describe a modeling framework and collection of foundational composition results for the study of probabilistic distributed algorithms in synchronous radio networks. Existing results in this setting rely on informal descriptions of the channel behavior and therefore lack easy comparability and are prone to error caused by definition subtleties. Our framework rectifies these issues by providing: (1) a method to precisely describe a radio channel as a probabilistic automaton; (2) a mathematical notion of implementing one channel using another channel, allowing for direct comparisons of channel strengths and a natural decomposition of problems into implementing a more powerful channel and solving the problem on the powerful channel; (3) a mathematical definition of a problem and solving a problem; (4) a pair of composition results that simplify the tasks of proving properties about channel implementation algorithms and combining problems with channel implementations. Our goal is to produce a model streamlined for the needs of the radio network algorithms community.",21 p.,MIT-CSAIL-TR-2009-023,,Modeling Radio Networks,,,,,,,,
Daniel Jackson,"Edwards, Jonathan",Software Design,2009-06-12T21:30:04Z,2009-06-12T21:30:04Z,2009-06-12,http://hdl.handle.net/1721.1/45563,"Side effects are both the essence and bane of imperative programming. The programmer must carefully coordinate actions to manage their side effects upon each other. Such coordination is complex, error-prone, and fragile. Coherent reaction is a new model of change-driven computation that coordinates effects automatically. State changes trigger events called reactions that in turn change other states. A coherent execution order is one in which each reaction executes before any others that are affected by its changes. A coherent order is discovered iteratively by detecting incoherencies as they occur and backtracking their effects. Unlike alternative solutions, much of the power of imperative programming is retained, as is the common sense notion of mutable state. Automatically coordinating actions lets the programmer express what to do, not when to do it. Coherent reactions are embodied in the Coherence language, which is specialized for interactive applications like those common on the desktop and web. The fundamental building block of Coherence is the dynamically typed mutable tree. The fundamental abstraction mechanism is the virtual tree, whose value is lazily computed, and whose behavior is generated by coherent reactions.",15 p.,MIT-CSAIL-TR-2009-024,reactive systems; synchronous reactive programming; interactive systems; functional reactive programming; bidirectional functions,Coherent Reaction,,,,,Creative Commons Attribution 3.0 Unported,http://creativecommons.org/licenses/by/3.0/,,
Dina Katabi,"Katabi, Dina; Raskar, Ramesh; Mohan, Ankit; Woo, Grace",Networks & Mobile Systems,2009-06-15T23:15:04Z,2009-06-15T23:15:04Z,2009-06-15,http://hdl.handle.net/1721.1/45565,"We demonstrate a freespace optical system using a consumer camera and projector in indoor environments using available devices for visual computing. Through design, prototype and experimentation with this commodity hardware, we analyze a practical optical solution as well as the drawbacks for current wireless challenges unmet by classic RF wireless communication. We summarize and introduce some new applications enabled by such similar setups.",5 p.,,Visible Light Communication,Simple LCD Transmitter Camera Receiver Data Link,,,,,,,,
,"Micali, Silvio",Theory of Computation,2009-06-16T15:00:04Z,2009-06-16T15:00:04Z,2009-06-15,http://hdl.handle.net/1721.1/45566,,1 p.,MIT-CSAIL-TR-2009-025,,A Useful Homomorphic Encryption Method,,,,,,,,
Srini Devadas,"Devadas, Srinivas; Agarwal, Anant; Hoffmann, Henry",Computer Architecture,2009-06-16T17:15:03Z,2009-06-16T17:15:03Z,2009-06-16,http://hdl.handle.net/1721.1/45567,"This work presents four partitioning strategies, or patterns, useful for decomposing a serial application into multiple concurrently executing parts. These partitioning strategies augment the commonly used task and data parallel design patterns by recognizing that applications are spatiotemporal in nature. Therefore, data and instruction decomposition are further distinguished by whether the partitioning is done in the spatial or in temporal dimension. Thus, this work describes four decomposition strategies: spatial data partitioning (SDP), temporal data partitioning (TDP), spatial instruction partitioning (SIP), and temporal instruction partitioning (TIP), while cataloging the benefits and drawbacks of each. In addition, the practical use of these strategies is demonstrated through a case study in which they are applied to implement several different parallelizations of a multicore H.264 encoder for HD video. This case study illustrates both the application of the patterns and their effects on the performance of the encoder.",16 p.,MIT-CSAIL-TR-2009-026,,Partitioning Strategies for Concurrent Programming,,,,,,,,
Nancy Lynch,"Lynch, Nancy; Ley-Wild, Ruy; Kuhn, Fabian; Cornejo, Alejandro",Theory of Computation,2009-06-17T21:15:03Z,2009-06-17T21:15:03Z,2009-06-17,http://hdl.handle.net/1721.1/45568,"Designing robust algorithms for mobile agents with reliable communication is difficult due to the distributed nature of computation, in mobile ad hoc networks (MANETs) the matter is exacerbated by the need to ensure connectivity. Existing distributed algorithms provide coordination but typically assume connectivity is ensured by other means. We present a connectivity service that encapsulates an arbitrary motion planner and can refine any plan to preserve connectivity (the graph of agents remains connected) and ensure progress (the agents advance towards their goal). The service is realized by a distributed algorithm that is modular in that it makes no assumptions of the motion-planning mechanism except the ability for an agent to query its position and intended goal position, local in that it uses 1-hop broadcast to communicate with nearby agents but doesn't need any network routing infrastructure, and \emph{oblivious} in that it does not depend on previous computations. We prove the progress of the algorithm in one round is at least Omega(min(d,r)), where d is the minimum distance between an agent and its target and r is the communication radius. We characterize the worst case configuration and show that when d >= r this bound is tight and the algorithm is optimal, since no algorithm can guarantee greater progress. Finally we show all agents get epsilon-close to their targets within O(D_0/r+n^2/epsilon) rounds where n is the number of agents and D_0 is the initial distance to the targets.",21 p.,MIT-CSAIL-TR-2009-027,,Keeping Mobile Robots Connected,,,,,,,,
John Leonard,"Benjamin, Michael R.; Leonard, John J.; Schmidt, Henrik; Newman, Paul M.","Robotics, Vision & Sensor Networks",2009-06-18T17:45:13Z,2009-06-18T17:45:13Z,2009-06-18,http://hdl.handle.net/1721.1/45569,"This document describes the IvP Helm - an Open Source behavior-based autonomy application for unmanned vehicles. IvP is short for interval programming - a technique for representing and solving multi-objective optimizations problems. Behaviors in the IvP Helm are reconciled using multi-objective optimization when in competition with each other for influence of the vehicle. The IvP Helm is written as a MOOS application where MOOS is a set of Open Source publish-subscribe autonomy middleware tools. This document describes the configuration and use of the IvP Helm, provides examples of simple missions and information on how to download and build the software from the MOOS-IvP server at www.moosivp.org.",168 p.,MIT-CSAIL-TR-2009-028,UUV; AUV; Behavior Based Architecture; Unmanned Surface Vehicles; Behavior Based Control; Unmanned Marine Vehicles; Action Selection; Collision Avoidance; Multi-Objective Optimization; Unmanned Vehicles; MOOS; USV; Autonomous Decision Making; Autonomous Marine Vehicles; Autonomous Helm; Arbitration; Autonomous Vehicles; Underwater Vehicles; AI; MOOSDB; Behaviors,An Overview of MOOS-IvP and a Brief Users Guide to the IvP Helm Autonomy Software,,,,,,,,
Tomaso Poggio,"Poggio, Tomaso; Serre, Thomas; Tan, Cheston; Chikkerur, Sharat",Center for Biological and Computational Learning (CBCL),2009-06-22T17:15:20Z,2009-06-22T17:15:20Z,2009-06-20,http://hdl.handle.net/1721.1/45598,"Apart from helping shed some light on human perceptual mechanisms, modeling visual attention has important applications in computer vision. It has been shown to be useful in priming object detection, pruning interest points, quantifying visual clutter as well as predicting human eye movements. Prior work has either relied on purely bottom-up approaches or top-down schemes using simple low-level features. In this paper, we outline a top-down visual attention model based on shape-based features. The same shape-based representation is used to represent both the objects and the scenes that contain them. The spatial priors imposed by the scene and the feature priors imposed by the target object are combined in a Bayesian framework to generate a task-dependent saliency map. We show that our approach can predict the location of objects as well as match eye movements (92% overlap with human observers). We also show that the proposed approach performs better than existing bottom-up and top-down computational models.",10 p.,CBCL-278; MIT-CSAIL-TR-2009-029,attention; bayesian network,An integrated model of visual attention using shape-based features,,,,,,,,
Fredo Durand,"Scull, Craig; Johnson, Steve; Aliaga, Frederick; Paris, Sylvain; Su, Sara L.; Durand, Fredo",Computer Graphics,2009-06-24T23:00:06Z,2009-06-24T23:00:06Z,2009-06-24,http://hdl.handle.net/1721.1/45600,"Presentation and graphics software enables users to experiment with variations of illustrations. They can revisit recent editing operations using the ubiquitous undo command, but they are limited to sequential exploration. We propose a new interaction metaphor and visualization for operation history. While editing, a user can access a history mode in which actions are denoted by graphical depictions appearing on top of the document. Our work is inspired by the visual language of film storyboards and assembly instructions. Our storyboard provides an interactive visual history, summarizing the editing of a document or a selected object. Each view is composed of action depictions representing the userâ  s editing actions and enables the user to consider the operation history in context rather than in a disconnected list view. This metaphor provides instant access to any past action and we demonstrate that this is an intuitive interface to a selective undo mechanism.",12 p.,MIT-CSAIL-TR-2009-031,interaction techniques; vector graphics; visualization; undo; storyboard; operation history,Interactive Visual Histories for Vector Graphics,,,,,,,,
Fredo Durand,"Su, Sara L.",Computer Graphics,2009-06-24T21:45:39Z,2009-06-24T21:45:39Z,2009-06-24,http://hdl.handle.net/1721.1/45599,"Graphical editors have introduced great flexibility to the designer's workflow, providing powerful digital tools and enabling the creation of complex and compelling designs. This thesis presents methods for improving these interactions by leveraging operation history. Much instrumentation and activity logging in software has been for the purpose of debugging, that is, for the benefit of the programmer or analyst. Our work addresses the mining of operation history for the benefit of the end user. We present three main contributions in this area. First, we introduce selection expansion, a method for facilitating the reuse of complex multiple-item selections by identifying items that are likely to be edited together. We then discuss an extension of this work, soft grouping, which gives users more control than standard selection and more flexibility than standard grouping. Finally, we present an interactive visualization of operation history, interactive storyboards, which enables in-context browsing and manipulation of operation history. We demonstrate these approaches in the context of vector graphics editing and present the results of pilot studies using our software implementation. While this thesis focuses on the usage patterns of graphic designers, many of the strategies could be generalized to other domains.",123 p.,MIT-CSAIL-TR-2009-030,operation history; storyboard; human computer interaction; selection; grouping; computer graphics; 2D drawing; interactive techniques; vector graphics,Enhanced Visual Authoring Using Operation History,,,,PhD thesis,,,Ph.D.,Electrical Engineering and Computer Science
Daniel Jackson,"Jackson, Daniel; Estler, H.-Christian; Rayside, Derek",Software Design,2009-07-03T19:15:04Z,2009-07-03T19:15:04Z,2009-07-03,http://hdl.handle.net/1721.1/46322,"This paper presents a new general-purpose algorithm for exact solving of combinatorial many-objective optimization problems. We call this new algorithm the guided improvement algorithm. The algorithm is implemented on top of the non-optimizing relational constraint solver Kodkod. We compare the performance of this new algorithm against two algorithms from the literature [Gavanelli 2002, Lukasiewycz et alia 2007, Laumanns et alia 2006]) on three micro-benchmark problems (n-Queens, n-Rooks, and knapsack) and on two aerospace case studies. Results indicate that the new algorithm is better for the kinds of many-objective problems that our aerospace collaborators are interested in solving. The new algorithm returns Pareto-optimal solutions as it computes.",20 p.,MIT-CSAIL-TR-2009-033,,"The Guided Improvement Algorithm for Exact, General-Purpose, Many-Objective Combinatorial Optimization",,,,,Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 Unported,http://creativecommons.org/licenses/by-nc-nd/3.0/,,
Ted Adelson,"Pfister, Hanspeter; Freeman, William T.; Avidan, Shai; Dale, Kevin; Johnson, Micah K.; Matusik, Wojciech",Vision,2009-07-21T21:30:34Z,2009-07-21T21:30:34Z,2009-07-15,http://hdl.handle.net/1721.1/46335,"Computer Graphics (CG) has achieved a high level of realism, producing strikingly vivid images. This realism, however, comes at the cost of long and often expensive manual modeling, and most often humans can still distinguish between CG images and real images. We present a novel method to make CG images look more realistic that is simple and accessible to novice users. Our system uses a large collection of photographs gathered from online repositories. Given a CG image, we retrieve a small number of real images with similar global structure. We identify corresponding regions between the CG and real images using a novel mean-shift cosegmentation algorithm. The user can then automatically transfer color, tone, and texture from matching regions to the CG image. Our system only uses image processing operations and does not require a 3D model of the scene, making it fast and easy to integrate into digital content creation workflows. Results of a user study show that our improved CG images appear more realistic than the originals.",10 p.,MIT-CSAIL-TR-2009-034,image databases; image synthesis; computer graphics,CG2Real: Improving the Realism of Computer Generated Images using a Large Collection of Photographs,,,,,,,,
Anant Agarwal,"Miller, Jason; Agarwal, Anant; Santambrogio, Marco; Eastep, Jonathan; Hoffmann, Henry",Computer Architecture,2009-08-07T17:45:05Z,2009-08-07T17:45:05Z,2009-08-07,http://hdl.handle.net/1721.1/46351,"Adaptive, or self-aware, computing has been proposed as one method to help application programmers confront the growing complexity of multicore software development. However, existing approaches to adaptive systems are largely ad hoc and often do not manage to incorporate the true performance goals of the applications they are designed to support. This paper presents an enabling technology for adaptive computing systems: Application Heartbeats. The Application Heartbeats framework provides a simple, standard programming interface that applications can use to indicate their performance and system software (and hardware) can use to query an applicationâ  s performance. Several experiments demonstrate the simplicity and efficacy of the Application Heartbeat approach. First the PARSEC benchmark suite is instrumented with Application Heartbeats to show the broad applicability of the interface. Then, an adaptive H.264 encoder is developed to show how applications might use Application Heartbeats internally. Next, an external resource scheduler is developed which assigns cores to an application based on its performance as specified with Application Heartbeats. Finally, the adaptive H.264 encoder is used to illustrate how Application Heartbeats can aid fault tolerance.",10 p.,MIT-CSAIL-TR-2009-035,,Application Heartbeats for Software Performance and Health,,,,,,,,
Srini Devadas,"Devadas, Srinivas; Cho, Myong Hyon; Shim, Keun Sup; Lis, Mieszko",Computation Structures,2009-08-18T22:30:03Z,2009-08-18T22:30:03Z,2009-08-18,http://hdl.handle.net/1721.1/46353,"In-order packet delivery, a critical abstraction for many higher-level protocols, can severely limit the performance potential in low-latency networks (common, for example, in network-on-chip designs with many cores). While basic variants of dimension-order routing guarantee in-order delivery, improving performance by adding multiple dynamically allocated virtual channels or using other routing schemes compromises this guarantee. Although this can be addressed by reordering out-of-order packets at the destination core, such schemes incur significant overheads, and, in the worst case, raise the specter of deadlock or require expensive retransmission. We present Exclusive Dynamic VCA, an oblivious virtual channel allocation scheme which combines the performance advantages of dynamic virtual allocation with in-network, deadlock-free in-order delivery. At the same time, our scheme reduces head-of-line blocking, often significantly improving throughput compared to equivalent baseline (out-of-order) dimension-order routing when multiple virtual channels are used, and so may be desirable even when in-order delivery is not required. Implementation requires only minor, inexpensive changes to traditional oblivious dimension-order router architectures, more than offset by the removal of packet reorder buffers and logic.",10 p.,MIT-CSAIL-TR-2009-036,,Guaranteed in-order packet delivery using Exclusive Dynamic Virtual Channel Allocation,,,,,,,,
