dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.title,dc.subject,dc.contributor.advisor,dc.description,dc.relation.isversionof,dc.identifier.citation,dc.description.degree
"Su, Sara L.; Durand, Fredo; Agrawala, Maneesh",Computer Graphics,2005-12-22T02:28:16Z,2005-12-22T02:28:16Z,2005-04-12,MIT-CSAIL-TR-2005-025; MIT-LCS-TR-987,http://hdl.handle.net/1721.1/30537,"A major obstacle in photography is the presence of distracting elements that pull attention away from the main subject and clutter the composition. In this article, we present a new image-processing technique that reduces the salience of distracting regions. It is motivated by computational models of attention that predict that texture variation influences bottom-up attention mechanisms. Our method reduces the spatial variation of texture using power maps, high-order features describing local frequency content in an image. We show how modification of power maps results in  powerful image de-emphasis. We validate our results using a user search experiment and eye tracking data.",12 p.; 24844567 bytes; 1742248 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,De-Emphasis of Distracting Image Regions Using Texture Power Maps,,,,,,
"Beal, Jacob",,2005-12-22T02:28:22Z,2005-12-22T02:28:22Z,2005-04-13,MIT-CSAIL-TR-2005-026; AIM-2005-012,http://hdl.handle.net/1721.1/30538,"Examples are a powerful tool for teaching both humans and computers.In order to learn from examples, however, a student must first extractthe examples from its stream of perception. Snapshot learning is ageneral approach to this problem, in which relevant samples ofperception are used as examples.  Learning from these examples can inturn improve the judgement of the snapshot mechanism, improving thequality of future examples.  One way to implement snapshot learning isthe Top-Cliff heuristic, which identifies relevant samples using ageneralized notion of peaks. I apply snapshot learning with theTop-Cliff heuristic to solve a distributed learning problem and showthat the resulting system learns rapidly and robustly, and canhallucinate useful examples in a perceptual stream from a teacherlesssystem.",22 p.; 16733589 bytes; 735336 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Learning From Snapshot Examples,AI; unsupervised supervised learning examples,,,,,
"Caponnetto, Andrea; Vito, Ernesto De",,2005-12-22T02:28:27Z,2005-12-22T02:28:27Z,2005-04-14,MIT-CSAIL-TR-2005-027; AIM-2005-013; CBCL-248,http://hdl.handle.net/1721.1/30539,"We develop a theoretical analysis of generalization performances of regularized least-squares on reproducing kernel Hilbert spaces for supervised learning.  We show that the concept of effective dimension of an integral operator plays a central role in the definition of a criterion for the choice of the regularization parameter as a function of the number of samples.  In fact, a minimax analysis is performed which shows asymptotic optimality of the above-mentioned criterion.",25 p.; 16130108 bytes; 833989 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Fast Rates for Regularized Least-squares Algorithm,AI; optimal rates; regularized least-squares; reproducing kernel Hilbert space; effe,,,,,
"Eisenstein, Jacob; Davis, Randall",,2005-12-22T02:28:32Z,2005-12-22T02:28:32Z,2005-04-19,MIT-CSAIL-TR-2005-028; AIM-2005-014,http://hdl.handle.net/1721.1/30540,"In human-human dialogues, face-to-face meetings are often preferred over phone conversations.One explanation is that non-verbal modalities such as gesture provide additionalinformation, making communication more efficient and accurate. If so, computerprocessing of natural language could improve by attending to non-verbal modalitiesas well. We consider the problem of sentence segmentation, using hand-annotatedgesture features to improve recognition. We find that gesture features correlate wellwith sentence boundaries, but that these features improve the overall performance of alanguage-only system only marginally. This finding is in line with previous research onthis topic. We provide a regression analysis, revealing that for sentence boundarydetection, the gestural features are largely redundant with the language model andpause features. This suggests that gestural features can still be useful when speech recognition is inaccurate.",13 p.; 13772256 bytes; 521371 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Gestural Cues for Sentence Segmentation,AI; gesture; natural language processing; multimodal,,,,,
"Taylor, Christopher; Rahimi, Ali; Bachrach, Jonathan; Shrobe, Howard",,2005-12-22T02:28:41Z,2005-12-22T02:28:41Z,2005-04-26,MIT-CSAIL-TR-2005-029; AIM-2005-016,http://hdl.handle.net/1721.1/30541,"We introduce Simultaneous Localization and Tracking (SLAT), the  problem of tracking a target in a sensor network while  simultaneously localizing and calibrating the nodes of the network.  Our proposed solution, LaSLAT, is a Bayesian filter providing  on-line probabilistic estimates of sensor locations and target  tracks. It does not require globally accessible beacon signals or  accurate ranging between the nodes.  When applied to a network of 27  sensor nodes, our algorithm can localize the nodes to within one or  two centimeters.",18 p.; 40655574 bytes; 2128443 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"Simultaneous Localization, Calibration, and Tracking in an ad Hoc Sensor Network",AI; sensor network; localization; bayesian filter; extended kalman filter,,,,,
"McCamant, Stephen; Morrisett, Greg",Program Analysis,2005-12-22T02:28:49Z,2005-12-22T02:28:49Z,2005-05-02,MIT-CSAIL-TR-2005-030; MIT-LCS-TR-988,http://hdl.handle.net/1721.1/30542,"Executing untrusted code while preserving security requiresenforcement of memory and control-flow safety policies:untrusted code must be prevented from modifying memory orexecuting code except as explicitly allowed.  Software-basedfault isolation (SFI) or \""sandboxing\"" enforces thosepolicies by rewriting the untrusted code at the level ofindividual instructions.  However, the original sandboxingtechnique of Wahbe et al. is applicable only to RISCarchitectures, and other previous work is either insecure,or has been not described in enough detail to giveconfidence in its security properties.  We present a noveltechnique that allows sandboxing to be easily applied to aCISC architecture like the IA-32.  The technique can beverified to have been applied at load time, so that neitherthe rewriting tool nor the compiler needs to be trusted.  Wedescribe a prototype implementation which provides a robustsecurity guarantee, is scalable to programs of any size, andhas low runtime overheads.  Further, we give amachine-checked proof that any program approved by theverification algorithm is guaranteed to respect the desiredsafety property.",17 p.; 29512899 bytes; 1053603 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,"Efficient, Verifiable Binary Sandboxing for a CISC Architecture",,,,,,
"Vito, Ernesto De; Caponnetto, Andrea",,2005-12-22T02:28:54Z,2005-12-22T02:28:54Z,2005-05-16,MIT-CSAIL-TR-2005-031; AIM-2005-015; CBCL-249,http://hdl.handle.net/1721.1/30543,We show that recent results in [3] on risk bounds for regularized least-squares on reproducing kernel Hilbert spaces can be straightforwardly extended to the vector-valued regression setting.  We first briefly introduce central concepts on operator-valued kernels.  Then we show how risk bounds can be expressed in terms of a generalization of effective dimension.,17 p.; 12090406 bytes; 642646 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Risk Bounds for Regularized Least-squares Algorithm with Operator-valued kernels,AI; optimal rates; reproducing kernel Hilbert space; effective dimension,,,,,
"Singh, Neha",Advanced Network Architecture,2005-12-22T02:29:27Z,2005-12-22T02:29:27Z,2005-05-17,MIT-CSAIL-TR-2005-032; MIT-LCS-TR-989,http://hdl.handle.net/1721.1/30544,"A service-providing system consists of hosts that provide services such as data, content, computational and memory resources and data-based services to other entities in the system. Consumers that wish to use services describe their needs with a set of high-level objectives. In this thesis, we address the problem of locating services in a large-scale distributed system using their descriptions, rather than their addresses. We propose a network architecture that is based on the concept of dividing the service-providing hosts into Regions. A Region is a grouping of elements of the network that share a set of common characteristics and policies. Members of a region manage their interactions with other regions and their elements according to some defined rules and policies. Hosts can be divided into regions based on various properties such as their content, their commercial model or their security characteristics to name a few. The service provided by a region is an ! aggregate of the services provided by all its member hosts. The region-based architecture routes a service request through the network efficiently based on its description and on the advertisements from regions providing services. Division of hosts into a set of independent regions partitions the search space and produces a scalable structure. The architecture also does not impose any rules on the internal organization of regions making the system flexible and dynamic.",136 p.; 114357185 bytes; 3081677 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,A Region-based Architecture for Service-Providing Distributed Systems,,,,,,
"Caponnetto, Andrea; Rakhlin, Alexander",,2005-12-22T02:29:32Z,2005-12-22T02:29:32Z,2005-05-17,MIT-CSAIL-TR-2005-033; AIM-2005-018; CBCL-250,http://hdl.handle.net/1721.1/30545,"We study properties of algorithms which minimize (or almost minimize) empirical error over a Donsker class of functions. We show that the L2-diameter of the set of almost-minimizers is converging to zero in probability. Therefore, as the number of samples grows, it is becoming unlikely that adding a point (or a number of points) to the training set will result in a large jump (in L2 distance) to a new hypothesis. We also show that under some conditions the expected errors of the almost-minimizers are becoming close with a rate faster than n^{-1/2}.",9 p.; 7033622 bytes; 434782 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Some Properties of Empirical Risk Minimization over Donsker Classes,AI; empirical risk minimization; stability; empirical processes,,,,,
"Nahnsen, Thade; Uzuner, Ozlem; Katz, Boris",,2005-12-22T02:29:37Z,2005-12-22T02:29:37Z,2005-05-19,MIT-CSAIL-TR-2005-034; AIM-2005-017,http://hdl.handle.net/1721.1/30546,"We present a system to determine content similarity of documents. More specifically, our goal is to identify book chapters that are translations of the same original chapter; this task requires identification of not only the different topics in the documents but also the particular flow of these topics. We experiment with different representations employing n-grams of lexical chains and test these representations on a corpus of approximately 1000 chapters gathered from books with multiple parallel translations.  Our representations include the cosine similarity of attribute vectors of n-grams of lexical chains, the cosine similarity of tf*idf-weighted keywords, and the cosine similarity of unweighted lexical chains (unigrams of lexical chains) as well as multiplicative combinations of the similarity measures produced by these approaches. Our results identify fourgrams of unordered lexical chains as a particularly useful representation for text similarity evaluation.",9 p.; 17827888 bytes; 7011726 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Lexical Chains and Sliding Locality Windows in Content-based Text Similarity Detection,AI; Natural Language Processing; N-grams; Text Similarity; Lexical Chains,,,,,
"Li, Hui X.",Model-based Embedded and Robotic Systems,2010-04-15T17:30:04Z,2010-04-15T17:30:04Z,2005-05-20,,http://hdl.handle.net/1721.1/53718,"Conflict-directed search algorithms have formed the core of practical, model-based reasoning systems for the last three decades. In many of these applications there is a series of discrete constraint optimization problems and a conflict-directed search algorithm, which uses conflicts in the forward search step to focus search away from known infeasibilities and towards the optimal solution. In the arena of model-based autonomy, discrete systems, like deep space probes, have given way to more agile systems, such as coordinated vehicle control, which must robustly control their continuous dynamics. Controlling these systems requires optimizing over continuous, as well as discrete variables, using linear and non-linear as well as logical constraints. This thesis explores the development of algorithms for solving ybrid discrete/linear optimization problems that use conflicts in the forward search direction, generalizing from the conflict-directed search algorithms of based reasoning. We introduce a novel algorithm called Generalized Conflict-directed Branch and Bound (GCD-BB). GCD-BB extends traditional Branch and Bound (B&B), by first constructing conflicts from nodes of the search tree that are found to be infeasible or sub-optimal, and then by using these conflicts to guide the forward search away from known infeasible and sub-optimal states. We evaluate GCD-BB empirically on a range of test problems of coordinated air vehicle control. GCD-BB demonstrates a substantial improvement in performance compared to a traditional B&B algorithm, applied to either disjunctive linear programs or an equivalent binary integer program encoding.",76 p.,,,MIT-CSAIL-TR-2010-017,Generalized Conflict Learning For Hybrid Discrete Linear Optimization,Constraint satisfaction; Optimization; Hybrid systems,Brian Williams,SM thesis,http://hdl.handle.net/1721.1/32466,"Li, H., Generalized Conflict Learning For Hybrid Discrete Linear Optimization, Master's Thesis, MIT, 2005",SM
"Wu, Jia Jane",,2005-12-22T02:29:44Z,2005-12-22T02:29:44Z,2005-05-25,MIT-CSAIL-TR-2005-035; AITR-2005-002; CBCL-251,http://hdl.handle.net/1721.1/30547,"This thesis presents a method of object classification using the idea of deformable shape matching.  Three types of visual features, geometric blur, C1 and SIFT, are used to generate feature descriptors.  These feature descriptors are then used to find point correspondences between pairs of images.  Various morphable models are created by small subsets of these correspondences using thin-plate spline.  Given these morphs, a simple algorithm, least median of squares (LMEDS), is used to find the best morph.  A scoring metric, using both LMEDS and distance transform, is used to classify test images based on a nearest neighbor algorithm.  We perform the experiments on the Caltech 101 dataset [5].  To ease computation, for each test image, a shortlist is created containing 10 of the most likely candidates.  We were unable to duplicate the performance of [1] in the shortlist stage because we did not use hand-segmentation to extract objects for our training images.  However, our gain from the shortlist to correspondence stage is comparable to theirs.  In our experiments, we improved from 21% to 28% (gain of 33%), while [1] improved from 41% to 48% (gain of 17%).  We find that using a non-shape based approach, C2 [14], the overall classification rate of 33.61% is higher than all of the shaped based methods tested in our experiments.",42 p.; 39773758 bytes; 1459526 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Comparing Visual Features for Morphing Based Recognition,AI; object recognition; shape-based,,,,,
"Caponnetto, Andrea; Rosasco, Lorenzo; Vito, Ernesto De; Verri, Alessandro",,2005-12-22T02:29:53Z,2005-12-22T02:29:53Z,2005-05-27,MIT-CSAIL-TR-2005-036; AIM-2005-019; CBCL-252,http://hdl.handle.net/1721.1/30548,"This paper presents an approach to model selection for regularized least-squares on reproducing kernel Hilbert spaces in the semi-supervised setting.  The role of effective dimension was recently shown to be crucial in the definition of a rule for the choice of the regularization parameter, attaining asymptotic optimal performances in a minimax sense.  The main goal of the present paper is showing how the effective dimension can be replaced by an empirical counterpart while conserving optimality.  The empirical effective dimension can be computed from independent unlabelled samples.  This makes the approach particularly appealing in the semi-supervised setting.",14 p.; 11158573 bytes; 526018 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Empirical Effective Dimension and Optimal Rates for Regularized Least Squares Algorithm,AI; optimal rates; effective dimension; semi-supervised learning,,,,,
"Taylor, Christopher J.",,2005-12-22T02:30:00Z,2005-12-22T02:30:00Z,2005-05-31,MIT-CSAIL-TR-2005-037; AITR-2005-003,http://hdl.handle.net/1721.1/30549,"In this thesis we present LaSLAT, a sensor network algorithm thatsimultaneously localizes sensors, calibrates sensing hardware, andtracks unconstrained moving targets using only range measurementsbetween the sensors and the target. LaSLAT is based on a Bayesian filter, which updates a probabilitydistribution over the quantities of interest as measurementsarrive. The algorithm is distributable, and requires only a constantamount of space with respect to the number of measurementsincorporated. LaSLAT is easy to adapt to new types of hardware and newphysical environments due to its use of intuitive probabilitydistributions: one adaptation demonstrated in this thesis uses amixture measurement model to detect and compensate for bad acousticrange measurements due to echoes.We also present results from a centralized Java implementation ofLaSLAT on both two- and three-dimensional sensor networks in whichranges are obtained using the Cricket ranging system. LaSLAT is ableto localize sensors to within several centimeters of their groundtruth positions while recovering a range measurement bias for eachsensor and the complete trajectory of the mobile.",69 p.; 81859537 bytes; 3510560 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Simultaneous Localization and Tracking in Wireless Ad-hoc Sensor Networks,AI; Localization; Target Tracking; Sensor Network; Calibration,,,,,
"Segonne, Florent; Pons, Jean-Philippe; Fischl, Bruce; Grimson, Eric",,2005-12-22T02:32:21Z,2005-12-22T02:32:21Z,2005-06-01,MIT-CSAIL-TR-2005-038; AIM-2005-020,http://hdl.handle.net/1721.1/30550,"We present a novel framework to exert a topology control over a level set evolution. Level set methods offer several advantages over parametric active contours, in particular automated topological changes. In some applications, where some a priori knowledge of the target topology is available, topological changes may not be desirable. A method, based on the concept of simple point borrowed from digital topology, was recently proposed to achieve a strict topology preservation during a level set evolution. However, topologically constrained evolutions often generate topological barriers that lead to large geometric inconsistencies. We introduce a topologically controlled level set framework that greatly alleviates this problem. Unlike existing work, our method allows connected components to merge, split or vanish under some specific conditions that ensure that no topological defects are generated. We demonstrate the strength of our method on a wide range of numerical experiments.",16 p.; 60440380 bytes; 1311817 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,A Novel Active Contour Framework. Multi-component Level Set  Evolution under Topology Control,AI; digital topology; level set; active contour,,,,,
"Larsen, Sam; Rabbah, Rodric; Amarasinghe, Saman",Computer Architecture,2005-12-19T23:46:12Z,2005-12-19T23:46:12Z,2005-06-03,MIT-CSAIL-TR-2005-039; MIT-LCS-TM-651,http://hdl.handle.net/1721.1/30423,"An emerging trend in processor design is the incorporation of short vector instructions into the ISA.  In fact, vector extensions have appeared in most general-purpose microprocessors.  To utilize these instructions, traditional vectorization technology can be used to identify and exploit data parallelism. In contrast, efficient use of a processor\'s scalar resources is typically achieved through ILP techniques such as software pipelining.  In order to attain the best performance, it is necessary to utilize both sets of resources.  This paper presents a novel approach for exploiting vector parallelism in a software pipelined loop.  At its core is a method for judiciously partitioning operations between vector and scalar resources.  The proposed algorithm (i) lowers the burden on the scalar resources by offloading computation to the vector functional units, and (ii) partially (or fully) inhibits the optimizations when full vectorization will decrease performance. !  This results in better resource usage and allows for software pipelining with shorter initiation intervals.  Although our techniques complement statically scheduled machines most naturally, we believe they are applicable to any architecture that tightly integrates support for ILP and data parallelism.An important aspect of the proposed methodology is its ability to manage explicit communication of operands between vector and scalar instructions.  Our methodology also allows for a natural handling of misaligned vector memory operations.  For architectures that provide hardware support for misaligned references, software pipelining effectively hides the latency of these potentially expensive instructions.  When explicit alignment is required in software, our algorithm accounts for these extra costs and vectorizes only when it is profitable.  Finally, our heuristic can take advantage of alignment information where it is available.We evaluate our methodology using several DSP and SPEC FP benchmarks.  Compared to software pipelining, our approach is able to achieve an average speedup of 1.30x and 1.18x for the two benchmark sets, respectively.",14 p.; 19708112 bytes; 690985 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Exploiting Vector Parallelism in Software Pipelined Loops,,,,,,
"Kumar, Ravi; Liben-Nowell, David; Novak, Jasmine; Raghavan, Prabhakar; Tomkins, Andrew",Theory of Computation,2005-12-22T02:32:28Z,2005-12-22T02:32:28Z,2005-06-03,MIT-CSAIL-TR-2005-040; MIT-LCS-TR-990,http://hdl.handle.net/1721.1/30551,"We introduce a formal model for geographic social networks, and introduce the notion of rank-based friendship, in which the probability that a person v is a friend of a person u is inversely proportional to the number of people w who live closer to u than v does.  We then prove our main theorem, showing that rank-based friendship is a sufficient explanation of the navigability of any geographic social network that adheres to it.",8 p.; 8282908 bytes; 444233 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Theoretical Analysis of Geographic Routing in Social Networks,,,,,,
"rahimi, ali; recht, ben; darrell, trevor",,2005-12-22T02:32:35Z,2005-12-22T02:32:35Z,2005-06-06,MIT-CSAIL-TR-2005-041; AIM-2005-021,http://hdl.handle.net/1721.1/30552,"Many high-dimensional time-varying signals can be modeled as a  sequence of noisy nonlinear observations of a low-dimensional  dynamical process.  Given high-dimensional observations and a  distribution describing the dynamical process, we present a  computationally inexpensive approximate algorithm for estimating the  inverse of this mapping. Once this mapping is learned, we can invert  it to construct a generative model for the signals. Our algorithm  can be thought of as learning a manifold of images by taking into  account the dynamics underlying the low-dimensional representation  of these images. It also serves as a nonlinear system identification  procedure that estimates the inverse of the observation function in  nonlinear dynamic system.  Our algorithm reduces to a generalized  eigenvalue problem, so it does not suffer from the computational or  local minimum issues traditionally associated with nonlinear system  identification, allowing us to apply it to the problem of learning  generative models for video sequences.",11 p.; 13801637 bytes; 2196348 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Nonlinear Latent Variable Models for Video Sequences,"AI; Manifold learning,nonlinear system identification; unsupervised learning",,,,,
"Saff, David; Artzi, Shay; Perkins, Jeff H.; Ernst, Michael D.",Program Analysis,2005-12-22T02:32:40Z,2005-12-22T02:32:40Z,2005-06-08,MIT-CSAIL-TR-2005-042; MIT-LCS-TR-991,http://hdl.handle.net/1721.1/30553,"Test factoring creates fast, focused unit tests from slow system-widetests; each new unit test exercises only a subset of the functionalityexercised by the system test.  Augmenting a test suite with factoredunit tests should catch errors earlier in a test run.One way to factor a test is to introduce 'mock' objects.  If a testexercises a component T, which interacts with another component E (the'environment'), the implementation of E can be replaced by a mock.The mock checks that T's calls to E are as expected, and it simulatesE's behavior in response.  We introduce an automatic technique fortest factoring.  Given a system test for T and E, and a record of T'sand E's behavior when the system test is run, test factoring generatesunit tests for T in which E is mocked.  The factored tests can isolatebugs in T from bugs in E and, if E is slow or expensive, improve testperformance or cost.We have built an implementation of automatic dynamic test factoring for theJava language.  Our experimental data indicates that it can reduce therunning time of a system test suite by up to an order of magnitude.",10 p.; 21413970 bytes; 780396 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Automatic Test Factoring for Java,,,,,,
"Muthitacharoen, Athicha; Gilbert, Seth; Morris, Robert",Parallel and Distributed Operating Systems,2005-12-22T02:32:54Z,2005-12-22T02:32:54Z,2005-06-15,MIT-CSAIL-TR-2005-044; MIT-LCS-TR-993,http://hdl.handle.net/1721.1/30555,"This paper presents Etna, an algorithm for atomic reads and writes of replicated data stored in a distributed hash table. Etna correctly handles dynamically changing sets of replica hosts, and is optimized for reads, writes, and reconfiguration, in that order.Etna maintains a series of replica configurations as nodes in the system change, using new sets of replicas from the pool supplied by the distributed hash table system. It uses the Paxos protocol to ensure consensus on the members of each new configuration. For simplicity and performance, Etna serializes all reads and writes through a primary during the lifetime of each configuration. As a result, Etna completes read and write operations in only a single round from the primary.Experiments in an environment with high network delaysshow that Etna's read latency is determined by round-tripdelay in the underlying network, while write and reconfiguration latency is determined by the transmission time required to send data to each replica. Etna's write latency is about the same as that of a non-atomic replicating DHT, and Etna's read latency is about twice that of a non-atomic DHT due to Etna assembling a quorum for every read.",10 p.; 16474627 bytes; 693416 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,Etna: a Fault-tolerant Algorithm for Atomic Mutable DHT Data,,,,,,
