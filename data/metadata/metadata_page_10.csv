dc.contributor.author,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.subject,dc.title,dc.contributor.advisor,dc.contributor.other,dc.identifier.citation
"Perez-Breva, Luis; Yoshimi, Osamu",2004-10-20T20:48:55Z,2004-10-20T20:48:55Z,2002-12-01,AIM-2002-023; CBCL-222,http://hdl.handle.net/1721.1/7181,"A difficulty in the design of automated text  summarization   algorithms is in the objective evaluation.  Viewing summarization   as a tradeoff between length and  information content, we introduce   a technique based on a hierarchy of  classifiers to rank, through   model selection, different summarization  methods. This summary   evaluation technique allows for broader  comparison of   summarization methods than the traditional  techniques of summary   evaluation. We present an empirical study  of two simple, albeit   widely used, summarization methods that  shows the different usages   of this automated task-based evaluation  system and confirms the   results obtained with human-based  evaluation methods over smaller   corpora.",1739841 bytes; 1972183 bytes,application/postscript; application/pdf,en_US,AIM-2002-023; CBCL-222,AI,Model Selection in Summary Evaluation,,,
"Grossman, J.P.",2004-10-20T20:00:24Z,2004-10-20T20:00:24Z,2002-12-05,AITR-2002-011,http://hdl.handle.net/1721.1/6828,"Parallel shared-memory machines with hundreds or thousands of processor-memory nodes have been built; in the future we will see machines with millions or  even billions of nodes. Associated with such large systems is a new set of  design challenges. Many problems must be addressed by an architecture in  order for it to be successful; of these, we focus on three in particular.  First, a scalable memory system is required. Second, the network messaging  protocol must be fault-tolerant. Third, the overheads of thread creation,  thread management and synchronization must be extremely low.  This thesis presents the complete system design for Hamal, a shared-memory  architecture which addresses these concerns and is directly scalable to one  million nodes. Virtual memory and distributed objects are implemented in a  manner that requires neither inter-node synchronization nor the storage of  globally coherent translations at each node. We develop a lightweight  fault-tolerant messaging protocol that guarantees message delivery and  idempotence across a discarding network. A number of hardware mechanisms  provide efficient support for massive multithreading and fine-grained  synchronization.  Experiments are conducted in simulation, using a trace-driven network  simulator to investigate the messaging protocol and a cycle-accurate simulator to evaluate the Hamal architecture. We determine implementation parameters  for the messaging protocol which optimize performance. A discarding network  is easier to design and can be clocked at a higher rate, and we find that with this protocol its performance can approach that of a non-discarding network.  Our simulations of Hamal demonstrate the effectiveness of its thread  management and synchronization primitives. In particular, we find  register-based synchronization to be an extremely efficient mechanism which  can be used to implement a software barrier with a latency of only 523 cycles on a 512 node machine.",186 p.; 14854547 bytes; 6844439 bytes,application/postscript; application/pdf,en_US,AITR-2002-011,AI; parallel; network; simulation; hashing; multithreading; synchronization,Design and Evaluation of the Hamal Parallel Computer,,,
"Newton, Ryan; Beal, Jacob",2006-03-01T19:47:25Z,2006-03-01T19:47:25Z,2002-12-10,MIT-CSAIL-TR-2006-015,http://hdl.handle.net/1721.1/31221,"We propose a method for the robust implementation of simple graphical automataon an amorphous computer. This infrastructure is applied to the implementationof purely functional programming languages. Specifically, it is usedin conjunction with data-flow techniques to implement a toy language homologousto recurrence equations, exploiting control-flow parallelism through paralleloperand evaluation. Also, data parallelism is explored in a separate implementation,in which a simple mark-up syntax enables Scheme programs to performspatially-distributed tree-walking without modifying their semantics. This additionenables an idiomatically expressed interpreter to be trivially instrumented,producing a spatially distributed universal machine, and once again achievingcontrol flow parallelism in the interpreted language.",20 p.; 21433070 bytes; 757210 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Amorphous Infrastructure for Language Implementation,Gerald Sussman,Mathematics and Computation,6.978 Final Project
"Suh, G. Edward; Clarke, Dwaine; Gassend, Blaise; van Dijk, Marten; Devadas, Srinivas",2023-03-30T15:51:48Z,2023-03-29T15:36:51Z; 2023-03-30T15:51:48Z,2003,,https://hdl.handle.net/1721.1/149977.2,"We describe the architecture for a single-chip AEGIS processor which can be used to build computing systems secure against both physical and software attacks. Our architecture assumes that all components external to the processor, such as memory, are untrusted. We show two different implementations. In the first case, the core functionality of the operating system is trusted and implemented in a security kernel. We also describe a variant implementation assuming an untrusted operating system. AEGIS provides users with tamper-evident, authenticated environments in which any physical or software tampering by an adversary is guaranteed to be detected, and private and authenticated tamper-resistant environments where additionally the adversary is unable to obtain any information about software or data by tampering with, or otherwise observing, system operation. AEGIS enables many applications, such as commercial grid computing, secure mobile agents, software licensing, and digital rights management. Preliminary simulation results indicate that the overhead of security mechanisms in AEGIS is reasonable.",,,,MIT-LCS-TR-883a,,AEGIS: Architecture for Tamper-Evident and Tamper-Resistant Processing,,,
"Suh, G. Edward; Clarke, Dwaine; Gassend, Blaise; van Dijk, Marten; Devadas, Srinivas",2023-03-30T15:53:37Z,2023-03-29T15:36:51Z; 2023-03-30T15:51:48Z; 2023-03-30T15:53:37Z,2003,,https://hdl.handle.net/1721.1/149977.3,"We describe the architecture of the AEGIS processor which can be used to build computing systems secure against both physical and software attacks. AEGIS assumes that the operating system and all components external to it, such as memory, are untrusted. AEGIS provides tamper-evident, authenticated environments in which any physical or software tampering by the adversary is guaranteed to be detected, and private and authenticated, tamper-resistant environments where additionally the adversary is unable to obtain any information about software or data by tampering with, or otherwise observing, system operation. AEGIS enables many applications, such as commercial grid computing, software licensing, and digital rights management. We present a new encryption/decryption method that successfully hides a significant portion of encryption/decryption latency, in comparison to a conventional direct encryption scheme. Efficient memory encryption and integrity verification enable the implementation of a secure computing system with the only trusted component being a single-chip AEGIS CPU. Detailed simulation results indicate that the performance overhead of security mechanisms in AEGIS is reasonable.",,,,MIT-LCS-TR-883b,,The AEGIS Processor Architecture for Tamper-Evident and Tamper-Resistant Processing,,,
"Suh, G. Edward; Clarke, Dwaine; Gassend, Blaise; van Dijk, Marten; Devadas, Srinivas",2023-03-30T16:31:13Z,2023-03-29T15:36:51Z; 2023-03-30T15:51:48Z; 2023-03-30T15:53:37Z; 2023-03-30T16:31:13Z,2003,,https://hdl.handle.net/1721.1/149977.4,"We describe the architecture for a single-chip AEGIS processor which can be used to build computing systems secure against both physical and software attacks. Our architecture assumes that all components external to the processor, such as memory, are untrusted. We show two different implementations. In the first case, the core functionality of the operating system is trusted and implemented in a security kernel. We also describe a variant implementation assuming an untrusted operating system. AEGIS provides users with  tamper-evident, authenticated environments in which any physical or software tampering by an adversary is guaranteed to be detected, and private and authenticated tamper-resistant environments where additionally the adversary is unable to obtain any information about software or data by tampering with, or otherwise observing, system operation. AEGIS enables many applications, such as commercial grid computing, secure mobile agents, software licensing, and digital rights management. We also present a new encryption/decryption method that successfully hides a significant portion of encryption/decryption latency, in comparison to a conventional direct encryption scheme. Efficient memory encryption and integrity verification enable the implementation of a secure computing system with the only trusted component being a single-chip AEGIS CPU. Preliminary simulation results indicate that the overhead of security mechanisms in AEGIS is reasonable.",,,,MIT-LCS-TR-883c;,,The AEGIS Processor Architecture for Tamper-Evident and Tamper-Resistant Processing,,,
"Lynch, Nancy A.; Segala, Roberto; Vaandrager, Frits",2023-03-30T15:36:48Z,2023-03-29T15:34:34Z; 2023-03-30T15:32:47Z; 2023-03-30T15:36:48Z,2003-01,,https://hdl.handle.net/1721.1/149930.3,"Hybrid systems are systems that exhibit a combination of discrete and continuous behavior. Typical hybrid systems include computer components, which operate in discrete program steps, and real-world components, whose behavior over time intervals evolves according to physical constraints. Important examples of hybrid systems include automated transportation systems, robotics systems, process control systems, systems of embedded devices, and mobile computing systems. Such systems can be very complex, and very difficult to describe and analyze. This paper presents the Hybrid Input/Output Automaton (HIOA) modeling framework, a basic mathematical framework to support description and analysis of hybrid systems. An important feature of this model is its support for decomposing hybrid system descriptions. In particular, the framework includes a notion of external behavior for a hybrid I/O automaton, which captures its discrete and continuous interactions with its environment. The framework also defines what it means for one HIOA to implement another, based on an inclusion relationship between their external behavior sets, and defines a notion of simulation, which provides a sufficient condition for demonstrating implementation relationships. The framework also includes a composition operation for HIOAs, which respects external behavior, and a notion of receptiveness, which implies that an HIOA does not block the passage of time. The framework is intended to support analysis methods from both computer science and control theory. This work is a simplification of an earlier version of the HIOA model [49, 50]. The main simplification in the new model is a clearer separation between the mechanisms used to model discrete and continuous interaction between components. In particular, the new model removes the dual use of external variables for discrete and continuous interaction.",,,,MIT-LCS-TR-827c,,Hybrid I/O Automata*,,,
"Kuncak, Viktor; Rinard, Martin",2023-03-29T15:36:43Z,2023-03-29T15:36:43Z,2003-01,,https://hdl.handle.net/1721.1/149974,"We show that the first-order theory of structural subtyping of non-recursive types is decidable.   Let Sigma be a language consisting of function symbols (representing type constructors) and C a decidable structure in the relational language L containing a binary relation <. C represents primitive types; < represents a subtype ordering.  We introduce the notion of Sigma-term-power of C, which generalizes the structure arising in structural subtyping.  The domain of the Sigma-term-power of C is the set of Sigma-terms over the set of elements of C.   We show that the decidability of the first-order theory of C implies the decidability of the first-order theory of the Sigma-term-power of C.  This result implies the decidability of the first-order theory of structural subtyping of non-recursive types.   Our decision procedure is based on quantifier elimination and makes use of quantifier elimination for term algebras and Feferman-Vaught construction for products of decidable structures.   We also explore connections between the theory of structural subtyping of recursive types and monadic second-order theory of tree-like structures.  In particular, we give an embedding of the monadic second-order theory of infinite binary tree into the first-order theory of structural subtyping of recursive types.",,,,MIT-LCS-TR-879,,On the Theory of Structural Subtyping,,,
"Suh, G. Edward; Clarke, Dwaine; Gassend, Blaise; van Dijk, Marten; Devadas, Srinivas",2023-03-29T15:36:51Z,2023-03-29T15:36:51Z,2003-01,,https://hdl.handle.net/1721.1/149977,"We describe the architecture of the AEGIS processor which can be used to build computing systems secure against both physical and software attacks. AEGIS assumes that the operating system and all components external to it, such as memory, are untrusted. AEGIS provides tamper-evident, authenticated environments in which any physical or software tampering by the adversary is guaranteed to be detected, and private and authenticated, tamper-resistant environments where additionally the adversary is unable to obtain any information about software or data by tampering with, or otherwise observing, system operation. AEGIS enables many applications, such as commercial grid computing, software licensing, and digital rights management. We present a new encryption/decryption method that successfully hides a significant portion of encryption/decryption latency, in comparison to a conventional direct encryption scheme. Efficient memory encryption and integrity verification enable the implementation of a secure computing system with the only trusted component being a single-chip AEGIS CPU. Detailed simulation results indicate that the performance overhead of security mechanisms in AEGIS is reasonable.",,,,MIT-LCS-TR-883,,The AEGIS Processor Architecture for Tamper-Evident and Private Tamper-Resistant Processing,,,
"Kaminsky, Michael; Peterson, Eric; Fu, Kevin; MaziÃ¨res, David; Kaashoek, M. Frans",2023-03-29T15:36:55Z,2023-03-29T15:36:55Z,2003-01,,https://hdl.handle.net/1721.1/149978,"The ubiquitous SSH package has demonstrated the importance of   secure remote login and execution.  This paper presents a new system,   REX, designed to provide remote login and execution in the context of   the SFS secure distributed file system.  REX departs from traditional   remote login design and is built around two main mechanisms---file   descriptor passing and a user agent process.        File descriptor passing allows REX to be split into several   smaller pieces; privileged code can run as its own process to   provide enhanced security guarantees.  REX also emulates secure file   descriptor passing over network connections, allowing users to build   extensions to REX outside of the core REX software.        REX uses and extends SFS's agent mechanism to provide a   transparent distributed computing environment to users.  The   agent stores private keys, server nicknames, and other per-user   configuration state; REX makes the SFS agent available to programs   that it executes on remote machines.        We have an implementation of REX and demonstrate that its   flexibility does not come at the cost of performance.  Initial REX   connections are comparable to those of SSH in speed, while subsequent   connections are much faster because REX exploits the SFS agent to   cache connection state to avoid costly public-key operations.",,,,MIT-LCS-TR-884,,"REX: Secure, modular remote execution through file descriptor passing",,,
"Krashinsky, Ronny",2023-03-29T15:36:49Z,2023-03-29T15:36:49Z,2003-01,,https://hdl.handle.net/1721.1/149976,"Efficient web browsing on mobile computers presents a unique challenge.  These machines are different from other classes of client computers since they have relatively low-bandwidth connections and they are battery-powered and therefore limited by their energy consumption.  However, they tend to interact with the same servers for the delivery of web content.  This project investigates optimizing the final critical link between a mobile client and a stationary base station by compressing HTTP request and response messages.  Using a split proxy design, compression of individual request messages reduces bandwidth by 26% to 34% across a variety of benchmark traces, and applying compression to response messages yields savings of 59% to 82% of the compressible data.  Higher compression rates are achieved by using streaming compression algorithms to compress the streams of request and response messages.  In this case, the bandwidth for requests sees an order of magnitude improvement, and the response stream obtains additional savings of 7% to 25% on top of the savings achieved with per-response compression.",,,,MIT-LCS-TR-882,,Efficient Web Browsing for Mobile Clients using HTTP Compression,,,
"Srebro, Nathan; Jaakkola, Tommi",2004-10-08T20:38:40Z,2004-10-08T20:38:40Z,2003-01-15,AIM-2003-001,http://hdl.handle.net/1721.1/6708,"We study the frequent problem of approximating a target matrix with a matrix of lower rank. We provide a simple and efficient (EM) algorithm for solving {\\em weighted} low rank approximation problems, which, unlike simple matrix factorization problems, do not admit a closed form solution in general. We analyze, in addition, the nature of locally optimal solutions that arise in this context, demonstrate the utility of accommodating the weights in reconstructing the underlying low rank representation, and extend the formulation to non-Gaussian noise models such as classification (collaborative filtering).",10 p.; 2061103 bytes; 911431 bytes,application/postscript; application/pdf,en_US,AIM-2003-001,AI; svd pca,Generalized Low-Rank Approximations,,,
"Ostrovsky, Rafail; Rackoff, Charles; Smith, Adam",2023-03-29T15:36:58Z,2023-03-29T15:36:58Z,2003-02,,https://hdl.handle.net/1721.1/149979,"A consistent query protocol allows a database owner to publish a very short string c which commits her to a particular database D with special consistency property (i.e., given c, every allowable query has unique and well-defined answer with respect to D.)  Moreover, when a user makes a query, any server hosting the database can answer the query, and provide a very short proof P that the answer is well-defined, unique, and consistent with c (and hence with D).  One potential application of consistent query protocols is for guaranteeing the consistency of many replicated copies of D---the owner can publish c, and users can verify the consistency of a query to some copy of D by making sure P is consistent with c.  This strong guarantee holds even for owners who try to cheat, while creating c.  The task of consistent query protocols was originally proposed for membership queries by Micali and Rabin, and subsequently and independently, by Kilian. In this setting a server can prove to a client whether or not a given key is present or not in a database, based only on a short public commitment c.  We strengthen their results in several ways. For membership queries, we improve the communication complexity; more importantly, we provide protocols for more general types of queries and more general relational databases.  For example, we consider databases in which entries have several keys and where we allow range queries (e.g. we allow a client to ask for all entries within a certain age range and a certain salary range).   Towards this goal, we introduce query algorithms with certain inherent robustness properties---called data-robust algorithms---and show how this robustness can be achieved. In particular, we illustrate our general technique by constructing an efficient data-robust algorithm for proving consistency of orthogonal range queries (a particular case of a ``join''query).  The server's proof convinces the client not only that all the matching entries provided are in D, but also that no others are present.  Our guarantees hold even if the answer is the empty set.  In the case of one-dimensional range queries we also show a new data-hiding technique---called explicit hashing---which allows us to a execute consistent query protocol P and at the same time protect the privacy of all other information in the database efficiently. In particular, we avoid the NP reductions required in a generic zero-knowledge proof.",,,,MIT-LCS-TR-887,,Efficient Consistency Proofs on a Committed Database,,,
"Gassend, Blaise",2023-03-29T15:36:46Z,2023-03-29T15:36:46Z,2003-02,,https://hdl.handle.net/1721.1/149975,"In general, secure protocols assume that participants are able to maintain secret key information. In practice, this assumption is often incorrect as an increasing number of devices are vulnerable to physical attacks.  Typical examples of vulnerable devices are smartcards and Automated Teller Machines.   To address this issue, Physical Random Functions are introduced. These are Random Functions that are physically tied to a particular device. To show that Physical Random Functions solve the initial problem, it must be shown that they can be made, and that it is possible to use them to provide secret keys for higher level protocols. Experiments with Field Programmable Gate Arrays are used to evaluate the feasibility of Physical Random Functions in silicon.",,,,MIT-LCS-TR-881,,Physical Random Functions,"Devadas, Srinivas",,
"Adler, Aaron D.",2004-10-20T20:31:48Z,2004-10-20T20:31:48Z,2003-02-01,AITR-2003-004,http://hdl.handle.net/1721.1/7103,"Sketches are commonly used in the early stages of  design. Our previous system allows users to sketch mechanical systems that  the computer interprets. However, some parts of the mechanical  system might be too hard or too complicated to express in the sketch.  Adding speech recognition to create a multimodal system would move  us toward our goal of creating a more natural user interface. This  thesis examines the relationship between the verbal and sketch input,  particularly how to segment and align the two inputs. Toward this end,  subjects were recorded while they sketched and talked. These  recordings were transcribed, and a set of rules to perform segmentation  and alignment was created. These rules represent the knowledge that  the computer needs to perform segmentation and alignment. The  rules successfully interpreted the 24 data sets that they were given.",193 p.; 34430522 bytes; 46149955 bytes,application/postscript; application/pdf,en_US,AITR-2003-004,AI; sketch; design; multimodal; disambiguation; segmentation; alignment,Segmentation and Alignment of Speech and Sketching in a Design Environment,,,
"Kim, Philip Mjong-Hyon Shin",2004-10-20T20:31:34Z,2004-10-20T20:31:34Z,2003-02-05,AITR-2003-001,http://hdl.handle.net/1721.1/7099,"Biological systems exhibit rich and complex behavior through the orchestrated interplay of a large array of components. It is hypothesized that separable subsystems with some degree of functional autonomy exist; deciphering their independent behavior and functionality would greatly facilitate understanding the system as a whole. Discovering and analyzing such subsystems are hence pivotal problems in the quest to gain a quantitative understanding of complex biological systems.  In this work, using approaches from machine learning, physics and graph theory, methods for the identification and analysis of such subsystems were developed. A novel methodology, based on a recent machine learning algorithm known as non-negative matrix factorization (NMF), was developed to discover such subsystems in a set of large-scale gene expression data. This set of subsystems was then used to predict functional relationships between genes, and this approach was shown to score significantly higher than conventional methods when benchmarking them against existing databases. Moreover, a mathematical treatment was developed to treat simple network subsystems based only on their topology (independent of particular parameter values). Application to a problem of experimental interest demonstrated the need for extentions to the conventional model to fully explain the experimental data.  Finally, the notion of a subsystem was evaluated from a topological perspective. A number of different protein networks were examined to analyze their topological properties with respect to separability, seeking to find separable subsystems. These networks were shown to exhibit separability in a nonintuitive fashion, while the separable subsystems were of strong biological significance. It was demonstrated that the separability property found was not due to incomplete or biased data, but is likely to reflect biological structure.",124 p.; 14826182 bytes; 3860263 bytes,application/postscript; application/pdf,en_US,AITR-2003-001,AI,"Understanding Subsystems in Biology through Dimensionality Reduction, Graph Partitioning and Analytical Modeling",,,
"Chklovski, Timothy",2004-10-20T20:31:36Z,2004-10-20T20:31:36Z,2003-02-12,AITR-2003-002,http://hdl.handle.net/1721.1/7100,"The goal of the work reported here is to capture the  commonsense knowledge of non-expert human  contributors. Achieving this goal will enable more  intelligent human-computer interfaces and pave the  way for computers to reason about our world. In the  domain of natural language processing, it will provide  the world knowledge much needed for semantic  processing of natural language. To acquire knowledge  from contributors not trained in knowledge engineering,  I take the following four steps: (i) develop a knowledge  representation (KR) model for simple assertions in  natural language, (ii) introduce cumulative analogy, a  class of nearest-neighbor based analogical reasoning  algorithms over this representation, (iii) argue that  cumulative analogy is well suited for knowledge  acquisition (KA) based on a theoretical analysis of  effectiveness of KA with this approach, and (iv) test the  KR model and the effectiveness of the cumulative  analogy algorithms empirically. To investigate  effectiveness of cumulative analogy for KA empirically,  Learner, an open source system for KA by cumulative  analogy has been implemented, deployed, and  evaluated. (The site ""1001 Questions,"" is available at  http://teach-computers.org/learner.html). Learner  acquires assertion-level knowledge by constructing  shallow semantic analogies between a KA topic and its  nearest neighbors and posing these analogies as  natural language questions to human contributors.  Suppose, for example, that based on the knowledge  about ""newspapers"" already present in the knowledge  base, Learner judges ""newspaper"" to be similar to  ""book"" and ""magazine."" Further suppose that  assertions ""books contain information"" and ""magazines  contain information"" are also already in the knowledge  base. Then Learner will use cumulative analogy from  the similar topics to ask humans whether ""newspapers  contain information."" Because similarity between topics  is computed based on what is already known about  them, Learner exhibits bootstrapping behavior --- the  quality of its questions improves as it gathers more  knowledge. By summing evidence for and against  posing any given question, Learner also exhibits noise  tolerance, limiting the effect of incorrect similarities. The  KA power of shallow semantic analogy from nearest  neighbors is one of the main findings of this thesis. I  perform an analysis of commonsense knowledge  collected by another research effort that did not rely on  analogical reasoning and demonstrate that indeed  there is sufficient amount of correlation in the  knowledge base to motivate using cumulative analogy  from nearest neighbors as a KA method. Empirically,  evaluating the percentages of questions answered  affirmatively, negatively and judged to be nonsensical  in the cumulative analogy case compares favorably  with the baseline, no-similarity case that relies on  random objects rather than nearest neighbors. Of the  questions generated by cumulative analogy,  contributors answered 45% affirmatively, 28%  negatively and marked 13% as nonsensical; in the  control, no-similarity case 8% of questions were  answered affirmatively, 60% negatively and 26% were  marked as nonsensical.",173 p.; 4895337 bytes; 1809437 bytes,application/postscript; application/pdf,en_US,AITR-2003-002,AI; knowledge acquisition; knowledge capture; analogy; natural language; reasoning,Using Analogy to Acquire Commonsense Knowledge from Human Contributors,,,
"Peshkin, Leonid",2004-10-20T20:31:39Z,2004-10-20T20:31:39Z,2003-02-14,AITR-2003-003,http://hdl.handle.net/1721.1/7101,"One objective of artificial intelligence is to model the  behavior of an intelligent agent interacting with its environment. The  environment's transformations can be modeled as a Markov chain,  whose state is partially observable to the agent and affected by its actions;  such processes are known as partially observable Markov decision processes  (POMDPs). While the environment's dynamics are assumed to obey certain  rules, the agent does not know them and must learn.  In this dissertation we focus on the agent's adaptation  as captured by the reinforcement learning framework. This means learning  a policy---a mapping of observations into actions---based  on feedback from the environment. The learning can be viewed as browsing  a set of policies while evaluating them by trial through interaction with the  environment.  The set of policies is constrained by the architecture of  the agent's controller. POMDPs require a controller to have  a memory. We investigate controllers with memory, including  controllers with  external memory, finite state controllers and distributed  controllers for multi-agent systems. For these various  controllers we work out the details of the algorithms which learn by ascending  the gradient of expected cumulative reinforcement.   Building on statistical learning theory and experiment  design theory, a policy evaluation algorithm is developed for the case of  experience re-use. We address the question of sufficient experience for  uniform convergence of policy evaluation and obtain sample complexity bounds  for various estimators. Finally, we demonstrate the performance of the  proposed algorithms on several domains, the most complex of which is simulated  adaptive packet routing in a telecommunication network.",144 p.; 26942112 bytes; 1735254 bytes,application/postscript; application/pdf,en_US,AITR-2003-003,AI; POMDP; policy search; adaptive systems; reinforcement learning; adaptive behavior,Reinforcement Learning by Policy Search,,,
"Steck, Harald; Jaakkola, Tommi S.",2004-10-08T20:38:42Z,2004-10-08T20:38:42Z,2003-02-25,AIM-2003-002,http://hdl.handle.net/1721.1/6709,"In this paper, we present an approach to discretizing  multivariate continuous data while learning the  structure of a graphical model. We derive the joint  scoring function from the principle of predictive  accuracy, which inherently ensures the optimal trade-off between goodness of fit and model complexity  (including the number of discretization levels). Using  the so-called finest grid implied by the data, our scoring  function depends only on the number of data points in  the various discretization levels. Not only can it be  computed efficiently, but it is also independent of the  metric used in the continuous space. Our experiments  with gene expression data show that discretization  plays a crucial role regarding the resulting network  structure.",15 p.; 4299414 bytes; 910469 bytes,application/postscript; application/pdf,en_US,AIM-2003-002,AI; Discretization; Graphical models,(Semi-)Predictive Discretization During Model Selection,,,
"Geiger, Gadi; Ezzat, Tony; Poggio, Tomaso",2004-10-20T21:05:09Z,2004-10-20T21:05:09Z,2003-02-28,AIM-2003-003; CBCL-224,http://hdl.handle.net/1721.1/7275,"abstract  With many visual speech animation techniques now  available, there is a clear need for systematic  perceptual evaluation schemes. We describe here our  scheme and its application to a new video-realistic  (potentially indistinguishable from real recorded video)  visual-speech animation system, called Mary 101.  Two types of experiments were performed: a)  distinguishing visually between real and synthetic  image- sequences of the same utterances, (""Turing  tests"") and b) gauging visual speech recognition by  comparing lip-reading performance of the real and  synthetic image-sequences of the same utterances  (""Intelligibility tests"").  Subjects that were presented randomly with either real  or synthetic image-sequences could not tell the  synthetic from the real sequences above chance level.  The same subjects when asked to lip-read the  utterances from the same image-sequences  recognized speech from real image-sequences  significantly better than from synthetic ones. However,  performance for both, real and synthetic, were at levels  suggested in the literature on lip-reading. We conclude  from the two experiments that the animation of Mary  101 is adequate for providing a percept of a talking  head. However, additional effort is required to improve  the animation for lip-reading purposes like  rehabilitation and language learning.  In addition, these two tasks could be considered as  explicit and implicit perceptual discrimination tasks. In  the explicit task (a), each stimulus is classified directly  as a synthetic or real image-sequence by detecting a  possible difference between the synthetic and the real  image-sequences. The implicit perceptual  discrimination task (b) consists of a comparison  between visual recognition of speech of real and  synthetic image-sequences. Our results suggest that  implicit perceptual discrimination is a more sensitive  method for discrimination between synthetic and real  image-sequences than explicit perceptual  discrimination.",17 p.; 1515741 bytes; 1358361 bytes,application/postscript; application/pdf,en_US,AIM-2003-003; CBCL-224,AI; visual speech; speech animation; face animation; image morphing; lip reading,Perceptual Evaluation of Video-Realistic Speech,,,
