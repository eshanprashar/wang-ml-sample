dc.contributor.author,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.uri,dc.description.abstract,dc.relation.ispartofseries,dc.title,dc.identifier.other,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.contributor.advisor,dc.subject
"Itkis, Gene; Reyzin, Leonid",2023-03-29T14:42:08Z,2023-03-29T14:42:08Z,2001-04,https://hdl.handle.net/1721.1/149303,"Ordinary digital signatures have an inherent weakness: if the secret key is leaked, then all signatures, even the ones generated before the leak, are no longer trustworthy. Forward-secure digital signatures were recently proposed to address this weakness: they ensure that past signatures remain secure even if the current secret key is leaked. We propose the first forward-secure signature scheme for which both signing and verifying are as efficient as for one of the most efficient ordinary signature schemes (Guillou-Quisquater): each requiring just two modular exponentiations with a short exponent. All previously proposed forward-secure signature schemes took significantly longer to sign and verify than ordinary signature schemees. Our scheme requires only fractional increases to the sizes of keys and signatures, and no additional public storage. Like the underlying Guillou-Quisquater scheme, our scheme is provably secure in the random oracle model.",MIT-LCS-TM-614,Forward-Secure Signatures with Optimal Signing and Verifying,,,,,,
"Lepinski, Matthew; Micali, Silvio",2023-03-29T14:42:14Z,2023-03-29T14:42:14Z,2001-04,https://hdl.handle.net/1721.1/149305,We provide a proof of knowledge assumption that allows us to construct a three round zero-knowledge proof system for any language in NP.,MIT-LCS-TM-616,Three Round Zero-Knowledge Using a Proof of Knowledge Assumption,,,,,,
"Meuleau, Nicolas; Peshkin, Leonid; Kim, Kee-Eung",2004-10-04T14:37:39Z,2004-10-04T14:37:39Z,2001-04-03,http://hdl.handle.net/1721.1/6076,"Gradient-based policy search is an alternative to value-function-based methods for reinforcement learning in non-Markovian domains. One apparent drawback of policy search is its requirement that all actions be 'on-policy'; that is, that there be no explicit exploration. In this paper, we provide a method for using importance sampling to allow any well-behaved directed exploration policy during learning. We show both theoretically and experimentally that using this method can achieve dramatic performance improvements.",AIM-2001-003,Exploration in Gradient-Based Reinforcement Learning,AIM-2001-003,5594043 bytes; 516972 bytes,application/postscript; application/pdf,en_US,,
"Chan, Nicholas Tung; Shelton, Christian",2004-10-20T20:50:09Z,2004-10-20T20:50:09Z,2001-04-17,http://hdl.handle.net/1721.1/7220,"This paper presents an adaptive learning model for market-making under the reinforcement learning framework. Reinforcement learning is a learning technique in which agents aim to maximize the long-term accumulated rewards. No knowledge of the market environment, such as the order arrival or price process, is assumed. Instead, the agent learns from real-time market experience and develops explicit market-making strategies, achieving multiple objectives including the maximizing of profits and minimization of the bid-ask spread. The simulation results show initial success in bringing learning techniques to building market-making algorithms.",AIM-2001-005; CBCL-195,An Electronic Market-Maker,AIM-2001-005; CBCL-195,2620276 bytes; 480221 bytes,application/postscript; application/pdf,en_US,,
"Arkoudas, Konstantine",2004-10-04T14:37:40Z,2004-10-04T14:37:40Z,2001-04-30,http://hdl.handle.net/1721.1/6077,"This paper introduces the notion of certified computation. A certified computation does not only produce a result r, but also a correctness certificate, which is a formal proof that r is correct. This can greatly enhance the credibility of the result: if we trust the axioms and inference rules that are used in the certificate,then we can be assured that r is correct. In effect,we obtain a trust reduction: we no longer have to trust the entire computation; we only have to trust the certificate. Typically, the reasoning used in the certificate is much simpler and easier to trust than the entire computation. Certified computation has two main applications: as a software engineering discipline, it can be used to increase the reliability of our code; and as a framework for cooperative computation, it can be used whenever a code consumer executes an algorithm obtained from an untrusted agent and needs to be convinced that the generated results are correct. We propose DPLs (Denotational Proof Languages)as a uniform platform for certified computation. DPLs enforce a sharp separation between logic and control and over versatile mechanicms for constructing certificates. We use Athena as a concrete DPL to illustrate our ideas, and we present two examples of certified computation, giving full working code in both cases.",AIM-2001-007,Certified Computation,AIM-2001-007,1923011 bytes; 286231 bytes,application/postscript; application/pdf,en_US,,
"Rodrigues, Rodrigo",2023-03-29T15:35:48Z,2023-03-29T15:35:48Z,2001-05,https://hdl.handle.net/1721.1/149952,,MIT-LCS-TR-850,Combining Abstraction with Byzantine Fault-Tolerance,,,,,,
"Mui, Lik; Mohtashemi, Mojdeh; Ang, Cheewee; Szolovits, Peter; Halberstadt, Ari",2023-03-29T14:42:16Z,2023-03-29T14:42:16Z,2001-05,https://hdl.handle.net/1721.1/149306,"For distributed systems at large and e-commerce systems in particular, ratings play an increasingly important role. Rating confer reputation measures about sources. This paper reports our formalization of the rating process. This paper argues that rating shuold be context- and individual- dependent quantities. In contrast to existing rating systems in many e-commerce or developer sites, our approach makes use of personalized and contextualized ratings for assessing source reputation. Our approach is based on a Bayesian probabilistic framework.",MIT-LCS-TM-617,Ratings in Distributed Systems: A Bayesian Approach,,,,,,
"Katabi, Dina; Handley, Mark",2023-03-29T15:34:14Z,2023-03-29T15:34:14Z,2001-05,https://hdl.handle.net/1721.1/149923,,MIT-LCS-TR-820,Using precise feedback for controlling congestion in the Internet,,,,,,
"De Couto, Douglas S.J.; Morris, Robert T.",2023-03-29T15:34:27Z,2023-03-29T15:34:27Z,2001-05,https://hdl.handle.net/1721.1/149927,,MIT-LCS-TR-824,Location Proxies and Intermediate Node Forwarding for Practical Geographic Forwarding,,,,,,
"Ajmani, Sameer; Morris, Robert T.; Liskov, Barbara H.",2023-03-29T15:35:41Z,2023-03-29T15:35:41Z,2001-05,https://hdl.handle.net/1721.1/149949,,MIT-LCS-TR-847,A Trusted Third-Party Computation Service,,,,,,
"Koh, Waikit",2023-03-29T15:34:59Z,2023-03-29T15:34:59Z,2001-05,https://hdl.handle.net/1721.1/149933,"The Internet has brought a new meaning to the term communities. Geography is no longer a barrier to international communications. However, the paradigm of meeting new interesting people remains entrenched in traditional means; meeting new interesting people on the Internet still relies on chance and contacts. This thesis explores a new approach towards matching users in online communities in an effective fashion.  Instead of using the conventional feature vector scheme to profile users, each user is represented by a personalized concept hierarchy (or an ontology) that is learnt from the user's behavior in the system. Each concept hierarchy is then interpreted within the Information Theory framework as a probabilistic decision tree. The matching algorithm uses the Kullback-Leiber distance as a measure of deviation between two probabilistic decision trees. Thus, in an online community, where a personalized concept hierarchy represents each user, the Kullback-Leiber distance imposes a full- order rank on the level of similarity of all the users with respect to a particular user in question.  The validity and utility of the proposed scheme of matching users is then applied in a set of simulations, using the feature-vector-overlap measure as a baseline. The results of the simulations show that the Kullback Leiber distance, when used in conjunction with the concept hierarchy, is more robust to noise and is able to make a stronger and more distinctive classification of users into similar groups in comparison to the conventional keyword-overlap scheme. A graphical agent system that relies upon the ontology-based interest matching algorithm, called the Collaborative Sanctioning Network, is also described in this thesis.",MIT-LCS-TR-830,An Information-Theoretic Approach to Interest Making,,,,,"Szolovits, Peter",
"Tanudjaja, Francisco; Mui, Lik",2023-03-29T14:42:18Z,2023-03-29T14:42:18Z,2001-05,https://hdl.handle.net/1721.1/149307,"Recent advances in graph-based search techniques derived from Kleinberg's work [1] have been impressive. This paper further improves the graph-based search algorithm in two dimensions. Firstly, variants of Kleinberg's techniques do not take into account the semantics of the query string nor of the nodes being searched. As a result, polysemy of query words cannot be resolved. This paper presents an interactive query scheme utilizing the simple web ontology provided by the Open Directory Project to resolve meanings of a user query. Secondly, we extend a recently proposed personalized version of the Kleinberg algorithm [3]. Simulation results are presented to illustrate the sensitivity of our technique. We outline the implementation of our algorithm in the Persona personalized web search system.",MIT-LCS-TM-618,Persona: A Contextualized and Personalized Web Search,,,,,,
"Keidar, Idit; Rajsbaum, Sergio",2023-03-29T15:34:18Z,2023-03-29T15:34:18Z,2001-05,https://hdl.handle.net/1721.1/149924,,MIT-LCS-TR-821,On the Cost of Fault-Tolerant Consensus When There Are No Faults - A Tutorial,,,,,,
"Felzenszwalb, Pedro F.",2004-10-20T20:28:15Z,2004-10-20T20:28:15Z,2001-05-01,http://hdl.handle.net/1721.1/7073,"This thesis presents a statistical framework for object recognition. The framework is motivated by the pictorial structure models introduced by Fischler and Elschlager nearly 30 years ago. The basic idea is to model an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. The problem of detecting an object in an image and the problem of learning an object model using training examples are naturally formulated under a statistical approach. We present efficient algorithms to solve these problems in our framework. We demonstrate our techniques by training models to represent faces and human bodies. The models are then used to locate the corresponding objects in novel images.",AITR-2001-002,Object Recognition with Pictorial Structures,AITR-2001-002,15588217 bytes; 1282972 bytes,application/postscript; application/pdf,en_US,,
"Sezgin, Tevfik Metin",2004-10-20T20:28:30Z,2004-10-20T20:28:30Z,2001-05-01,http://hdl.handle.net/1721.1/7077,"Freehand sketching is both a natural and crucial part of design, yet is unsupported by current design automation software. We are working to combine the flexibility and ease of use of paper and pencil with the processing power of a computer to produce a design environment that feels as natural as paper, yet is considerably smarter. One of the most basic steps in accomplishing this is converting the original digitized pen strokes in the sketch into the intended geometric objects using feature point detection and approximation. We demonstrate how multiple sources of information can be combined for  feature detection in strokes and apply this technique using two approaches to  signal processing, one using simple average based thresholding and a second  using scale space.",AITR-2001-009,Feature Point Detection and Curve Approximation for Early Processing of Freehand Sketches,AITR-2001-009,82 p.; 10553461 bytes; 5067939 bytes,application/postscript; application/pdf,en_US,,AI; Feature Point Detection; Curve Approximation; Freehand Sketching
"Banks, Jessica",2004-10-20T20:28:07Z,2004-10-20T20:28:07Z,2001-05-01,http://hdl.handle.net/1721.1/7070,"The goal of this research is to develop the prototype of a tactile sensing platform for anthropomorphic manipulation research. We investigate this problem through the fabrication and simple control of a planar 2-DOF robotic finger inspired by anatomic consistency, self-containment, and adaptability. The robot is equipped with a tactile sensor array based on optical transducer technology whereby localized changes in light intensity within an illuminated foam substrate correspond to the distribution and magnitude of forces applied to the sensor surface plane.   The integration of tactile perception is a key component in realizing robotic systems which organically interact with the world. Such natural behavior is characterized by compliant performance that can initiate internal, and respond to external, force application in a dynamic environment. However, most of the current manipulators that support some form of haptic feedback either solely derive proprioceptive sensation or only limit tactile sensors to the mechanical fingertips. These constraints are due to the technological challenges involved in high resolution, multi-point tactile perception.  In this work, however, we take the opposite approach, emphasizing the role of full-finger tactile feedback in the refinement of manual capabilities. To this end, we propose and implement a control framework for sensorimotor coordination analogous to infant-level grasping and fixturing reflexes. This thesis details the mechanisms used to achieve these sensory, actuation, and control objectives, along with the design philosophies and biological influences behind them. The results of behavioral experiments with a simple tactilely-modulated control scheme are also described. The hope is to integrate the modular finger into an %engineered analog of the human hand with a complete haptic system.",AITR-2001-005,Design and Control of an Anthropomorphic Robotic Finger with Multi-point Tactile Sensation,AITR-2001-005,88 p.; 17699541 bytes; 1837341 bytes,application/postscript; application/pdf,en_US,,AI; tactile sensation; finger; robot; anthropomorphic; skin
"Ucko, Aaron Mark",2004-10-20T20:28:09Z,2004-10-20T20:28:09Z,2001-05-01,http://hdl.handle.net/1721.1/7071,"I have added support for predicate dispatching, a powerful generalization of other dispatching mechanisms, to the Common Lisp Object System (CLOS). To demonstrate its utility, I used predicate dispatching to enhance Weyl, a computer algebra system which doubles as a CLOS library. My result is Dispatching-Enhanced Weyl (DEW), a computer algebra system that I have demonstrated to be well suited for both users and programmers.",AITR-2001-006,Predicate Dispatching in the Common Lisp Object System,AITR-2001-006,74 p.; 2463955 bytes; 977046 bytes,application/postscript; application/pdf,en_US,,AI; predicate dispatching; Common Lisp; CLOS; Weyl
"Demirdjian, D.; Darrell, T.",2004-10-04T14:37:43Z,2004-10-04T14:37:43Z,2001-05-07,http://hdl.handle.net/1721.1/6079,"A new method for 3D rigid motion estimation from stereo is proposed in this paper. The appealing feature of this method is that it directly uses the disparity images obtained from stereo matching. We assume that the stereo rig has parallel cameras and show, in that case, the geometric and topological properties of the disparity images. Then we introduce a rigid transformation (called d-motion) that maps two disparity images of a rigidly moving object. We show how it is related to the Euclidean rigid motion and a motion estimation algorithm is derived. We show with experiments that our approach is simple and more accurate than standard approaches.",AIM-2001-009,Motion Estimation from Disparity Images,AIM-2001-009,1035214 bytes; 158055 bytes,application/postscript; application/pdf,en_US,,
"Rahimi, A.; Morency, L.-P.; Darrell, T.",2004-10-04T14:37:42Z,2004-10-04T14:37:42Z,2001-05-07,http://hdl.handle.net/1721.1/6078,"We develop a class of differential motion trackers that automatically stabilize when in finite domains. Most differ-ential trackers compute motion only relative to one previous frame, accumulating errors indefinitely. We estimate pose changes between a set of past frames, and develop a probabilistic framework for integrating those estimates. We use an approximation to the posterior distribution of pose changes as an uncertainty model for parametric motion in order to help arbitrate the use of multiple base frames. We demonstrate this framework on a simple 2D translational tracker and a 3D, 6-degree of freedom tracker.",AIM-2001-008,Reducing Drift in Parametric Motion Tracking,AIM-2001-008,8757672 bytes; 1663085 bytes,application/postscript; application/pdf,en_US,,
"Ho, Purdy",2004-10-20T20:48:40Z,2004-10-20T20:48:40Z,2001-05-31,http://hdl.handle.net/1721.1/7171,"In this report, a face recognition system that is capable of detecting and recognizing frontal and rotated faces was developed. Two face recognition methods focusing on the aspect of pose invariance are presented and evaluated - the whole face approach and the component-based approach. The main challenge of this project is to develop a system that is able to identify faces under different viewing angles in realtime. The development of such a system will enhance the capability and robustness of current face recognition technology.  The whole-face approach recognizes faces by classifying a single feature vector consisting of the gray values of the whole face image. The component-based approach  first locates the facial components and extracts them. These components are normalized and combined into a single feature vector for classification. The Support Vector Machine (SVM) is used as the classifier for both approaches. Extensive tests with respect to the robustness against pose changes are performed on a  database that includes faces rotated up to about 40 degrees in depth. The component-based approach clearly outperforms the whole-face approach on all tests. Although this approach isproven to be more reliable, it is still too slow for real-time applications. That is the reason why a real-time face recognition system using the whole-face approach is implemented to recognize people in color video sequences.",AIM-2001-010; CBCL-197,Rotation Invariant Real-time Face Detection and Recognition System,AIM-2001-010; CBCL-197,24 p.; 12501066 bytes; 896203 bytes,application/postscript; application/pdf,en_US,,AI; vision
