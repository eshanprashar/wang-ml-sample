dc.contributor.advisor,dc.contributor.author,dc.contributor.other,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.uri,dc.description,dc.description.abstract,dc.format.extent,dc.relation.ispartofseries,dc.subject,dc.title,dc.date.updated,dc.relation.isreferencedby,dc.relation.uri,dc.relation,dc.rights,dc.rights.uri,dc.contributor,dc.identifier.citation
Karen Sollins,"Beckler, Kendra K.",Advanced Network Architecture,2015-02-02T16:30:05Z,2015-02-02T16:30:05Z,2015-01-31,http://hdl.handle.net/1721.1/93253,MEng thesis,"The systemic structure of TCP/IP is outdated; a new scheme for data transportation is needed in order to make the internet more adaptive to modern demands of mobility, information-driven demand, ever-increasing quantity of users and data, and performance requirements. While an information centric networking system addresses these issues, one required component for publish subscribe or content-addressed internet networking systems to work properly is an improved caching system. This allows the publish subscribe internet networking to dynamically route packets to mobile users, as an improvement over pure hierarchical or pure distributed caching systems. To this end, I proposed, implemented, and analyzed the workings of a superdomain caching system. The superdomain caching system is a hybrid of hierarchical and dynamic caching systems designed to continue reaping the benefits of the caching system for mobile users (who may move between neighboring domains in the midst of a network transaction) while minimizing the latency inherent in any distributed caching system to improve upon the content-addressed system.",82 p.,MIT-CSAIL-TR-2015-002,Network caching; information centric networking,Improved Caching Strategies for Publish/Subscribe Internet Networking,2015-02-02T16:30:05Z,,,,,,,
Martin Rinard,"Qi, Zichao; Long, Fan; Achour, Sara; Rinard, Martin",Computer Architecture,2015-02-02T22:00:04Z,2015-02-02T22:00:04Z,2015-02-02,http://hdl.handle.net/1721.1/93255,,"We analyze reported patches for three prior generate-and-validate patch generation systems (GenProg, RSRepair, and AE). Because of experimental error, the majority of the reported patches violate the basic principle behind the design of these systems -- they do not produce correct outputs even for the inputs in the test suite used to validate the patches. We also show that the overwhelming majority of the accepted patches are not correct and are equivalent to a single modification that simply deletes functionality. We also present Kali, a generate-and-validate patch generation system that simply deletes functionality. Working with a simpler and more effectively focused search space, Kali produces more correct patches and at least as many patches that produce correct outputs for the inputs in the validation test suite as prior GenProg, RSRepair, and AE systems.",N/A,,,An Analysis of Patch Plausibility and Correctness for Generate-And-Validate Patch Generation Systems (Supplementary Material),2015-02-02T22:00:04Z,Main paper: http://hdl.handle.net/1721.1/94337,http://hdl.handle.net/1721.1/94337,,,,,
Martin Rinard,"Qi, Zichao; Long, Fan; Achour, Sara; Rinard, Martin",Computer Architecture,2015-02-11T19:45:04Z,2015-02-11T19:45:04Z,2015-02-10,http://hdl.handle.net/1721.1/94337,,"We analyze reported patches for three prior generate-and-validate patch generation systems (GenProg, RSRepair, and AE). Because of experimental error, the majority of the reported patches violate the basic principle behind the design of these systems -- they do not produce correct outputs even for the inputs in the test suite used to validate the patches. We also show that the overwhelming majority of the accepted patches are not correct and are equivalent to a single modification that simply deletes functionality. We also present Kali, a generate-and-validate patch generation system that simply deletes functionality. Working with a simpler and more effectively focused search space, Kali generates at least as many correct patches as prior GenProg, RSRepair, and AE systems. Kali also generates at least as many plausible patches that produce correct outputs for the inputs in the validation test suite as the three prior systems. We also discuss the patches produced by ClearView, a generate-and-validate binary hot patching system that leverages learned invariants to produce patches that enable systems to survive otherwise fatal defects and security attacks.",13 p.,MIT-CSAIL-TR-2015-003,Automatic Program Repair; Patch Analysis; Functionality Elimination,An Analysis of Patch Plausibility and Correctness for Generate-And-Validate Patch Generation Systems,2015-02-11T19:45:04Z,,http://hdl.handle.net/1721.1/93255,See supplementary material at http://hdl.handle.net/1721.1/93255,,,,
Martin Rinard,"Long, Fan; Qi, Zichao; Achour, Sara; Rinard, Martin",Computer Architecture,2015-02-12T21:00:03Z,2015-02-12T21:00:03Z,2015-02-12,http://hdl.handle.net/1721.1/94520,,"We present PCR, a new automatic patch generation system. PCR uses a new condition synthesis technique to efficiently discover logical expressions that generate desired control- flow transfer patterns. Presented with a set of test cases, PCR deploys condition synthesis to find and repair incorrect if conditions that cause the application to produce the wrong result for one or more of the test cases. PCR also leverages condition synthesis to obtain a set of compound modifications that generate a rich, productive, and tractable search space of candidate patches. We evaluate PCR on a set of 105 defects from the GenProg benchmark set. For 40 of these defects, PCR generates plausible patches (patches that generate correct outputs for all inputs in the test suite used to validate the patch). For 12 of these defects, PCR generates correct patches that are functionally equivalent to developer patches that appear in subsequent versions. For comparison purposes, GenProg generates plausible patches for only 18 defects and correct patches for only 2 defects. AE generates plausible patches for only 27 defects and correct patches for only 3 defects.",14 p.,MIT-CSAIL-TR-2015-004,,Automatic Program Repair with Condition Synthesis and Compound Mutations,2015-02-12T21:00:03Z,,,,,,,
Manolis Kellis,"Feizi, Soheil; Quon, Gerald; Medard, Muriel; Kellis, Manolis; Jadbabaie, Ali",Computational Biology (Kellis),2015-02-18T18:45:06Z,2015-02-18T18:45:06Z,2015-02-18,http://hdl.handle.net/1721.1/94606,,"Network alignment refers to the problem of finding a bijective mapping across vertices of two or more graphs to maximize the number of overlapping edges and/or to minimize the number of mismatched interactions across networks. This paper introduces a network alignment algorithm inspired by eigenvector analysis which creates a simple relaxation for the underlying quadratic assignment problem. Our method relaxes binary assignment constraints along the leading eigenvector of an alignment matrix which captures the structure of matched and mismatched interactions across networks. Our proposed algorithm denoted by EigeAlign has two steps. First, it computes the Perron-Frobenius eigenvector of the alignment matrix. Second, it uses this eigenvector in a linear optimization framework of maximum weight bipartite matching to infer bijective mappings across vertices of two graphs. Unlike existing network alignment methods, EigenAlign considers both matched and mismatched interactions in its optimization and therefore, it is effective in aligning networks even with low similarity. We show that, when certain technical conditions hold, the relaxation given by EigenAlign is asymptotically exact over Erdos-Renyi graphs with high probability. Moreover, for modular network structures, we show that EigenAlign can be used to split the large quadratic assignment optimization into small subproblems, enabling the use of computationally expensive, but tight semidefinite relaxations over each subproblem. Through simulations, we show the effectiveness of the EigenAlign algorithm in aligning various network structures including Erdos-Renyi, power law, and stochastic block models, under different noise models. Finally, we apply EigenAlign to compare gene regulatory networks across human, fly and worm species which we infer by integrating genome-wide functional and physical genomics datasets from ENCODE and modENCODE consortia. EigenAlign infers conserved regulatory interactions across these species despite large evolutionary distances spanned. We find strong conservation of centrally-connected genes and some biological pathways, especially for human-fly comparisons.",61 p.,MIT-CSAIL-TR-2015-005,Network alignment; Graph isomorphism; Gene regulatory networks,Spectral Alignment of Networks,2015-02-18T18:45:06Z,,,,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,,
Nancy Lynch,"Lynch, Nancy; Sastry, Srikanth",Theory of Computation,2015-03-03T21:00:09Z,2015-03-03T21:00:09Z,2015-03-02,http://hdl.handle.net/1721.1/95775,,"The FLP result shows that crash-tolerant consensus is impossible to solve in asynchronous systems, and several solutions have been proposed for crash-tolerant consensus under alternative (stronger) models. One popular approach is to augment the asynchronous system with appropriate failure detectors, which provide (potentially unreliable) information about process crashes in the system, to circumvent the FLP impossibility. In this paper, we demonstrate the exact mechanism by which (sufficiently powerful) asynchronous failure detectors enable solving crash-tolerant consensus. Our approach, which borrows arguments from the FLP impossibility proof and the famous result from CHT, which shows that Omega is a weakest failure detector to solve consensus, also yields a natural proof to Omega as a weakest asynchronous failure detector to solve consensus. The use of I/O automata theory in our approach enables us to model execution in a more detailed fashion than CHT and also addresses the latent assumptions and assertions in the original result in CHT.",66 p.,MIT-CSAIL-TR-2015-006,,Consensus using Asynchronous Failure Detectors,2015-03-03T21:00:09Z,,,,,,,
Howard Shrobe,"Khan, Muhammad Taimoor; Serpanos, Dimitrios; Shrobe, Howard",Cybersecurity,2015-03-03T21:00:05Z,2015-03-03T21:00:05Z,2015-03-03,http://hdl.handle.net/1721.1/95774,,"The purpose of this work is two fold: on one hand we want to formalize the behavior of critical components of the self generating and adapting cognitive middleware AWDRAT such that the formalism not only helps to understand the semantics and technical details of the middleware but also opens an opportunity to extend the middleware to support other complex application domains of cybersecurity; on the other hand, the formalism serves as a prerequisite for our proof of the behavioral correctness of the critical components to ensure the safety of the middleware itself. However, here we focus only on the core and critical component of the middleware, i.e. Execution Monitor which is a part of the module ""Architectural Differencer"" of AWDRAT. The role of the execution monitor is to identify inconsistencies between run-time observations of the target system and predictions of the System Architectural Model. Therefore, to achieve this goal, we first define the formal (denotational) semantics of the observations (run-time events) and predictions (executable specifications as of System Architectural Model); then based on the aforementioned formal semantics, we formalize the behavior of the ""Execution Monitor"" of the middleware.",60 p.,MIT-CSAIL-TR-2015-007,cyber-security; reference-monitor; wrappers; executable specification,On the Formal Semantics of the Cognitive Middleware AWDRAT,2015-03-03T21:00:05Z,,,,,,AIRE,
Martin Rinard,"Long, Fan; Rinard, Martin",Computer Architecture,2015-03-11T19:45:06Z,2015-03-11T19:45:06Z,2015-03-05,http://hdl.handle.net/1721.1/95963,,"We present SPR, a new program repair system that uses condition synthesis to instantiate transformation schemas to repair program defects. SPR's staged repair strategy combines a rich space of potential repairs with a targeted search algorithm that makes this space viably searchable in practice. This strategy enables SPR to successfully find correct program repairs within a space that contains many correct patches. The majority of these correct patches are not within the search spaces of previous automatic program repair systems.",1213290 bytes,,Program Repair; Transformation Schema; Condition Synthesis,Staged Program Repair in SPR (Supplementary Material),2015-03-11T19:45:06Z,,,,,,,
Martin Rinard,"Long, Fan; Rinard, Martin",Computer Architecture,2015-03-11T21:15:02Z,2015-03-11T21:15:02Z,2015-03-11,http://hdl.handle.net/1721.1/95970,,"We present SPR, a new program repair system that uses condition synthesis to instantiate transformation schemas to repair program defects. SPR s staged repair strategy combines a rich space of potential repairs with a targeted search algorithm that makes this space viably searchable in practice. This strategy enables SPR to successfully find correct program repairs within a space that contains many meaningful and useful patches. The majority of these correct repairs are not within the search spaces of previous automatic program repair systems.",15 p.,MIT-CSAIL-TR-2015-008,Program Repair; Transformation Schema; Condition Synthesis,Staged Program Repair in SPR,2015-03-11T21:15:02Z,,,,,,,
Boris Katz,"Borchardt, Gary C.",Infolab,2015-03-31T22:15:06Z,2015-03-31T22:15:06Z,2015-03-30,http://hdl.handle.net/1721.1/96300,,"This report presents a set of software techniques that support the tasks of event recognition, summarization of event sequences, explanation of recognized events, explanation of non-recognized events, prediction of event completions, and question answering by leveraging language-encoded human knowledge of what typically happens during various types of events. The techniques operate on sequences of timestamped, three-dimensional positions and contacts for humans, body parts, and objects, provided by a Microsoft Kinect sensor plus associated software. Appendices describe 64 activity sequences used for development and testing of the techniques and 102 event models created as part of the effort.",89 p.,MIT-CSAIL-TR-2015-009,,A Suite of Techniques for Describing Activity in Terms of Events,2015-03-31T22:15:06Z,,,,Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International,http://creativecommons.org/licenses/by-nc-nd/4.0/,,
Julie A Shah,"Kim, Been; Glassman, Elena; Johnson, Brittney; Shah, Julie",Interactive Robotics Group,2015-04-01T17:30:03Z,2015-04-01T17:30:03Z,2015-04-01,http://hdl.handle.net/1721.1/96315,,"Clustering methods optimize the partitioning of data points with respect to an internal metric, such as likelihood, in order to approximate the goodness of clustering. However, this internal metric does not necessarily translate into effective clustering from the user's perspective. This work presents the interactive Bayesian Case Model (iBCM), a model that opens a communication channel between the clustering model and the user. Users can provide direct input to iBCM in order to achieve effective clustering results, and iBCM optimizes the clustering by creating a balance between what the data indicate and what makes the most sense to the user. This model provides feedback for users and does not assume any prior knowledge of machine learning on their part. We provide quantitative evidence that users are able to obtain more satisfactory clustering results through iBCM than without an interactive model. We also demonstrate the use of this method in a real-world setting where computer language class teachers utilize iBCM to cluster students' coding assignments for grading.",10 p.,MIT-CSAIL-TR-2015-010,interactive machine learning; machine learning; user interaction,iBCM: Interactive Bayesian Case Model Empowering Humans via Intuitive Interaction,2015-04-01T17:30:03Z,,,,,,,
Daniel Sanchez,"Beckmann, Nathan; Sanchez, Daniel",Computation Structures,2015-04-10T18:45:07Z,2015-04-10T18:45:07Z,2015-04-09,http://hdl.handle.net/1721.1/96525,,"Modern processors use high-performance cache replacement policies that outperform traditional alternatives like least-recently used (LRU). Unfortunately, current cache models use stack distances to predict LRU or its variants, and cannot capture these high-performance policies. Accurate predictions of cache performance enable many optimizations in multicore systems. For example, cache partitioning uses these predictions to divide capacity among applications in order to maximize performance, guarantee quality of service, or achieve other system objectives. Without an accurate model for high-performance replacement policies, these optimizations are unavailable to modern processors. We present a new probabilistic cache model designed for high-performance replacement policies. This model uses absolute reuse distances instead of stack distances, which makes it applicable to arbitrary age-based replacement policies. We thoroughly validate our model on several high-performance policies on synthetic and real benchmarks, where its median error is less than 1%. Finally, we present two case studies showing how to use the model to improve shared and single-stream cache performance.",15 p.,MIT-CSAIL-TR-2015-011,,A Cache Model for Modern Processors,2015-04-10T18:45:07Z,,,,Creative Commons Attribution 4.0 International,http://creativecommons.org/licenses/by/4.0/,,
Martin Rinard,"Sidiroglou-Douskos, Stelios; Davis, Eli; Rinard, Martin",Program Analysis,2015-04-14T20:45:09Z,2015-04-14T20:45:09Z,2015-04-14,http://hdl.handle.net/1721.1/96585,,"We present a new horizontal code transfer technique, program fracture and recombination, for automatically replacing, deleting, and/or combining code from multiple applications. Benefits include automatic generation of new applications incorporating the best or most desirable functionality developed anywhere, the automatic elimination of security vulnerabilities, effective software rejuvenation, the automatic elimination of obsolete or undesirable functionality, and improved performance, simplicity, analyzability, and clarity.",12 p.,MIT-CSAIL-TR-2015-012,program fracture and recombination; horizontal code transfer,Horizontal Code Transfer via Program Fracture and Recombination,2015-04-14T20:45:10Z,,,,,,,
Martin Rinard,"Sidiroglou-Douskos, Stelios; Lahtinen, Eric; Long, Fan; Rinard, Martin",Program Analysis,2015-04-15T21:30:04Z,2015-04-15T21:30:04Z,2015-04-15,http://hdl.handle.net/1721.1/96625,,"We present Code Phage (CP), a system for automatically transferring correct code from donor applications into recipient applications that process the same inputs to successfully eliminate errors in the recipient. Experimental results using seven donor applications to eliminate ten errors in seven recipient applications highlight the ability of CP to transfer code across applications to eliminate out of bounds access, integer overflow, and divide by zero errors. Because CP works with binary donors with no need for source code or symbolic information, it supports a wide range of use cases. To the best of our knowledge, CP is the first system to automatically transfer code across multiple applications.",15 p.,MIT-CSAIL-TR-2015-013,,Automatic Error Elimination by Horizontal Code Transfer Across Multiple Applications,2015-04-15T21:30:04Z,,,,,,,
Nick Roy,"Richter, Charles; Vega-Brown, William; Roy, Nicholas","Robotics, Vision & Sensor Networks",2015-05-01T21:15:04Z,2015-05-01T21:15:04Z,2015-04-27,http://hdl.handle.net/1721.1/96879,,We document two environment-generating distributions used for sampling random 2D maps. The first generates random hallway environments based on a Markov chain and the second generates random forest environments based on the Poisson distribution.,2 p.,MIT-CSAIL-TR-2015-014,,Markov Chain Hallway and Poisson Forest Environment Generating Distributions,2015-05-01T21:15:04Z,,,,,,,
Martin Rinard,"Rubin, Julia; Gordon, Michael I.; Nguyen, Nguyen; Rinard, Martin",Program Analysis,2015-05-04T20:30:03Z,2015-05-04T20:30:03Z,2015-05-04,http://hdl.handle.net/1721.1/96909,,"This paper studies communication patterns in mobile applications. Our analysis shows that 65% of the HTTP, socket, and RPC communication in top-popular Android applications from Google Play have no effect on the user-observable application functionality. We present a static analysis that is able to detect non-essential communication with 84%-90% precision and 63%-64% recall, depending on whether advertisement content is interpreted as essential or not. We use our technique to analyze the 500 top-popular Android applications from Google Play and determine that more than 80% of the connection statements in these applications are non-essential.",11 p.,MIT-CSAIL-TR-2015-015,,Non-Essential Communication in Mobile Applications,2015-05-04T20:30:03Z,,,,,,,
Nancy Lynch,"Lynch, Nancy; Newport, Calvin",Theory of Computation,2015-05-18T20:00:06Z,2015-05-18T20:00:06Z,2015-05-18,http://hdl.handle.net/1721.1/97014,,"In this paper, we implement an efficient local broadcast service for the dual graph model, which describes communication in a radio network with both reliable and unreliable links. Our local broadcast service offers probabilistic latency guarantees for: (1) message delivery to all reliable neighbors (i.e., neighbors connected by reliable links), and (2) receiving some message when one or more reliable neighbors are broadcasting. This service significantly simplifies the design and analysis of algorithms for the otherwise challenging dual graph model. To this end, we also note that our solution can be interpreted as an implementation of the abstract MAC layer specification---therefore translating the growing corpus of algorithmic results studied on top of this layer to the dual graph model. At the core of our service is a seed agreement routine which enables nodes in the network to achieve ""good enough"" coordination to overcome the difficulties of unpredictable link behavior. Because this routine has potential application to other problems in this setting, we capture it with a formal specification---simplifying its reuse in other algorithms. Finally, we note that in a break from much work on distributed radio network algorithms, our problem definitions (including error bounds), implementation, and analysis do not depend on global network parameters such as the network size, a goal which required new analysis techniques. We argue that breaking the dependence of these algorithms on global parameters makes more sense and aligns better with the rise of ubiquitous computing, where devices will be increasingly working locally in an otherwise massive network. Our push for locality, in other words, is a contribution independent of the specific radio network model and problem studied here.",27 p.,MIT-CSAIL-TR-2015-016,,A (Truly) Local Broadcast Layer for Unreliable Radio Networks,2015-05-18T20:00:07Z,,,,,,,
Martin Rinard,"Qi, Zichao; Long, Fan; Achour, Sara; Rinard, Martin",Computer Architecture,2015-05-21T21:00:09Z,2015-05-21T21:00:09Z,2015-05-21,http://hdl.handle.net/1721.1/97051,,"We analyze reported patches for three prior generate-and-validate patch generation systems (GenProg, RSRepair, and AE). Because of errors in the patch evaluation infrastructure, the majority of the reported patches violate the basic principle behind the design of these systems   they do not produce correct outputs even for the inputs in the test suite used to validate the patches. We also show that the overwhelming majority of the accepted patches are not correct and are equivalent to a single modification that simply deletes functionality. We also present Kali, a generate-and-validate patch generation system that only deletes functionality. Working with a simpler and more effectively focused search space, Kali generates at least as many correct patches as prior GenProg, RSRepair, and AE systems. Kali also generates at least as many patches that produce correct outputs for the inputs in the validation test suite as the three prior systems. We also discuss the patches produced by ClearView, a generate-and-validate binary hot patching system that leverages learned invariants to produce patches that enable systems to survive otherwise fatal defects and security attacks. Our analysis indicates that ClearView successfully patches 9 of the 10 security vulnerabilities used to evaluate the system. At least 4 of these patches are correct.",13152246 bytes,,Automatic Repair; Patch Analysis; Function Elimination,An Analysis of Patch Plausibility and Correctness for Generate-And-Validate Patch Generation Systems (Supplementary Material),2015-05-21T21:00:09Z,,,,,,,
Martin Rinard,"Qi, Zichao; Long, Fan; Achour, Sara; Rinard, Martin",Program Analysis,2015-05-26T23:00:02Z,2015-05-26T23:00:02Z,2015-05-26,http://hdl.handle.net/1721.1/97089,,"We analyze reported patches for three existing generate-and-validate patch generation systems (GenProg, RSRepair, and AE). The basic principle behind generate-and-validate systems is to accept only plausible patches that produce correct outputs for all inputs in the test suite used to validate the patches. Because of errors in the patch evaluation infrastructure, the majority of the reported patches are not plausible --- they do not produce correct outputs even for the inputs in the validation test suite. The overwhelming majority of the reported patches are not correct and are equivalent to a single modification that simply deletes functionality. Observed negative effects include the introduction of security vulnerabilities and the elimination of desirable standard functionality. We also present Kali, a generate-and-validate patch generation system that only deletes functionality. Working with a simpler and more effectively focused search space, Kali generates at least as many correct patches as prior GenProg, RSRepair, and AE systems. Kali also generates at least as many patches that produce correct outputs for the inputs in the validation test suite as the three prior systems. We also discuss patches produced by ClearView, a generate-and-validate binary hot patching system that leverages learned invariants to produce patches that enable systems to survive otherwise fatal defects and security attacks. Our analysis indicates that ClearView successfully patches 9 of the 10 security vulnerabilities used to evaluate the system. At least 4 of these patches are correct.",24 p.,MIT-CSAIL-TR-2015-020,,An Analysis of Patch Plausibility and Correctness for Generate-And-Validate Patch Generation Systems,2015-05-26T23:00:02Z,,,,,,,
Martin Rinard,"Sidiroglou-Douskos, Stelios; Lahtinen, Eric; Rinard, Martin",Program Analysis,2015-05-26T21:30:02Z,2015-05-26T21:30:02Z,2015-05-26,http://hdl.handle.net/1721.1/97087,,"We present Targeted Automatic Patching (TAP), an automatic buffer and integer overflow discovery and patching system. Starting with an application and a seed input that the application processes correctly, TAP dynamically analyzes the execution of the application to locate target memory allocation sites and statements that access dynamically or statically allocated blocks of memory. It then uses targeted error-discovery techniques to automatically generate inputs that trigger integer and/or buffer overflows at the target sites. When it discovers a buffer or integer overflow error, TAP automatically matches and applies patch templates to generate patches that eliminate the error. Our experimental results show that TAP successfully discovers and patches two buffer and six integer overflow errors in six real-world applications.",10 p.,MIT-CSAIL-TR-2015-018,,Automatic Discovery and Patching of Buffer and Integer Overflow Errors,2015-05-26T21:30:03Z,,,,,,,
