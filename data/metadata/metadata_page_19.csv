dc.contributor.author,dc.date.accessioned,dc.date.available,dc.date.issued,dc.identifier.other,dc.identifier.uri,dc.description.abstract,dc.format.extent,dc.format.mimetype,dc.language.iso,dc.relation.ispartofseries,dc.subject,dc.title,dc.contributor.other,dc.contributor.advisor,dc.identifier.citation
"Serre, Thomas; Riesenhuber, Maximilian",2005-12-22T01:36:22Z,2005-12-22T01:36:22Z,2004-07-27,MIT-CSAIL-TR-2004-052; AIM-2004-017; CBCL-239,http://hdl.handle.net/1721.1/30491,"Riesenhuber \& Poggio recently proposed a model of object recognitionin cortex which, beyond integrating general beliefs about the visualsystem in a quantitative framework, made testable predictions aboutvisual processing. In particular, they showed that invariant objectrepresentation could be obtained with a selective pooling mechanismover properly chosen afferents through a {\sc max} operation: Forinstance, at the complex cells level, pooling over a group of simplecells at the same preferred orientation and position in space but atslightly different spatial frequency would provide scale tolerance,while pooling over a group of simple cells at the same preferredorientation and spatial frequency but at slightly different positionin space would provide position tolerance. Indirect support for suchmechanisms in the visual system come from the ability of thearchitecture at the top level to replicate shape tuning as well asshift and size invariance properties of ``view-tuned cells'' (VTUs)found in inferotemporal cortex (IT), the highest area in the ventralvisual stream, thought to be crucial in mediating object recognitionin cortex. There is also now good physiological evidence that a {\scmax} operation is performed at various levels along the ventralstream. However, in the original paper by Riesenhuber \& Poggio,tuning and pooling parameters of model units in early and intermediateareas were only qualitatively inspired by physiological data. Inparticular, many studies have investigated the tuning properties ofsimple and complex cells in primary visual cortex, V1. We show thatunits in the early levels of HMAX can be tuned to produce realisticsimple and complex cell-like tuning, and that the earlier findings onthe invariance properties of model VTUs still hold in this morerealistic version of the model.",11 p.; 24089158 bytes; 2715073 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; object recognition; simple cell; complex cell; hmax; V1; IT; view-tuned unit; in,"Realistic Modeling of Simple and Complex Cell Tuning in the HMAXModel, and Implications for Invariant Object Recognition in Cortex",,,
"Sezgin, Tevfik Metin; Davis, Randall",2005-12-22T01:36:30Z,2005-12-22T01:36:30Z,2004-07-28,MIT-CSAIL-TR-2004-053; AIM-2004-016,http://hdl.handle.net/1721.1/30492,"Freehand sketching is a natural and crucial part of everyday humaninteraction, yet is almost totally unsupported by current user interfaces. With the increasing availability of tablet notebooks and pen based PDAs, sketchbased interaction has gained attention as a natural interaction modality.We are working to combine the flexibility and ease of use of paper and pencilwith the processing power of a computer, to produce a user interface fordesign that feels as natural as paper, yet is considerably smarter. One of themost basic tasks in accomplishing this is converting the original digitizedpen strokes in a sketch into the intended geometric objects. In this paper wedescribe an implemented system that combines multiple sources of knowledge toprovide robust early processing for freehand sketching. We also show how thisearly processing system can be used as part of a fast sketch recognition system with polynomial time segmentation and recognition algorithms.",16 p.; 29102772 bytes; 1401214 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; Sketch Recognition; Early Sketch Processing; Shape Approximation,Early Sketch Processing with Application in HMM Based Sketch Recognition,,,
"Leong, Ben; Liskov, Barbara; Demaine, Erik D.",2005-12-22T01:36:42Z,2005-12-22T01:36:42Z,2004-08-13,MIT-CSAIL-TR-2004-054; MIT-LCS-TR-963,http://hdl.handle.net/1721.1/30493,"EpiChord is a DHT lookup algorithm that demonstrates that we canremove the O(log n)-state-per-node restriction on existing DHTtopologies to achieve significantly better lookup performance andresilience using a novel reactive routing state maintenance strategythat amortizes network maintenance costs into existing lookups and byissuing parallel queries. Our technique allows us to design a newclass of unlimited-state-per-node DHTs that is able to adapt naturallyto a wide range of lookup workloads. EpiChord is able to achieveO(1)-hop lookup performance under lookup-intensive workloads, and atleast O(log n)-hop lookup performance under churn-intensiveworkloads even in the worst case (though it is expected to performbetter on average).Our reactive routing state maintenance strategy allows us to maintainlarge amounts of routing state with only a modest amount of bandwidth,while parallel queries serve to reduce lookup latency and allow us toavoid costly lookup timeouts.  In general, EpiChord exploits theinformation gleaned from observing lookup traffic to improve lookupperformance, and only sends network probes when necessary. Nodespopulate their caches mainly from observing network traffic, andcache entries are flushed from the cache after a fixed lifetime.Our simulations show that with our approach can reduce both lookuplatencies and pathlengths by a factor of 3 by issuing only 3 queriesasynchronously in parallel per lookup.  Furthermore, we show that weare able to achieve this result with minimal additional communicationoverhead and the number of messages generated per lookup is no morethan that for the corresponding sequential Chord lookup algorithm overa range of lookup workloads.  We also present a novel token-passingstabilization scheme that automatically detects and repairs globalrouting inconsistencies.",18 p.; 27633175 bytes; 1206942 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,EpiChord: Parallelizing the Chord Lookup Algorithm with Reactive Routing State Management,Programming Methodology,,
"Rodrigues, Rodrigo; Liskov, Barbara",2005-12-22T01:40:26Z,2005-12-22T01:40:26Z,2004-08-13,MIT-CSAIL-TR-2004-055; MIT-LCS-TR-962,http://hdl.handle.net/1721.1/30494,"This paper proposes counter-measures that can be deployedas part of a replicated system to reduce the size ofW, and thus reduce the class of attacks to which the system is vulnerable. Obviously it will not be possible to withstandall attacks via this technique, in particular attacks with verysmall A. But we will propose techniques that can reduceWto quite a small value.In the remainder of this paper, we discuss how to lowerthe value of W. We begin by discussing attacks. Then wediscuss some prior work in this area and why it is insufficient.The final section describes the approach we propose.",3 p.; 6194127 bytes; 262522 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Byzantine Fault Tolerance in Long-Lived Systems,Programming Methodology,,
"Beal, Jacob",2006-06-01T16:22:22Z,2006-06-01T16:22:22Z,2004-09,MIT-CSAIL-TR-2006-039,http://hdl.handle.net/1721.1/32985,"Amorphous computing considers the problem of controllingmillions of spatially distributed unreliable devices which communicateonly with nearby neighbors. To program such a system, we need a highleveldescription language for desired global behaviors, and a system tocompile such descriptions into locally executing code which robustly createsand maintains the desired global behavior. I survey existing amorphouscomputing primitives and give desiderata for a language describingcomputation on an amorphous computer. I then bring these together inAmorphous Medium Language, which computes on an amorphous computeras though it were a space-filling computational medium.",16 p.; 4880361 bytes; 386051 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,distributed computing sensor networks,Programming an Amorphous Computational Medium,Mathematics and Computation,Gerald Sussman,"J.-P. Banatre et al. (Eds.): UPP 2004, LNCS 3566, pp. 121Â–136, 2005.Springer-Verlag Berlin Heidelberg 2005"
"Kreiman, Gabriel; Hung, Chou; Poggio, Tomaso; DiCarlo, James",2005-12-19T23:29:04Z,2005-12-19T23:29:04Z,2004-09-21,MIT-CSAIL-TR-2004-056; AIM-2004-020; CBCL-240,http://hdl.handle.net/1721.1/30417,"While single neurons in inferior temporal (IT) cortex show differential responses to distinct complex stimuli, little is known about the responses of populations of neurons in IT.  We recorded single electrode data, including multi-unit activity (MUA) and local field potentials (LFP), from 618 sites in the inferior temporal cortex of macaque monkeys while the animals passively viewed 78 different pictures of complex stimuli. The LFPs were obtained by low-pass filtering the extracellular electrophysiological signal with a corner frequency of 300 Hz. As reported previously, we observed that spike counts from MUA showed selectivity for some of the pictures.  Strikingly, the LFP data, which is thought to constitute an average over large numbers of neurons, also showed significantly selective responses.  The LFP responses were less selective than the MUA responses both in terms of the proportion of selective sites as well as in the selectivity of each site. We observed that there was only little overlap between the selectivity of MUA and LFP recordings from the same electrode.  To assess the spatial organization of selective responses, we compared the selectivity of nearby sites recorded along the same penetration and sites recorded from different penetrations.  We observed that MUA selectivity was correlated on spatial scales up to 800 &#61549;m while the LFP selectivity was correlated over a larger spatial extent, with significant correlations between sites separated by several mm.  Our data support the idea that there is some topographical arrangement to the organization of selectivity in inferior temporal cortex and that this organization may be relevant for the representation of object identity in IT.",1 p.; 154663209 bytes; 29794050 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; object recognition; inferior temporal cortex; local field potentials,Selectivity of Local Field Potentials in Macaque Inferior Temporal Cortex,,,
"Arsenio, Artur Miguel",2005-12-22T14:51:02Z,2005-12-22T14:51:02Z,2004-09-26,MIT-CSAIL-TR-2004-057; AITR-2004-006,http://hdl.handle.net/1721.1/30591,"The goal of this work is to build a cognitive system for the humanoid robot, Cog, that exploits human caregivers as catalysts to perceive and learn about actions, objects, scenes, people, and the robot itself. This thesis addresses a broad spectrum of machine learning problems across several categorization levels. Actions by embodied agents are used to automatically generate training data for the learning mechanisms, so that the robot develops categorization autonomously. Taking inspiration from the human brain, a framework of algorithms and methodologies was implemented to emulate different cognitive capabilities on the humanoid robot Cog. This framework is effectively applied to a collection of AI, computer vision, and signal processing problems. Cognitive capabilities of the humanoid robot are developmentally created, starting from infant-like abilities for detecting, segmenting, and recognizing percepts over multiple sensing modalities. Human caregivers provide a helping hand for communicating such information to the robot. This is done by actions that create meaningful events (by changing the world in which the robot is situated) thus inducing the ""compliant perception"" of objects from these human-robot interactions. Self-exploration of the world extends the robot's knowledge concerning object properties.This thesis argues for enculturating humanoid robots using infant development as a metaphor for building a humanoid robot's cognitive abilities. A human caregiver redesigns a humanoid's brain by teaching the humanoid robot as she would teach a child, using children's learning aids such as books, drawing boards, or other cognitive artifacts. Multi-modal object properties are learned using these tools and inserted into several recognition schemes, which are then applied to developmentally acquire new object representations. The humanoid robot therefore sees the world through the caregiver's eyes.Building an artificial humanoid robot's brain, even at an infant's cognitive level, has been a long quest which still lies only in the realm of our imagination. Our efforts towards such a dimly imaginable task are developed according to two alternate and complementary views: cognitive and developmental.",388 p.; 610948893 bytes; 19073417 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; Humanoid Robots; Developmental Learning; Perception; Human-robot Interactions,Cognitive-Developmental Learning for a Humanoid Robot: A Caregiver's Gift,,,
"Benjamin, Michael R.",2005-12-19T23:28:02Z,2005-12-19T23:28:02Z,2004-09-27,MIT-CSAIL-TR-2004-058; AIM-2004-021,http://hdl.handle.net/1721.1/30416,"The interval programming model (IvP) is a mathematical programmingmodel for representing and solving multi-objective optimizationproblems.  The central characteristic of the model is the use ofpiecewise linearly defined objective functions and a solution methodthat searches through the combination space of pieces rather thanthrough the actual decision space. The piecewise functions typicallyrepresent an approximation of some underlying function, but thisconcession is balanced on the positive side by relative freedom fromfunction form assumptions as well as the assurance of global optimality.In this paper the model and solution algorithms are described, and theapplicability of IvP to certain applications arediscussed.",32 p.; 42228177 bytes; 2845444 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; multi-objective decision making; behavior-based control; action selection; MCDM,The Interval Programming Model for Multi-objective Decision Making,,,
"Yeo, Gene; Van Nostrand, Eric; Holste, Dirk; Poggio, Tomaso; Burge, Christopher",2005-12-19T23:22:45Z,2005-12-19T23:22:45Z,2004-09-30,MIT-CSAIL-TR-2004-059; AIM-2004-022,http://hdl.handle.net/1721.1/30411,"Alternative pre-messenger RNA splicing affects a majority of human genes and plays important roles in development and disease.  Alternative splicing (AS) events conserved since the divergence of human and mouse are likely of primary biological importance, but relatively few such events are known.  Here we describe sequence features that distinguish exons subject to evolutionarily conserved AS, which we call 'alternative-conserved exons' (ACEs) from other orthologous human/mouse exons, and integrate these features into an exon classification algorithm, ACEScan.  Genome-wide analysis of annotated orthologous human-mouse exon pairs identified ~2,000 predicted ACEs.  Alternative splicing was verified in both human and mouse tissues using an RT-PCR-sequencing protocol for 21 of 30 (70%) predicted ACEs tested, supporting the validity of a majority of ACEScan predictions.  By contrast, AS was observed in mouse tissues for only 2 of 15 (13%) tested exons which had EST or cDNA evidence of AS in human but were not predicted ACEs, and was never observed for eleven negative control exons in human or mouse tissues.  Predicted ACEs were much more likely to preserve reading frame, and less likely to disrupt protein domains than other AS events, and were enriched in genes expressed in the brain and in genes involved in transcriptional regulation, RNA processing and development.  Our results also imply that the vast majority of AS events represented in the human EST databases are not conserved in mouse, and therefore may represent aberrant, disease- or allele-specific, or highly lineage-restricted splicing events.",56 p.; 49600059 bytes; 2638503 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; alternative splicing; comparative genomics; classification; regularization,Predictive identification of alternative events conserved in human and mouse,,,
"Tucker-Kellogg, Lisa",2005-12-19T23:32:53Z,2005-12-19T23:32:53Z,2004-10-01,MIT-CSAIL-TR-2004-060; AITR-2004-007,http://hdl.handle.net/1721.1/30419,"Throughout biological, chemical, and pharmaceutical research,conformational searches are used to explore the possiblethree-dimensional configurations of molecules.  This thesis describesa new systematic method for conformational search, including anapplication of the method to determining the structure of a peptidevia solid-state NMR spectroscopy.  A separate portion of the thesis isabout protein-DNA binding, with a three-dimensional macromolecularstructure determined by x-ray crystallography.The search method in this thesis enumerates all conformations of amolecule (at a given level of torsion angle resolution) that satisfy aset of local geometric constraints, such as constraints derived fromNMR experiments.  Systematic searches, historically used for smallmolecules, generally now use some form of divide-and-conquer forapplication to larger molecules.  Our method can achieve a significantimprovement in runtime by making some major and counter-intuitivemodifications to traditional divide-and-conquer:(1) OmniMerge divides a polymer into many alternative pairs ofsubchains and searches all the pairs, instead of simply cutting inhalf and searching two subchains.  Although the extra searches mayappear wasteful, the bottleneck stage of the overall search, which isto re-connect the conformations of the largest subchains, can be greatlyaccelerated by the availability of alternative pairs of sidechains.(2)  Propagation of disqualified conformations acrossoverlapping subchains can disqualify infeasible conformations veryrapidly, which further offsets the cost of searching the extrasubchains of OmniMerge.(3) The search may be run in two stages, once at low-resolutionusing a side-effect of OmniMerge to determine an optimalpartitioning of the molecule into efficient subchains; then again athigh-resolution while making use of the precomputed subchains.(4) An A* function prioritizes each subchain based onestimated future search costs.  Subchains with sufficiently lowpriority can be omitted from the search, which improves efficiency.A common theme of these four ideas is to make good choices about howto break the large search problem into lower-dimensional subproblems.In addition, the search method uses heuristic local searches withinthe overall systematic framework, to maintain the systematic guaranteewhile providing the empirical efficiency of stochastic search.These novel algorithms were implemented and the effectiveness of eachinnovation is demonstrated on a highly constrained peptide with 40degrees of freedom.",177 p.; 127791565 bytes; 5501537 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI; Distance Geometry; Nuclear Magnetic Resonance (NMR); Molecular Modeling,Systematic Conformational Search with Constraint Satisfaction,,,
"Lam, Patrick; Kuncak, Viktor; Rinard, Martin",2005-12-19T23:39:47Z,2005-12-19T23:39:47Z,2004-10-04,MIT-CSAIL-TR-2004-061; MIT-LCS-TR-965,http://hdl.handle.net/1721.1/30421,"We present a technique that enables the focused applicationof multiple analyses to di erent modules in thesame program. In our approach, each module encapsulatesone or more data structures and uses membershipin abstract sets to characterize how objects participatein data structures. Each analysis veri es that the implementationof the module 1) preserves important internaldata structure consistency properties and 2) correctlyimplements an interface that uses formulas in a set algebrato characterize the e ects of operations on theencapsulated data structures. Collectively, the analysesuse the set algebra to 1) characterize how objects participatein multiple data structures and to 2) enable theinter-analysis communication required to verify propertiesthat depend on multiple modules analyzed by differentanalyses.We have implemented our system and deployed threepluggable analyses into it: a ag analysis for modulesin which abstract set membership is determined by aag  eld in each object, a plugin for modules that encapsulatelinked data structures such as lists and trees,and an array plugin in which abstract set membershipis determined by membership in an array. Our experimentalresults indicate that our approach makes it possibleto e ectively combine multiple analyses to verifyproperties that involve objects shared by multiple modules,with each analysis analyzing only those modulesfor which it is appropriate.",21 p.; 36771229 bytes; 1343453 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,On Our Experience with Modular Pluggable Analyses,Computer Architecture,,
"Georgiou, Chryssis; Mavrommatis, Panayiotis P.; Tauber, Joshua A.",2005-12-19T23:25:19Z,2005-12-19T23:25:19Z,2004-10-06,MIT-CSAIL-TR-2004-062; MIT-LCS-TR-966,http://hdl.handle.net/1721.1/30412,"This document is a report about the capabilities and performance of the IOA Toolkit, and in particularthe tools that provide support for implementing and running distributed systems (checker,composer, code generator). The Toolkit compiles distributed systems specified in IOA into Javaclasses, which run on a network of workstations and communicate using the Message Passing Interface(MPI). In order to test the toolkit, several distributed algorithms were implemented, rangingfrom simple algorithms such as LCR leader election in a ring network to more complex algorithmssuch as the GHS algorithm for computing the minimum spanning tree in an arbitrary graph. Allof our experiments completed successfully, and several runtime measurements were made.",107 p.; 63601552 bytes; 2713486 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Implementing Asynchronous Distributed Systems Using the IOA Toolkit,Theory of Computation,,
"Pacheo, Carlos; Ernst, Michael D.",2005-12-19T23:26:54Z,2005-12-19T23:26:54Z,2004-10-14,MIT-CSAIL-TR-2004-063; MIT-LCS-TR-968,http://hdl.handle.net/1721.1/30414,"This paper describes a technique that helps a test engineerselect, from a large set of randomly generated testinputs, a small subset likely to reveal faults in the softwareunder test. The technique takes a program or software component,plus a set of normal executionsÂ—say, from an existingtest suite, or from observations of the software runningproperly. The technique works by extracting an operationalmodel of the softwareÂ’s operation, and comparingeach inputÂ’s operational pattern of execution against themodel. Test inputs whose operational pattern is suggestiveof a fault are further reduced by selecting only one inputper such pattern. The result is a small portion of the originalinputs, deemed most likely to reveal faults. Thus, ourtechnique can also be seen as an error-detection technique.We have implemented these ideas in the Eclat tool, designedfor unit testing of Java classes. Eclat generates alarge number of inputs and uses our technique to select onlya few of them as fault-revealing. The inputs that it selectsare an order of magnitude more likely to reveal faults thannon-selected inputs.",10 p.; 16601827 bytes; 677668 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Eclat: Automatic Generation and Classification of Test Inputs,Program Analysis,,
"Yang, Xiaowei",2005-12-22T01:41:13Z,2005-12-22T01:41:13Z,2004-10-14,MIT-CSAIL-TR-2004-064; MIT-LCS-TR-967,http://hdl.handle.net/1721.1/30495,"The present Internet routing system faces two challengingproblems. First, unlike in the telephone system, Internet users cannotchoose their wide-area Internet service providers (ISPs) separatelyfrom their local access providers.  With the introduction of newtechnologies such as broadband residential service andfiber-to-the-home, the local ISP market is often a monopoly or aduopoly. The lack of user choice is likely to reduce competition amongwide-area ISPs, limiting the incentives for wide-area ISPs to improvequality of service, reduce price, and offer new services. Second, thepresent routing system fails to scale effectively in the presence ofreal-world requirements such as multi-homing for robust and redundantInternet access. A multi-homed site increases the amount of routingstate maintained globally by the Internet routing system. As thedemand for multi-homing continues to rise, the amount of routing statecontinues to grow.This dissertation presents the design of a new Internet routingarchitecture (NIRA) that simultaneously addresses these twoproblems. NIRA gives a user the ability to choose the sequence ofInternet service providers his packets traverse. It also has betterscaling characteristics than today's routing system. The design ofNIRA is decomposed into four modular components: route discovery,route availability discovery, route representation and packetforwarding, and provider compensation. This dissertation describesmechanisms to realize each of these components. It also makes clearthose places in the design where a globally agreed mechanism isneeded, and those places where alternative mechanisms can be designedand deployed locally. In particular, this dissertation describes ascalable route discovery mechanism. With this mechanism, a user onlyneeds to know a small region of the Internet in order to select aroute to reach a destination. In addition, a novel routerepresentation and packet forwarding scheme is designed such that asource and a destination address can uniquely represent a sequence ofproviders a packet traverses.Network measurement, simulation, and analytic modeling are used incombination to evaluate the design of NIRA. The evaluation suggeststhat NIRA is scalable.",183 p.; 173514347 bytes; 5643389 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,NIRA: A New Internet Routing Architecture,Advanced Network Architecture,,
"Steinkraus, Kurt; Kaelbling, Leslie Pack",2005-12-22T01:41:41Z,2005-12-22T01:41:41Z,2004-10-21,MIT-CSAIL-TR-2004-065; AIM-2004-023,http://hdl.handle.net/1721.1/30496,"One of the reasons that it is difficult to plan and act in real-worlddomains is that they are very large.  Existing research generallydeals with the large domain size using a static representation andexploiting a single type of domain structure.  In this paper, wecreate a framework that encapsulates existing and new abstraction andapproximation methods into modules, and combines arbitrary modulesinto a system that allows for dynamic representation changes.  We showthat the dynamic changes of representation allow our framework tosolve larger and more interesting domains than were previouslypossible, and while there are no optimality guarantees, suitablemodule choices gain tractability at little cost to optimality.",12 p.; 9975204 bytes; 424481 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI,Combining dynamic abstractions in large MDPs,,,
"Kandula, Srikanth; Katabi, Dina; Jacob, Matthias; Berger, Arthur",2005-12-22T02:14:46Z,2005-12-22T02:14:46Z,2004-10-22,MIT-CSAIL-TR-2004-066; MIT-LCS-TR-969,http://hdl.handle.net/1721.1/30497,"Recent denial of service attacks are mounted by professionalsusing Botnets of tens of thousands of compromisedmachines. To circumvent detection, attackers areincreasingly moving away from pure bandwidth  oods toattacks that mimic the Web browsing behavior of a largenumber of clients, and target expensive higher-layer resourcessuch as CPU, database and disk bandwidth. Theresulting attacks are hard to defend against using standardtechniques as the malicious requests differ from thelegitimate ones in intent but not in content.We present the design and implementation of Kill-Bots, a kernel extension to protect Web servers againstDDoS attacks that masquerade as  ash crowds. Kill-Botsprovides authentication using graphical tests but is differentfrom other systems that use graphical tests. First,instead of authenticating clients based on whether theysolve the graphical test, Kill-Bots uses the test to quicklyidentify the IP addresses of the attack machines. Thisallows it to block the malicious requests while allowingaccess to legitimate users who are unable or unwillingto solve graphical tests. Second, Kill-Bots sends a testand checks the client's answer without allowing unauthenticatedclients access to sockets, TCBs, worker processes,etc. This protects the authentication mechanismfrom being DDoSed. Third, Kill-Bots combines authenticationwith admission control. As a result, it improvesperformance, regardless of whether the server overloadis caused by DDoS or a true Flash Crowd. We have implementedKill-Bots in the Linux kernel and evaluated itin the wide-area Internet using PlanetLab.",15 p.; 27361453 bytes; 1271267 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Botz-4-Sale: Surviving Organized DDoS Attacks that Mimic Flash Crowds,Networks and Mobile Systems,,
"Kuncak, Viktor; Rinard, Martin",2005-12-22T02:14:54Z,2005-12-22T02:14:54Z,2004-10-25,MIT-CSAIL-TR-2004-067; MIT-LCS-TR-970,http://hdl.handle.net/1721.1/30498,"Spatial conjunction is a powerful construct for reasoning about dynamically allocateddata structures, as well as concurrent, distributed and mobile computation. Whileresearchers have identified many uses of spatial conjunction, its precise expressive powercompared to traditional logical constructs was not previously known.In this paper we establish the expressive power of spatial conjunction. We construct anembedding from first-order logic with spatial conjunction into second-order logic, and moresurprisingly, an embedding from full second order logic into first-order logic with spatialconjunction. These embeddings show that the satisfiability of formulas in first-order logicwith spatial conjunction is equivalent to the satisfiability of formulas in second-order logic.These results explain the great expressive power of spatial conjunction and can be usedto show that adding unrestricted spatial conjunction to a decidable logic leads to an undecidablelogic. As one example, we show that adding unrestricted spatial conjunction totwo-variable logic leads to undecidability.On the side of decidability, the embedding into second-order logic immediately implies thedecidability of first-order logic with a form of spatial conjunction over trees. The embeddinginto spatial conjunction also has useful consequences: because a restricted form of spatialconjunction in two-variable logic preserves decidability, we obtain that a correspondinglyrestricted form of second-order quantification in two-variable logic is decidable. The resultinglanguage generalizes the first-order theory of boolean algebra over sets and is useful inreasoning about the contents of data structures in object-oriented languages.",16 p.; 15950544 bytes; 692945 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,On Spatial Conjunction as Second-Order Logic,Computer Architecture,,
"Monteleoni, Claire; Balakrishnan, Hari; Feamster, Nick; Jaakkola, Tommi",2005-12-22T02:15:02Z,2005-12-22T02:15:02Z,2004-10-27,MIT-CSAIL-TR-2004-068; MIT-LCS-TR-971,http://hdl.handle.net/1721.1/30499,"This paper addresses the problem of managing the tradeoff betweenenergy consumption and performance in wireless devices implementingthe IEEE 802.11 standard. To save energy, the 802.11 specificationproposes a power-saving mode (PSM), where a device can sleep to saveenergy, periodically waking up to receive packets from a neighbor(e.g., an access point) that may have buffered packets for thesleeping device. Previous work has shown that a fixed polling time forwaking up degrades the performance of Web transfers, because networkactivity is bursty and time-varying. We apply a new online machinelearning algorithm to this problem and show, using ns simulation andtrace analysis, that it is able to adapt well to network activity. Thelearning process makes no assumptions about the underlying networkactivity being stationary or even Markov. Our learning power-savingalgorithm, LPSM, guides the learning using a ""loss function"" thatcombines the increased latency from potentially sleeping too long andthe wasted use of energy in waking up too soon.  In our nssimulations, LPSM saved 7%-20% more energy than 802.11 in power-savingmode, with an associated increase in average latency by a factor of1.02, and not more than 1.2.  LPSM is straightforward to implementwithin the 802.11 PSM framework.",14 p.; 23210224 bytes; 1542849 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,Managing the 802.11 Energy/Performance Tradeoff with Machine Learning,Networks and Mobile Systems,,
"Gilbert, Seth; Malewicz, Grzegorz",2005-12-19T23:27:35Z,2005-12-19T23:27:35Z,2004-10-29,MIT-CSAIL-TR-2004-069; MIT-LCS-TR-972,http://hdl.handle.net/1721.1/30415,"Quorum systems are commonly used to maintain the consistency of replicated data in adistributed system. Much research has been devoted to developing quorum systems with good theoreticalproperties, such as fault tolerance and high availability. However, even given a theoreticallygood quorum system, it is not obvious how to efficiently deploy such a system in a real network. Thispaper introduces a new combinatorial optimization problem, the Quorum Deployment Problem, andstudies its complexity. We demonstrate that it is NP-hard to approximate the Quorum DeploymentProblem within any factor of n?, where n is the number of nodes in the distributed network and ? > 0.The problem is NP-hard in even the simplest possible distributed network: a one-dimensional line withmetric cost. We begin to study algorithms for variants of the problem. Some variants can be solved optimallyin polynomial time and some NP-hard variants can be approximated to within a constant factor.",20 p.; 25684763 bytes; 1002668 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,,The Quorum Deployment Problem,Theory of Computation,,
"Werfel, Justin",2005-12-22T02:15:12Z,2005-12-22T02:15:12Z,2004-11-09,MIT-CSAIL-TR-2004-070; AITR-2004-008,http://hdl.handle.net/1721.1/30500,"The zebra finch is a standard experimental system for studying learning and generation of temporally extended motor patterns.  The first part of this project concerned the evaluation of simple models for the operation and structure of the network in the motor nucleus RA.  A directed excitatory chain with a global inhibitory network, for which experimental evidence exists, was found to produce waves of activity similar to those observed in RA; this similarity included one particularly important feature of the measured activity, synchrony between the onset of bursting in one neuron and the offset of bursting in another.  Other models, which were simpler and more analytically tractable, were also able to exhibit this feature, but not for parameter values quantitatively close to those observed.Another issue of interest concerns how these networks are initially learned by the bird during song acquisition.  The second part of the project concerned the analysis of exemplars of REINFORCE algorithms, a general class of algorithms for reinforcement learning in neural networks, which are on several counts more biologically plausible than standard prescriptions such as backpropagation.  The former compared favorably with backpropagation on tasks involving single input-output pairs, though a noise analysis suggested it should not perform so well.  On tasks involving trajectory learning, REINFORCE algorithms meet with some success, though the analysis that predicts their success on input-output-pair tasks fails to explain it for trajectories.",61 p.; 385088 bytes; 121048 bytes,application/postscript; application/pdf,en_US,Massachusetts Institute of Technology Computer Science and Artificial Intelligence Laboratory,AI,Neural Network Models for Zebra Finch Song Production and Reinforcement Learning,,,
